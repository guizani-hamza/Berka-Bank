# -*- coding: utf-8 -*-
"""the_berka_bank_DB_2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JaHOcIn9mlPc-qEPkgQ2cnJ-ua6kwg0P
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import chi2_contingency

df_loan = pd.read_csv("/content/loan.csv", sep=';')
df_client = pd.read_csv("/content/client.csv", sep=';')
df_account = pd.read_csv("/content/account.csv", sep=';')
df_card = pd.read_csv("/content/card.csv", sep=';')
df_disposition = pd.read_csv("/content/disp.csv", sep=';')
df_district = pd.read_csv("/content/district.csv", sep=';')
df_order = pd.read_csv("/content/order.csv", sep=';')
df_trans = pd.read_csv("/content/trans.csv", sep=';')

# cellule de test
df_trans = pd.read_csv("/content/trans.csv", sep=';')

pd.set_option('display.max_columns', 500)

"""#**Data Cleaning**

##**1- description de la table loan**
"""

df_loan.head()

df_loan["status"].value_counts()#(normalize=True)
# A : Pr√™t en cours de remboursement (actif).
# B : Pr√™t en d√©faut de paiement (d√©faut).
# C : Pr√™t rembours√© int√©gralement (clos).
# D : Pr√™t restructur√© ou en cours en recouvrement

# | `loan_id`             | Integer       | Identifiant unique du pr√™t. Cl√© primaire de la table.                                                                                                                                                      |
# | `account_id`          | Integer       | Identifiant du compte li√© au pr√™t. Cl√© √©trang√®re vers la table `account`. Permet de relier le pr√™t au client concern√©.                                                                                     |
# | `date`                | Date          | Date d'octroi du pr√™t (format AAAA-MM-JJ).                                                                                                                                                                 |
# | `amount`              | Float/Integer | Montant total du pr√™t accord√© (en couronnes tch√®ques).                                                                                                                                                     |
# | `duration`            | Integer       | Dur√©e du pr√™t, exprim√©e en **mois**.                                                                                                                                                                       |
# | `payments`            | Float         | Montant **mensuel** √† rembourser (valeur fixe).                                                                                                                                                            |
# | `status`              | Categorical   | Statut actuel du pr√™t. G√©n√©ralement cod√© par une lettre :
# | `A` = actif (en cours de remboursement) `B` = en d√©faut (impay√©) `C` = rembours√© `D` = litige ou restructur√© (moins courant) |

# aper√ßu
print(df_loan.shape)
print("_______________")
print(df_loan.columns)
print("_______________")
print(df_loan.info())

df_loan.describe()

status_mapping = {
    'A': 'actif',       # en cours de remboursement
    'B': 'd√©faut',      # en d√©faut de paiement
    'C': 'rembours√©',   # pr√™t termin√©
    'D': 'litige'       # autre situation (rare)
}
df_loan['status'] = df_loan['status'].map(status_mapping)
df_loan.head()

df_loan['date'] = pd.to_datetime(df_loan['date'], format='%y%m%d', errors='coerce')
df_loan

df_loan['loan_id'] = df_loan['loan_id'].astype(str)
df_loan['account_id'] = df_loan['account_id'].astype(str)
df_loan.info()

print(df_loan.isnull().sum())

print(df_loan.duplicated().sum())

df_loan['status'].value_counts(normalize=True)

# renomm√© les colonnes
df_loan.rename(columns={
    'amount': 'loan_amount',
    'duration': 'loan_duration',
    'payments': 'loan_payments',
    'status': 'loan_status',
    'date': 'loan_date'
}, inplace=True)

df_loan_clean = df_loan.copy()
df_loan_clean

"""##**2 - description de la table client**



"""

df_client.head()

# aper√ßu
print(df_client.shape)
print("_______________")
print(df_client.columns)
print("_______________")
print(df_client.info())

df_client.describe()

# | `client_id`     Identifiant unique du client. Cl√© primaire. Sert √† relier le client aux autres tables (`disposition`, `card`, etc.).                                                                      |
# | `birth_number`  Encodage de la **date de naissance** et du **sexe** :<br>‚Üí Format `YYMMDD`<br>‚Üí Si le mois est > 50, il s'agit d'une femme (ex. 536123 = 16 mars 1953, femme)<br>‚Üí Sinon, c‚Äôest un homme. |
# | `district_id`   Identifiant du **district** de r√©sidence du client. Cl√© √©trang√®re vers la table `district`, qui contient les donn√©es socio-√©conomiques de la zone.                                        |

def decode_birth_number(birth_number):
    # S'assure que c'est bien une cha√Æne de 6 chiffres
    birth_str = str(birth_number).zfill(6)
    year = int(birth_str[:2])
    month = int(birth_str[2:4])
    day = int(birth_str[4:6])

    gender = 'F' if month > 50 else 'M'
    if month > 50:
        month -= 50

    # Gestion du si√®cle (√† adapter si besoin)
    year += 1900

    return pd.to_datetime(f"{year}-{month:02d}-{day:02d}"), gender

# Exemple d‚Äôutilisation sur un DataFrame
df_client['birth_date'], df_client['gender'] = zip(*df_client['birth_number'].apply(decode_birth_number))
df_client.head()

df_client['age'] = 1998 - df_client['birth_date'].dt.year

df_client.drop(columns='birth_number', inplace=True)

df_client['client_id'] = df_client['client_id'].astype(str)
df_client['district_id'] = df_client['district_id'].astype(str)
df_client.head()

df_client.isnull().sum()

df_client.duplicated().sum()

df_client['district_id'].nunique()

df_client_clean = df_client.copy()

df_client_clean

df_client_clean.describe()

"""##**3 - description de la table account**

"""

df_account.head()

# | `account_id`           Identifiant unique du compte bancaire.                                                                             |
# | `district_id`          Identifiant du district o√π le compte est domicili√©.                                                                                                   |
# | `frequency`            Fr√©quence d‚Äôenvoi des relev√©s bancaires au titulaire du compte.
# | `date`                 Date d‚Äôouverture du compte bancaire.                                                                                                                                   |

# aper√ßu
print(df_account.shape)
print("_______________")
print(df_account.columns)
print("_______________")
print(df_account.info())

df_account.describe()

df_account['date'] = pd.to_datetime(df_account['date'], format='%y%m%d', errors='coerce')

df_account['frequency'].unique()
#`'POPLATEK MESICNE'` ‚Üí mensuel
#'POPLATEK TYDNE'` ‚Üí hebdomadaire
#'POPLATEK PO OBRATU'` ‚Üí apr√®s transaction

freq_map = {
    'POPLATEK MESICNE': 'mensuel',
    'POPLATEK TYDNE': 'hebdomadaire',
    'POPLATEK PO OBRATU': 'apr√®s transaction'
}

df_account['frequency'] = df_account['frequency'].map(freq_map)

df_account.isna().sum()

df_account.drop_duplicates(inplace=True)
df_account.duplicated().sum()

df_account['account_id'] = df_account['account_id'].astype(str)
df_account['district_id'] = df_account['district_id'].astype(str)
df_account.head()

df_account['frequency'].value_counts()

# renomm√© les colonnes
df_account.rename(columns={
    'date': 'account_date',
    'frequency': 'sending_frequency'
}, inplace=True)

df_account

df_account_clean = df_account.copy()

df_account_clean.describe()

"""##**4 - description de la table card**"""

df_card.head()

# | `card_id`              Identifiant unique de la carte.                                                                                                               |
# | `disp_id`              Identifiant de la **relation client-compte** Permet de relier la carte √† un client pr√©cis et √† son compte.                  |
# | `type`                 Type de carte bancaire.
# | `issued`               Date d‚Äô√©mission de la carte

# aper√ßu
print(df_card.shape)
print("_______________")
print(df_card.columns)
print("_______________")
print(df_card.info())

df_card.describe()

def fix_date(d):
    if pd.isna(d):
        return pd.NaT
    d = pd.to_datetime(str(d)[:6], format="%y%m%d", errors='coerce')
    # Corrige les ann√©es sup√©rieures √† 2025 en les ramenant au XXe si√®cle
    if d and d.year > 2000:
        d = d.replace(year=d.year - 100)
    return d

df_card['issued'] = df_card['issued'].apply(fix_date)

df_card['card_id'] = df_card['card_id'].astype(str)
df_card['disp_id'] = df_card['disp_id'].astype(str)
df_card.head()

df_card['type'].unique()

df_card.rename(columns={
    'type': 'card_type',
    'issued': 'card_date'
}, inplace=True)

df_card_clean = df_card.copy()

df_card_clean

df_card_clean.describe()

"""##**5 - description de la table disp**

"""

df_disposition.head()

df_disposition.info()

df_disposition['type'].unique()
#  'OWNER' ‚Üí le client est le titulaire du compte
#  'DISPONENT' ‚Üí le client est un utilisateur (ex. mandataire, conjoint)

df_disposition['type'].value_counts()

df_disposition['disp_id'] = df_disposition['disp_id'].astype(str)
df_disposition['client_id'] = df_disposition['client_id'].astype(str)
df_disposition['account_id'] = df_disposition['account_id'].astype(str)
df_disposition

# renomm√© les colonnes
df_disposition.rename(columns={
    'type': 'disp_role'
}, inplace=True)

df_disposition_clean = df_disposition.copy()
df_disposition_clean

"""
##**6 - description de la table district (r√©gion)**"""

df_district.head()

# Renommage des colonnes avec des noms plus parlants
df_district.rename(columns={
    'A1': 'district_id',
    'A2': 'district_name',
    'A3': 'region',
    'A4': 'nb_inhabitants',
    'A5': 'municipalities_lt_499',
    'A6': 'municipalities_500_1999',
    'A7': 'municipalities_2000_9999',
    'A8': 'municipalities_gt_10000',
    'A9': 'nb_cities',
    'A10': 'urban_ratio',
    'A11': 'average_salary',
    'A12': 'unemployment_1995',
    'A13': 'unemployment_1996',
    'A14': 'entrepreneurs_par_1000',
    'A15': 'crimes_1995',
    'A16': 'crimes_1996'
}, inplace=True)

# district_id : Identifiant unique du district.
# district_name : Nom du district.
# region : R√©gion administrative.
# nb_inhabitants : Nombre d'habitants.
# municipalities_lt_499 : Nombre de municipalit√©s avec moins de 499 habitants.
# municipalities_500_1999 : Nombre de municipalit√©s avec 500 √† 1999 habitants.
# municipalities_2000_9999 : Nombre de municipalit√©s avec 2000 √† 9999 habitants.
# municipalities_gt_10000 : Nombre de municipalit√©s avec plus de 10000 habitants.
# nb_cities : Nombre de villes.
# urban_ratio : Proportion d'habitants urbains.
# average_salary : Salaire moyen dans le district.
# unemployment_1995 : Taux de ch√¥mage en 1995.
# unemployment_1995 : Taux de ch√¥mage en 1996.
# entrepreneurs_par_1000 : nb d'entrepreneurs par 1000 habitants
# crimes_1995 : Nombre de crimes commis en 1995.
# crimes_1995 : Nombre de crimes commis en 1996.

df_district.info()

df_district['unemployment_1995'].unique()

df_district['crimes_1995'].unique()

df_district['unemployment_1995'] = df_district['unemployment_1995'].replace('?', np.nan)
df_district['crimes_1995'] = df_district['crimes_1995'].replace('?', np.nan)

df_district['district_id'] = df_district['district_id'].astype(str)
df_district['unemployment_1995'] = df_district['unemployment_1995'].astype(float)
df_district['crimes_1996'] = df_district['crimes_1996'].astype(float)
df_district['crimes_1995'] = df_district['crimes_1995'].astype(float)

df_district.head()

df_district.isnull().sum()

mean_value = df_district['unemployment_1995'].mean()
mean_valuee = df_district['crimes_1995'].mean()
df_district['unemployment_1995'].fillna(mean_value, inplace=True)
df_district['crimes_1995'].fillna(mean_valuee, inplace=True)

df_district.describe()

df_district.isnull().sum()

df_district.duplicated().sum()

df_district.info()

df_district['district_name'].unique()

df_district_clean = df_district.copy()

df_district_clean

"""


##**7 - description de la table order**"""

df_order.head()



#  `order_id`             Identifiant unique de l‚Äôordre permanent.
#  `account_id`           Identifiant du compte √©metteur de l‚Äôordre.
#  `bank_to`              Code de la banque du b√©n√©ficiaire du virement
#  `account_to`           Num√©ro du compte du b√©n√©ficiaire.
#  `amount`               Montant envoy√© √† chaque ex√©cution de l‚Äôordre permanent
#  `k_symbol`             Code de signification du virement.

df_order.info()

df_order.describe()

df_order.shape



k_symbol_map = {
    'SIPO': 'paiement group√© (SIPO)',
    'UVER': 'remboursement de pr√™t',
    'POJISTNE': 'assurance',
    'LEASING': 'leasing',
    'SLUZBY': 'services',
    'DUCHOD': 'retraite',
    'SANKC. UROK': 'int√©r√™ts de p√©nalit√©',
    'UROK': 'int√©r√™ts cr√©diteurs'

}

df_order['k_symbol'] = df_order['k_symbol'].map(k_symbol_map).fillna('inconnu')
df_order.head()

df_order['account_id'] = df_order['account_id'].astype(str)
df_order['order_id'] = df_order['order_id'].astype(str)
df_order['account_to'] = df_order['account_to'].astype(str)
df_order.head()

df_order['k_symbol'].unique()
#'POJISTNE' ‚Üí assurance
#'LEASING' ‚Üí location / leasing
#'UVER' ‚Üí remboursement de pr√™t
# 'SIPO' ‚Üí Paiement group√© de factures courantes
# ' ' ‚Üí NAN

#df_order['k_symbol'] = df_order['k_symbol'].fillna('inconnu')

df_order.isnull().sum()

df_order.duplicated().sum()

df_order['bank_to'].unique()
#Ces codes sont fictifs et anonymis√©s dans le dataset √† des fins de protection des donn√©es.

df_order['bank_to'].value_counts()

df_order.rename(columns={
    'amount': 'order_amount',
    'k_symbol' : 'order_type'
}, inplace=True)

df_order_clean = df_order.copy()
df_order_clean

df_order_clean.groupby('bank_to').count

df_order_clean['order_type'].value_counts()

"""##**8 - description de la table transaction**"""

df_trans.head()

# | **`trans_id`**    Identifiant unique de la transaction.                                  |
# | **`account_id`**  R√©f√©rence au **compte bancaire** concern√© par la transaction     |
# | **`date`**        Date de la transaction
# | **`type`**        Type g√©n√©ral de la transaction
# | **operation**     D√©tail du type d‚Äôop√©ration
# | **amount**        Montant de la transaction (en couronnes tch√®ques). |
# | **balance**       Solde du compte apr√®s la transaction. |
# | **k_symbol**      Cat√©gorie du paiement. Valeurs possibles
# | **bank**          Code de la banque de l‚Äôautre partie (comme dans bank_to dans order).
# | **account**       Num√©ro de compte du b√©n√©ficiaire ou de l‚Äôexp√©diteur.

# important
# | Elles sont simplement vides (NaN) dans certaines lignes, notamment pour les retraits ou d√©p√¥ts manuels sans contrepartie externe.

df_trans.info()

df_trans.shape

df_trans.describe()

df_trans['type'].unique()
# 'PRIJEM' ‚Üí cr√©dit (entr√©e d‚Äôargent)
# 'VYDAJ' ‚Üí d√©bit (sortie d‚Äôargent)
# 'VYBER' ‚Üí retrait (par le client)

type_map = {
    'PRIJEM': 'credit',
    'VYDAJ': 'debit',
    'VYBER': 'retrait'
}
df_trans['type'] = df_trans['type'].map(type_map)

df_trans['operation'].unique()
#'VKLAD' ‚Üí d√©p√¥t en esp√®ces
#'PREVOD Z UCTU' ‚Üí virement entrant
#'VYBER' ‚Üí retrait standard
#'PREVOD NA UCET' ‚Üí virement sortant
#'VYBER KARTOU' ‚Üí retrait par carte

df_trans['k_symbol'].unique()
#'SIPO' ‚Üí Paiement group√© de factures courantes
#'UVER' ‚Üí remboursement de pr√™t
#' ' ‚Üí Vide
#'POJISTNE' ‚Üí assurance
#'LEASING' ‚Üí location / leasing
#'SLUZBY' ‚Üí  Paiements pour des services divers
#'SANKC. UROK'  ‚Üí  	Int√©r√™ts de p√©nalit√©
#'UROK' ‚Üí Paiement d‚Äôint√©r√™ts vers√©s au client par la banque
#'DUCHOD' ‚Üí une pension ou une retraite mensuelle.

df_trans['k_symbol'] = df_trans['k_symbol'].str.strip().replace('', None)

k_symbol_map = {
    'SIPO': 'paiement groupe',
    'UVER': 'remboursement pret',
    'POJISTNE': 'assurance',
    'LEASING': 'leasing',
    'SLUZBY': 'services',
    'DUCHOD': 'retraite',
    'SANKC. UROK': 'int√©rets penalite',
    'UROK': 'interets crediteurs',
    None: 'inconnu'
}

df_trans['k_symbol'] = df_trans['k_symbol'].map(k_symbol_map).fillna('inconnu')

df_trans['k_symbol'].unique()

operation_map = {
    'VYBER KARTOU': 'retrait par carte',
    'VKLAD': 'depot en especes',
    'PREVOD Z UCTU': 'virement entrant',
    'PREVOD NA UCET': 'virement sortant',
    'SANKC. UROK': 'interets de penalite',
    'UROK': 'interets crediteurs',
    'VYBER': 'retrait en especes',
    ' ': 'inconnu',
    None: 'inconnu'
}
# nous d√©cidons de traiter les ' ' en NAN


# Nettoyage des espaces superflus
df_trans['operation'] = df_trans['operation'].str.strip()

# Remplacement
df_trans['operation'] = df_trans['operation'].replace(operation_map)

df_trans['date'] = pd.to_datetime(df_trans['date'], format='%y%m%d', errors='coerce')

df_trans.info()

df_trans['account_id'] = df_trans['account_id'].astype(str)
df_trans['trans_id'] = df_trans['trans_id'].astype(str)
df_trans['account'] = df_trans['account'].astype(str)
df_trans.head()

df_trans.isnull().sum()

df_trans['bank'] = df_trans['bank'].fillna('inconnu')
df_trans['account'] = df_trans['account'].fillna('inconnu')
df_trans['account'] = df_trans['account'].replace({"nan": "inconnu"})

df_trans.isnull().sum()

df_trans.duplicated().sum()

df_trans.head()

df_trans.info()

#Colonnes
df_trans.rename(columns={
    'date': 'trans_date',
    'type' : 'trans_type',
    'amount' : 'trans_amount',
    'balance' : 'trans_balance',
    'k_symbol' : 'order_type',
    'bank' : 'bank_to',
    'account' : 'order_account'
}, inplace=True)

df_trans_clean = df_trans.copy()
df_trans_clean

"""#**Outliers**"""

import pandas as pd
import matplotlib.pyplot as plt


dfs = {
    'loan'     : df_loan_clean,
    'account'  : df_account_clean,
    'card'     : df_card_clean,
    'trans'    : df_trans_clean,
    'client'   : df_client_clean,
    'district' : df_district_clean,
    'order'    : df_order_clean,
}


outlier_stats = []

for tbl_name, df in dfs.items():
    numeric_cols = df.select_dtypes(include='number').columns

    for col in numeric_cols:
        plt.figure()
        df.boxplot(column=col)
        plt.title(f'{tbl_name} ‚Äî {col}')
        plt.ylabel(col)
        plt.show()


        q1, q3 = df[col].quantile([0.25, 0.75])
        iqr = q3 - q1
        lower = q1 - 1.5 * iqr
        upper = q3 + 1.5 * iqr
        n_out = ((df[col] < lower) | (df[col] > upper)).sum()

        outlier_stats.append({
            'table'       : tbl_name,
            'column'      : col,
            'lower_bound' : lower,
            'upper_bound' : upper,
            'n_outliers'  : n_out
        })

report_df = pd.DataFrame(outlier_stats)
report_df.sort_values(['table', 'n_outliers'], ascending=[True, False], inplace=True)
report_df.reset_index(drop=True, inplace=True)


report_df

"""#**Exportation des donn√©es**"""

# df_client.to_csv("client_clean.csv", index=False)
# df_account.to_csv("account_clean.csv", index=False)
# df_trans.to_csv("transaction_clean.csv", index=False)
# df_loan.to_csv("loan_clean.csv", index=False)
# df_card.to_csv("card_clean.csv", index=False)
# df_order.to_csv("order_clean.csv", index=False)
# df_district.to_csv("district_clean.csv", index=False)
# df_disposition.to_csv("disposition_clean.csv", index=False)

"""#TABLES

"""

df_disposition_clean.head(1)

df_client_clean.head(1)

df_account_clean.head(1)

df_district_clean.head(1)

df_card_clean.head(1)

df_loan_clean.head(1)

df_trans_clean.head(1)

df_order_clean.head(1)

"""#**1 - PROBL√âMATIQUE 1 : R√©partition des clients selon l‚Äô√¢ge, sexe, localisation ou statut**

#**Jointures**
"""

# === Jointure client + disposition ===
client_dispo = pd.merge(df_client_clean, df_disposition_clean, on="client_id", how="inner")

# === Jointure avec district ===
df_final_p_1 = pd.merge(client_dispo, df_district_clean, left_on="district_id", right_on="district_id", how="left")

# === Jointure avec loan
df_final_p_1_loan = pd.merge(df_final_p_1, df_loan_clean, on="account_id", how="left")

"""## **1 - R√©partition par sexe**"""

df_client_clean.head()

# Compter les sexes
sex_counts = df_client_clean['gender'].value_counts()

# Affichage
sex_counts.plot(kind='pie', autopct='%1.1f%%', title="R√©partition par sexe")
plt.ylabel('')
plt.show()

"""## **2 - R√©partition par tranche d‚Äô√¢ge**"""

# Cr√©er des tranches
df_client_clean['tranche_age'] = pd.cut(df_client_clean['age'], bins=[0, 18, 30, 45, 60, 100],
                                labels=['<18', '18-30', '31-45', '46-60', '60+'])
df_client_clean.head()

# Compter et afficher
df_client_clean['tranche_age'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black', width=0.8
, title="R√©partition par tranche d‚Äô√¢ge")
plt.xlabel("Tranche d‚Äô√¢ge")
plt.ylabel("Nombre de clients")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**3 - R√©partition g√©ographique**"""

# Top 10 des r√©gion
df_final_p_1["district_name"].value_counts().head(10)

plt.figure(figsize=(10, 6))
df_final_p_1["district_name"].value_counts().head(10).plot(kind='bar')
plt.title("Top 10 des districts les plus repr√©sent√©s")
plt.xlabel("Nom du district")
plt.ylabel("Nombre de clients")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**4 -  R√©partition par statut**"""

df_final_p_1_loan.head()

df_final_p_1_loan["loan_status"].value_counts()
#[-3:]
#(normalize=True) * 100

plt.figure(figsize=(6, 4))
df_final_p_1_loan["loan_status"].value_counts().plot(kind='bar', color='skyblue')
plt.title("R√©partition des clients selon leur statut")
plt.xlabel("Statut")
plt.ylabel("Nombre de clients")
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

"""## check des tables"""

display(df_account_clean.head()), #ok

display(df_client_clean.head()), #copy
client = df_client_clean.copy() #ajout des tranches d'age

display(df_account_clean.head()),

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),
display(df_trans_clean.head())

"""#**2 - PROBL√âMATIQUE 2 : les types de comptes les plus utilis√©s, et avec quelle fr√©quence les op√©rations sont effectu√©es**





"""

# La colonne 'frequency' (fr√©quence de frais ou de relev√©)
df_account_clean['sending_frequency'].value_counts()

plt.figure(figsize=(8,5))
df_account_clean['sending_frequency'].value_counts().plot(kind='bar', color='orange')
plt.title("R√©partition des types de comptes")
plt.xlabel("Type de compte (fr√©quence)")
plt.ylabel("Nombre de comptes")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Nombre d'op√©rations par compte
transactions_per_account = df_trans_clean.groupby('account_id').size().reset_index(name='transaction_count')
transactions_per_account

# Jointure avec account_clean pour r√©cup√©rer le type de compte
account_usage = pd.merge(df_account_clean, transactions_per_account, on='account_id', how='left')
account_usage

account_usage['transaction_count'].sum()

account_usage['transaction_count'] = account_usage['transaction_count'].fillna(0)

account_usage['sending_frequency'].value_counts()

# === 5. Analyse : Moyenne d‚Äôop√©rations par type de compte ===
avg_transactions_by_type = account_usage.groupby('sending_frequency')['transaction_count'].mean().sort_values(ascending=False)

print("Nombre moyen d'op√©rations par type de compte :")
avg_transactions_by_type

plt.figure(figsize=(8,5))
avg_transactions_by_type.plot(kind='bar', color='green')
plt.title("Moyenne d'op√©rations par type de compte")
plt.xlabel("Type de compte (fr√©quence)")
plt.ylabel("Nombre moyen d'op√©rations")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""# segmenter les compte et deduire un type par leur comportement"""

df_account_clean.head()

df_trans_clean.head()

# Regrouper les transactions par compte
agg_trans = df_trans_clean.groupby('account_id').agg(
    nb_operations_trans=('trans_amount', 'count'),
    montant_moyen_trans=('trans_amount', 'mean'),
    montant_total_trans=('trans_amount', 'sum'),
    balance_moyen_trans	 = ('trans_balance', 'mean'),
    balance_total_trans = ('trans_balance', 'sum'),
).reset_index().round(2)
agg_trans

# Regrouper les transactions par compte
agg_trans_2 = df_trans_clean.groupby('account_id').agg(
    nb_operations_trans=('trans_amount', 'count'),
    montant_moyen_trans=('trans_amount', 'mean'),
    montant_total_trans=('trans_amount', 'sum'),
    balance_moyen_trans_mean	 = ('trans_balance', 'mean'),
    balance_total_trans_median = ('trans_balance', 'median'),
    balance_total_trans_std = ('trans_balance', 'std')
).reset_index().round(2)
agg_trans_2

df_card_disp = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='left')
df_card_disp

# Cr√©er une colonne binaire : 1 si le compte a un pr√™t
df_loan_clean['has_loan'] = 1
loan_flag = df_loan_clean[['account_id', 'has_loan']].drop_duplicates()

df_card_disp['has_card'] = 1
card_flag = df_card_disp[['account_id', 'has_card']].drop_duplicates()

# Fusion avec les donn√©es des comptes

df = (df_account_clean
      .merge(agg_trans_2, on='account_id', how='left')   # agr√©gats de transactions
      .merge(loan_flag, on='account_id', how='left')   # flag pr√™t
      .merge(card_flag, on='account_id', how='left') )




# df = pd.merge(df_account_clean, agg_trans, on='account_id', how='left')
# df = pd.merge(df, loan_flag, on='account_id', how='left')


df['has_loan'] = df['has_loan'].fillna(0)
df['has_card'] = df['has_card'].fillna(0)
df['nb_operations_trans'] = df['nb_operations_trans'].fillna(0)
df['montant_moyen_trans'] = df['montant_moyen_trans'].fillna(0)
df['montant_total_trans'] = df['montant_total_trans'].fillna(0)
df['balance_moyen_trans_mean'] = df['balance_moyen_trans_mean'].fillna(0)
df['balance_total_trans_median'] = df['balance_total_trans_median'].fillna(0)
df['balance_total_trans_std'] = df['balance_total_trans_std'].fillna(0)




  # balance_moyen_trans_mean	 = ('trans_balance', 'mean'),
  #   balance_total_trans_median = ('trans_balance', 'median'),
  #   balance_total_trans_std = ('trans_balance', 'std')

df.head()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

#Clustering avec KMeans


X = df[['nb_operations_trans', 'montant_moyen_trans', 'montant_total_trans', 'balance_moyen_trans_mean', 'balance_total_trans_median', 'balance_total_trans_std','has_loan', 'has_card']]

# Standardisation
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# KMeans clustering
kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
df['cluster'] = kmeans.fit_predict(X_scaled)

# Visualisation du r√©sultat
plt.figure(figsize=(8, 5))
df['cluster'].value_counts().sort_index().plot(kind='bar', color='purple')
plt.title("Segmentation des comptes bancaires par KMeans")
plt.xlabel("Cluster")
plt.ylabel("Nombre de comptes")
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
kmeans

# Moyenne des variables explicatives par cluster
resume_clusters = df.groupby('cluster')[['nb_operations_trans', 'montant_moyen_trans', 'montant_total_trans', 'balance_moyen_trans_mean', 'balance_total_trans_median', 'balance_total_trans_std','has_loan', 'has_card']].mean().round(2)
resume_clusters

# | Cluster | Segmentation comportementale                 | Type bancaire probable                                 |
# | ------- | -------------------------------------------- | ------------------------------------------------------ |
# | **0**   | Activit√© moyenne, pas de pr√™t                | üßæ **Compte courant personnel standard**               |
# | **1**   | Compte tr√®s actif, flux √©lev√©s               | üíº **Compte courant professionnel (TPE/PME) ou client tr√®s fortun√© |
# | **2**   | Grosse activit√©, tr√®s gros flux, pas de pr√™t | üí∞ **Livret √©pargne haut de gamme / Compte titre**     |
# | **3**   | Gros volumes + pr√™t                          | üí≥ **Compte avec cr√©dit (conso ou immo)**              |

def nom_cluster(row):
    if row['cluster'] == 0:
        return 'Compte courant'
    elif row['cluster'] == 1:
        return 'Compte courant pro'
    elif row['cluster'] == 2:
        return 'Compte √©pargne'
    elif row['cluster'] == 3:
        return 'Compte cr√©dit'

df['type_compte_kmeans'] = df.apply(nom_cluster, axis=1)
df

df_account_clean.head()

df_trans_clean = df_trans_clean.merge(df[['account_id', 'type_compte_kmeans']], on='account_id', how='left')
df_account_clean = df_account_clean.merge(df[['account_id', 'type_compte_kmeans']], on='account_id', how='left')

df_account_clean.head()

df_trans_clean.head()

df_account_clean['type_compte_kmeans'].value_counts().sort_index()

df_trans_clean['type_compte_kmeans'].value_counts().sort_index()

df_loan_clean.shape

# agg_df = df.groupby(['type_compte_kmeans', 'sending_frequency']).agg(
#     {'nb_operations_trans': 'count','montant_total_trans': 'sum'}
#     ).reset_index().round(2)
trans = df_trans_clean.groupby(['type_compte_kmeans','trans_type', 'operation']).size().reset_index(name='nb_transactions')
trans

import pandas as pd

# Regrouper les donn√©es par type de compte et trans_type
#bar_data = trans.groupby(['type_compte_kmeans', 'trans_type'])['nb_transactions'].sum().unstack()

trans.plot(kind='bar', stacked=True, figsize=(10, 6))
plt.title("R√©partition des types de transactions par cluster")
plt.xlabel("Type de compte (cluster KMeans)")
plt.ylabel("Nombre de transactions")
plt.legend(title='Type de transaction')
plt.tight_layout()
plt.show()

import plotly.express as px

fig = px.bar(
    trans,
    x='type_compte_kmeans',
    y='nb_transactions',
    color='trans_type',
    hover_data=['operation'],
    title='Nombre de transactions par type de compte et type de transaction',
    barmode='stack'
)
fig.show()

# Visualisation du r√©sultat nb de comptes
plt.figure(figsize=(8, 5))
df_account_clean['type_compte_kmeans'].value_counts().sort_index().plot(kind='bar', color='purple')
plt.title("Segmentation des comptes bancaires par KMeans")
plt.xlabel("Cluster")
plt.ylabel("Nombre de comptes")
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

# Visualisation du r√©sultat nb de transaction ===
plt.figure(figsize=(8, 5))
df_trans_clean['type_compte_kmeans'].value_counts().sort_index().plot(kind='bar', color='purple')
plt.title("Segmentation des transactions bancaires par KMeans")
plt.xlabel("Cluster")
plt.ylabel("Nombre de transaction")
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

# Regrouper par ty compte
agg = df.groupby(['type_compte_kmeans','sending_frequency']).size().reset_index(name='nb_compte')
agg

agg_df = df.groupby(['type_compte_kmeans', 'sending_frequency']).agg(
    {'nb_operations_trans': 'count','montant_total_trans': 'sum'}
    ).reset_index().round(2)

agg_df

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
components = pca.fit_transform(X_scaled)
df['PC1'] = components[:, 0]
df['PC2'] = components[:, 1]

# Graphique
plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")
sns.scatterplot(data=df, x='PC1', y='PC2', hue='type_compte_kmeans', palette='Set2', s=70, alpha=0.9)
plt.title("Segmentation KMeans des comptes (PCA 2D)")
plt.xlabel("Composante principale 1")
plt.ylabel("Composante principale 2")
plt.legend(title='type_compte')
plt.tight_layout()
plt.show()

# Composante principale 1 (axe horizontal) :
# Probablement corr√©l√©e aux flux mon√©taires (montants d‚Äôop√©rations, soldes, etc.)
# Va de comptes √† flux faibles (gauche) √† tr√®s √©lev√©s (droite)

# Composante principale 2 (axe vertical) :
# Peut refl√©ter la variabilit√© ou fr√©quence des op√©rations (ou une distinction actif/passif)
# Haut : comptes avec activit√© r√©guli√®re
# Bas : comptes plus passifs ou d√©s√©quilibr√©s (comme cr√©dit ou livret peu utilis√©)

components = pca.fit_transform(X_scaled)
components

"""## Check des tables"""

display(df_loan_clean.head()),
loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),
display(df_trans_clean.head()),
transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

"""#**3 - PROBL√âMATIQUE 3 : le volume mensuel ou annuel des transactions ? Y a-t-il une saisonnalit√© dans les d√©penses ?**"""

df_trans_clean.head()

df_trans_clean['year'] = df_trans['trans_date'].dt.year
df_trans_clean['month'] = df_trans['trans_date'].dt.month
df_trans_clean['month'] = df_trans['trans_date'].dt.month
df_trans_clean['day'] = df_trans['trans_date'].dt.day
df_trans_clean['periode'] = df_trans['trans_date'].dt.to_period('M')

df_trans_clean.head()

# Nombre de transactions par mois
tx_count = df_trans_clean.groupby("periode")["trans_id"].count()

# Montant total des transactions par mois
tx_sum = df_trans_clean.groupby("periode")["trans_amount"].sum()

# Regroupement dans un DataFrame
monthly_stats = pd.DataFrame({
    "transactions_count": tx_count,
    "transactions_sum": tx_sum
}).reset_index()

monthly_stats["periode"] = monthly_stats["periode"].astype(str)
monthly_stats

#Visualisation des tendances

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="transactions_sum", data=monthly_stats, marker="o", label="Montant total")
#sns.lineplot(x="periode", y="transactions_count", data=monthly_stats, marker="o", label="Nb op√©rations")

plt.title("√âvolution mensuelle des transactions")
plt.xlabel("Mois")
plt.ylabel("Montants / Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

#D√©tection de la saisonnalit√©
# Moyenne mensuelle toutes ann√©es confondues
seasonal_avg = df_trans_clean.groupby("month")["trans_amount"].sum().reset_index()
seasonal_nb = df_trans_clean.groupby("month")["trans_id"].count().reset_index()

#seasonal_avg

plt.figure(figsize=(10, 5))
#sns.barplot(x="month", y="trans_amount", data=seasonal_avg)
sns.lineplot(x="month", y="trans_amount", data=seasonal_avg, marker="o")
sns.lineplot(x="month", y='trans_id', data=seasonal_nb, marker="o")

plt.title("Saison moyenne des d√©penses mensuelles")
plt.xlabel("Mois")
plt.ylabel("Montant/nb total")
plt.show()

seasonal_nb

#D√©tection de la saisonnalit√©
# Moyenne mensuelle toutes ann√©es confondues
seasonal_avg = df_trans_clean.groupby("year")["trans_amount"].sum().reset_index()
seasonal_nb = df_trans_clean.groupby("year")["trans_id"].count().reset_index()

#seasonal_avg

plt.figure(figsize=(10, 5))
#sns.barplot(x="year", y="trans_amount", data=seasonal_avg)
sns.lineplot(x="year", y="trans_amount", data=seasonal_avg, marker="o")
#sns.lineplot(x="year", y='trans_id', data=seasonal_nb, marker="o")

plt.title("Saison moyenne des d√©penses mensuelles")
plt.xlabel("ann√©e")
plt.ylabel("Montant/nb total")
plt.show()

"""#**time series**"""

df_time = df_trans_clean.copy()
df_time.head()

df_time.set_index("trans_date", inplace=True)

# Option 1 : montant total mensuel
ts_montant = df_time["trans_amount"].resample("M").sum()

# Option 2 : nombre de transactions mensuel
#ts_count = df["amount"].resample("M").count()
print(ts_montant.head())

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))
ts_montant.plot(title="Montant total des transactions (mensuel)")
plt.ylabel("Montant")
plt.xlabel("Date")
plt.grid(True)
plt.show()

from statsmodels.tsa.seasonal import seasonal_decompose

decomposition = seasonal_decompose(ts_montant, model='multiplicative')  # multiplicative parce quevariance croissante

decomposition.plot()
plt.suptitle("D√©composition de la s√©rie temporelle")
plt.tight_layout()
plt.show()

# Tendance : √âvolution globale sur le long terme
# Saison : Motifs r√©currents chaque ann√©e (p√©riodicit√©)
# R√©sidu : √âv√©nements irr√©guliers

decomposition.seasonal.plot(title="Composante saisonni√®re")
plt.show()

decomposition.resid.plot(title="Composante r√©siduelle")
plt.show()

# Amplitude mod√©r√©e des variations
# Les r√©sidus oscillent autour de la valeur 1.00, ce qui signifie que les √©carts √† la tendance + saison sont faibles (max ~1.06, min ~0.96).
# ‚Üí Le mod√®le capte bien la structure globale de la s√©rie.

# Aucune tendance forte apparente
# Pas de d√©rive claire √† la hausse ou √† la baisse : les r√©sidus sont stationnaires autour de 1.
# ‚Üí Cela indique que la tendance et la saisonnalit√© ont √©t√© correctement extraites.

# Quelques pics irr√©guliers
# Des pics en 1993-1994, en 1995, et un peu en 1998.
# ‚Üí Cela pourrait indiquer des anomalies ponctuelles, ou des √©v√©nements exceptionnels (ex : op√©ration massive, erreur, effet externe).

import matplotlib.cm as cm

df_season = ts_montant.to_frame(name='valeur')
df_season['ann√©e'] = df_season.index.year
df_season['mois'] = df_season.index.month

# Pivot pour lignes = mois, colonnes = ann√©es
df_pivot = df_season.pivot(index='mois', columns='ann√©e', values='valeur')

# Trac√©
plt.figure(figsize=(12, 6))
colors = cm.rainbow(np.linspace(0, 1, df_pivot.shape[1]))

for i, col in enumerate(df_pivot.columns):
    plt.plot(df_pivot.index, df_pivot[col], label=str(col), color=colors[i], marker="o")

plt.title("Seasonplot : Rendement")
plt.xlabel("Mois")
plt.ylabel("Valeur")
plt.xticks(ticks=range(1,13), labels=[
    "Jan", "F√©v", "Mar", "Avr", "Mai", "Juin",
    "Juil", "Ao√ªt", "Sep", "Oct", "Nov", "D√©c"
])
plt.legend(title="Ann√©e", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Pr√©paration des donn√©es (index datetime et colonnes 'ds' et 'y')
df_ts = ts_montant.reset_index()
df_ts.columns = ['ds', 'y']
df_ts['ds'] = pd.to_datetime(df_ts['ds'])  # S'assurer que ds est en datetime
df_ts.set_index('ds', inplace=True)

# Entra√Ænement du mod√®le SARIMA
#model = auto_arima(df_ts['y'], seasonal=True, m=12, trace=True, error_action='ignore')
model = SARIMAX(df_ts['y'],  # <- endog ici !
                order=(1, 1, 1),
                seasonal_order=(1, 1, 1, 12),
                enforce_stationarity=False,
                enforce_invertibility=False)

results = model.fit()

# Pr√©vision sur 36 mois √† venir
# On √©tend l'index avec 36 dates suppl√©mentaires
future_dates = pd.date_range(start=df_ts.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')
df_forecast_index = df_ts.index.union(future_dates)

# Pr√©dictions compl√®tes
forecast = results.predict(start=0, end=len(df_forecast_index)-1)

# 4. Visualisation
plt.figure(figsize=(12, 6))
plt.plot(df_ts.index, df_ts['y'], label='Historique')
plt.plot(df_forecast_index, forecast, label='Pr√©vision', linestyle='--')
plt.title("Pr√©vision des transactions")
plt.xlabel("Date")
plt.ylabel("Montant")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""## Check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),

display(df_trans_clean.head()),
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

"""#**4 - PROBL√âMATIQUE 4 : Quel est le solde moyen par r√©gion ou par groupe d‚Äô√¢ge ? Y a-t-il des diff√©rences significatives selon le sexe ou la zone g√©ographique ?**

#**Jointure**
"""

pd.set_option('display.max_columns', 500)

df_district_clean['region'].value_counts()

# Fusion avec les comptes (account) pour r√©cup√©rer les dates et district_id
client_dispo_account = pd.merge(client_dispo, df_account, on="account_id")

# Renommage pour √©viter le conflit de colonnes
client_dispo_account = client_dispo_account.rename(columns={"district_id_y": "district_id"})
client_dispo_account = client_dispo_account.drop(columns=["district_id_x"])

# Fusion avec la table des districts (avec colonnes renomm√©es)
client_account = pd.merge(client_dispo_account, df_district, on="district_id", how="left")
client_account.head()

# Cr√©ation de tranches d'√¢ge
bins = [0, 25, 35, 45, 55, 65, 100]
labels = ["<25", "25-34", "35-44", "45-54", "55-64", "65+"]
client_account["age_group"] = pd.cut(client_account["age"], bins=bins, labels=labels, right=False)

# Calcul du solde moyen par compte √† partir des transactions
balance_mean = df_trans_clean.groupby("account_id")["trans_balance"].mean().reset_index(name="avg_balance")

# Fusion avec les donn√©es client-account
client_account = pd.merge(client_account, balance_mean, on="account_id", how="left")

# Agr√©gation du solde moyen par r√©gion, groupe d'√¢ge et sexe
agg_result = client_account.groupby(["region", "age_group", "gender"])["avg_balance"].mean().reset_index()
agg_result.head(15)

import scipy.stats as stats


# Test t de Student : solde moyen homme vs femme
male_balances = client_account[client_account["gender"] == "M"]["avg_balance"].dropna()
female_balances = client_account[client_account["gender"] == "F"]["avg_balance"].dropna()
t_stat_sex, p_value_sex = stats.ttest_ind(male_balances, female_balances, equal_var=False)

# Test ANOVA : solde moyen par r√©gion
region_groups = client_account.dropna(subset=["avg_balance"]).groupby("region")["avg_balance"].apply(list)
f_stat_region, p_value_region = stats.f_oneway(*region_groups)

{
    "test_t_sex": {"t_stat": t_stat_sex, "p_value": p_value_sex},
    "anova_region": {"f_stat": f_stat_region, "p_value": p_value_region}
}

# Test entre hommes et femmes (t de Student)
# t-statistique = 1.51
# p-value = 0.13
# üëâ : pas de diff√©rence significative entre les sexes (car p > 0.05)

# Test entre r√©gions (ANOVA)
# F-statistique = 0.63
# p-value = 0.73
# üëâ : pas de diff√©rence significative entre les r√©gions non plus

# ‚úÖ : Selon ces tests, le solde moyen ne varie pas significativement selon le sexe ou la zone g√©ographique.

df_dispo_ownerr = df_disposition_clean[df_disposition_clean['disp_role'] == 'OWNER'].value_counts()
df_dispo_ownerr

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),

display(df_trans_clean.head()),
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker

"""#**5 - PROBL√âMATIQUE 5 : Quels districts pr√©sentent les meilleures conditions √©conomiques (faible ch√¥mage, salaire √©lev√©, peu de criminalit√©) ?**"""

df_district_clean.head()

# Cr√©ation d'un score √©conomique combin√©
df_district_clean['score'] = (
    df_district_clean['average_salary'] -
    df_district_clean[['unemployment_1995', 'unemployment_1996']].mean(axis=1)*1000 -
    df_district_clean[['crimes_1995', 'crimes_1996']].mean(axis=1)*100
)

# Top 10 des meilleurs districts selon ce score
top_districts = df_district_clean.sort_values(by='score', ascending=False)[[
    'region', 'district_name', 'average_salary', 'unemployment_1996', 'crimes_1996', 'score'
]].head(10)

top_districts

# des revenus √©lev√©s (donc on ajoute le salaire moyen),
# un faible taux de ch√¥mage (donc on soustrait le ch√¥mage),
# une faible criminalit√© (donc on soustrait le taux de crimes).

# #  Interpr√©tation :
# # Plus le score est √©lev√© (moins n√©gatif), plus le district est favorable √©conomiquement.
# # # Un district avec un salaire √©lev√©, peu de ch√¥mage, et peu de crimes aura un score √©lev√©.

 #Bien que Prague ou Brno soient les centres √©conomiques √©vidents, mon analyse fait ressortir des districts moins urbanis√©s mais tr√®s stables comme Rokycany ou Domazlice, o√π la combinaison entre bas taux de ch√¥mage, salaires corrects et faible criminalit√© constitue un excellent indicateur de bien-√™tre √©conomique.

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# S√©lectionner les colonnes pour l'analyse
features = ['unemployment_1996', 'average_salary', 'crimes_1996']
df_features = df_district_clean[features]
df_features
# Standardiser les donn√©es
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df_features)
scaled_features

# Appliquer la PCA pour cr√©er 1 seul "super-score"
pca = PCA(n_components=1)
df_district_clean['score_pca'] = pca.fit_transform(scaled_features)
df_district_clean['score_pca']


# Interpr√©ter les poids (les "loadings")
# pca.components_ nous donne la "recette"
poids = pca.components_[0]

print("Poids calcul√©s par la PCA pour chaque variable :")
for feature, weight in zip(features, poids):
    print(f"- {feature}: {weight:.2f}")

# Pour obtenir un classement, on doit s'assurer que le score va dans le bon sens.
# Ex: si 'average_salary' a un poids positif, un score √©lev√© est bon.
# Si 'unemployment' a un poids n√©gatif, un score √©lev√© est bon.
# Ici, il faut peut-√™tre inverser le signe du score pour que "petit = meilleur".
# On regarde les poids : si le poids du salaire est n√©gatif, on inverse.
if poids[1] < 0:
    df_district_clean['score_pca'] = -df_district_clean['score_pca']


# Afficher le classement final bas√© sur la PCA
classement_pca = df_district_clean.sort_values('score_pca', ascending=False)
display(classement_pca[['district_name', 'score_pca']].head(10))

df_district_clean
df_district_clean = df_district_clean.drop(columns=["score"])

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker

"""#**6 - PROBL√âMATIQUE 6 : Quelle proportion de clients a contract√© un pr√™t ? Quels sont les montants et dur√©es les plus fr√©quents ?**

#**Jointure**
"""

# Fusion pour relier les pr√™ts aux clients via disposition
df_loan_full = df_loan_clean.merge(df_disposition_clean, on="account_id", how="left")
df_loan_full = df_loan_full.merge(df_client_clean, on="client_id", how="left")

df_loan_clean.head()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np



# Calcul de la proportion de clients ayant un pr√™t
total_clients = df_client_clean['client_id'].nunique()
clients_with_loan = df_loan_full['client_id'].nunique()
loan_proportion = clients_with_loan / total_clients
loan_proportion
# 15,4 % des clients ont au moins un pr√™t actif.

# Affichage graphique des montants et dur√©es les plus fr√©quents
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Histogramme des montants
sns.histplot(df_loan_clean['loan_amount'], bins=30, kde=True, ax=axes[0])
axes[0].set_title('Distribution des montants de pr√™ts')
axes[0].set_xlabel('Montant')
axes[0].set_ylabel('Nombre de pr√™ts')

# Histogramme des dur√©es
sns.histplot(df_loan_clean['loan_duration'], bins=30, kde=True, ax=axes[1])
axes[1].set_title('Distribution des dur√©es de pr√™ts')
axes[1].set_xlabel('Dur√©e (mois)')
axes[1].set_ylabel('Nombre de pr√™ts')

plt.tight_layout()
plt.show()

# Montants et dur√©es les plus fr√©quents
top_loan_amounts = df_loan['loan_amount'].value_counts().head(5)
top_loan_durations = df_loan['loan_duration'].value_counts().head(5)
# R√©sultats chiffr√©s
top_loan_amounts, top_loan_durations

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS

"""#**7 - Problematique 7 : Quels types d‚Äôop√©rations bancaires sont les plus fr√©quents (virements, retraits, paiements par carte...) ?**"""

df_trans_clean.head()

# Comptage des types d'op√©rations les plus fr√©quents
operation_counts = df_trans_clean['operation'].value_counts().reset_index()
operation_counts.columns = ['operation', 'count']

# Affichage des r√©sultats
operation_counts.head(10)

# Cr√©ation d'un graphique √† barres
plt.figure(figsize=(10, 6))
plt.bar(operation_counts['operation'], operation_counts['count'])
plt.title("Types d'op√©rations bancaires les plus fr√©quents")
plt.xlabel("Type d'op√©ration")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=45)
plt.tight_layout()
plt.grid(axis='y')
plt.show()

"""# check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS
#pbt 7 : RAS

"""#**8 - PROBLEMATIQUE 8 : √Ä travers les pr√™ts et les frais bancaires visibles dans les transactions, peut-on estimer la rentabilit√© par client ou par r√©gion**

#**Jointure**
"""

df_trans_clean.head()

# Lier clients aux comptes via la table des dispositions
df_dispo_owner = df_disposition_clean[df_disposition_clean['disp_role'] == 'OWNER']
df_clients_accounts = df_dispo_owner.merge(df_client_clean, on='client_id').merge(df_account_clean, on='account_id')
df_clients_accounts = df_clients_accounts.rename(columns={"district_id_y": "district_id"})
df_clients_accounts = df_clients_accounts.drop(columns=["district_id_x"])
# Ajout des infos sur les districts
df_clients_accounts = df_clients_accounts.merge(df_district_clean, on='district_id')
# Ajout des infos client sur les pr√™ts
df_loan_clients = df_loan_clean.merge(df_account_clean[['account_id']], on='account_id')
df_loan_clients = df_loan_clients.merge(df_clients_accounts[['account_id', 'client_id', 'district_id', 'district_name']], on='account_id')
df_loan_clients.head()

# Revenu = int√©r√™ts = (amount * interest_rate / 100) * (duration / 12)
df_loan_clients['revenu_pret'] = df_loan_clients['loan_payments'] * df_loan_clients['loan_duration'] - df_loan_clients['loan_amount']
df_loan_clients['revenu_pret'].sum()

# Revenus issus des frais bancaires (transactions)

# S√©lection des frais dans les transactions (frais = "POPLATEK", int√©r√™ts cr√©dit = "PRIJEM_UROKU")
df_frais = df_trans_clean[df_trans_clean['operation'].isin(['int√©rets penalite','interets crediteurs'])].reset_index()

# Join avec comptes et clients
df_frais = df_frais.merge(df_clients_accounts[['account_id', 'client_id', 'district_id', 'district_name']], on='account_id')

# Ajout d'une colonne 'revenu_frais' (positif si revenu pour la banque)
#df_frais['revenu_frais'] = df_frais['tans_amount'].abs()
df_frais.head()

"""## Check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS m√™me si on devrait creuser les int√©rets sur la partie Power BI

"""#**1 - Comptes**

##**jointure**
"""

# === Jointure client + disposition ===
client_dispo = pd.merge(df_client_clean, df_disposition_clean, on="client_id", how="inner")
client_account = pd.merge(client_dispo, df_account_clean, on="account_id", how="inner")

# Renommage pour √©viter le conflit de colonnes
client_account = client_account.rename(columns={"district_id_y": "district_id"})
client_account = client_account.drop(columns=["district_id_x"])

client_account_district = pd.merge(df_district_clean, client_account, on='district_id', how='left')

client_account_district_trans = pd.merge(df_trans_clean, client_account_district, on='account_id', how='left')

"""##**1 - account fid√®le**"""

client_account_district_trans.head()

# Recalcul de la date maximale pour mesurer l'anciennet√©
max_trans = df_trans_clean['trans_date'].max()

max_trans

# # Calcul de l'anciennet√© en ann√©es
df_account_clean['anciennete_annees'] = (max_trans - df_account_clean['account_date']).dt.days / 365.25
anciennete_stats = df_account_clean['anciennete_annees'].describe()
anciennete_stats



"""##**2 - repartion par sexe**"""

# Compter les sexes
sex_counts = client_account['gender'].value_counts()

# Affichage
sex_counts.plot(kind='pie', autopct='%1.1f%%', title="R√©partition par sexe")
plt.ylabel('')
plt.show()

"""##**3 - repartion des comptes par tranche d'age**"""

# Compter et afficher
client_account['tranche_age'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black', width=0.8
, title="R√©partition par tranche d‚Äô√¢ge")
plt.xlabel("Tranche d‚Äô√¢ge")
plt.ylabel("Nombre de compte")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**4 - repartion des comptes par type**"""

# repartition des comptes par type de compte
client_account_district['type_compte_kmeans'].value_counts().plot(kind='pie', autopct='%1.1f%%', title="R√©partition des comptes par type de compte")
plt.ylabel('')
plt.show()

"""##**5 - Analyse temporelle**

###**Par nombre de compte cr√©e par mois**
"""

client_account_district['year'] = client_account_district['account_date'].dt.year
client_account_district['month'] = client_account_district['account_date'].dt.month
client_account_district['month'] = client_account_district['account_date'].dt.month
client_account_district['day'] = client_account_district['account_date'].dt.day
client_account_district['periode'] = client_account_district['account_date'].dt.to_period('M')

client_account_district.head()

# Nombre de compte cr√©e par mois
tx_count = client_account_district.groupby("periode")["account_id"].count()



# Regroupement dans un DataFrame
monthly_stats = pd.DataFrame({
    "compte_cree": tx_count,
    "balance_total": tx_sum

}).reset_index()

monthly_stats["periode"] = monthly_stats["periode"].astype(str)
monthly_stats

#Visualisation des tendances

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="compte_cree", data=monthly_stats, marker="o", label="nb compte cree ")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("√âvolution mensuelle des compte cree")
plt.xlabel("Mois")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

#D√©tection de la saisonnalit√©
# Moyenne mensuelle toutes ann√©es confondues
#seasonal_avg = df_trans_clean.groupby("month")["trans_amount"].sum().reset_index()
seasonal_nb = client_account_district.groupby("month")["account_id"].count().reset_index()

#seasonal_avg

plt.figure(figsize=(10, 5))
#sns.barplot(x="month", y="trans_amount", data=seasonal_avg)
#sns.lineplot(x="month", y="trans_amount", data=seasonal_avg, marker="o")
sns.lineplot(x="month", y='account_id', data=seasonal_nb, marker="o")

plt.title("Saison moyenne des creation de compte mensuelles")
plt.xlabel("Mois")
plt.ylabel("nb total")
plt.show()



# attention a l'√©chelle

"""###**Par solde des compte**"""

client_account_district_trans.sort_values(by=['account_id', 'trans_date']).head(100)

"""####**Par ann√©e**"""

# Trier les donn√©es
client_account_district_trans_year = client_account_district_trans.sort_values(by=['account_id', 'year', 'trans_date'])

# Garder la derni√®re transaction de chaque mois pour chaque compte
df_last_trans_per_year = client_account_district_trans_year.groupby(['account_id', 'year']).tail(1)

# Garder uniquement les colonnes utiles
result_year = df_last_trans_per_year[['account_id', 'year', 'trans_date', 'trans_balance']].reset_index(drop=True)

result_year.head(10)

result_year.groupby('year')['trans_balance'].sum().reset_index()

sns.lineplot(x="year", y='trans_balance', data=result_year, marker="o")

plt.title("solde total par ann√©e")
plt.xlabel("ann√©e")
plt.ylabel("solde total")
plt.show()

"""####**Par mois**"""

# 3. Trier les donn√©es
client_account_district_trans_month = client_account_district_trans.sort_values(by=['account_id', 'periode', 'trans_date'])

# 4. Garder la derni√®re transaction de chaque mois pour chaque compte
df_last_trans_per_month = client_account_district_trans_month.groupby(['account_id', 'periode']).tail(1)

# 5. (Optionnel) Garder uniquement les colonnes utiles
result_month = df_last_trans_per_month[['account_id', 'month','year','periode', 'trans_date', 'trans_balance']].reset_index(drop=True)

result_month

result_month.groupby('month')['trans_balance'].sum()

sns.lineplot(x="month", y='trans_balance', data=result_month, marker="o")

plt.title("solde total par mois")
plt.xlabel("ann√©e")
plt.ylabel("solde total")
plt.show()



"""##**6 - Stat des soldes des comptes**"""

result_year.describe()

result_month.describe()

"""##**7 - volume des comptes par r√©gion**"""

result_month

df_month = pd.merge(result_month, client_account_district, on='account_id', how='left')
df_month_bis = df_month.groupby('region')['trans_balance'].sum().reset_index()
df_month_bis.head()

"""## check des tables"""

df_account_clean = df_account_clean.drop(columns='anciennete_annees')

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS m√™me si on devrait creuser les int√©rets sur la partie Power BI
#pbt compte : table compte, on ne garde pas anciennet√© (droppper)

"""#**2- loan**

##**Jointures**
"""

client_account_loan = pd.merge(df_loan_clean, client_account, on='account_id', how='left')

client_account_loan.head()

"""##**1- repartition par tranche d'age**

"""

# Compter et afficher
client_account_loan['tranche_age'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black', width=0.8
, title="R√©partition par tranche d‚Äô√¢ge")
plt.xlabel("Tranche d‚Äô√¢ge")
plt.ylabel("Nombre de pr√©t")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**2 - repartion par sexe**"""

# Compter les sexes
sex_counts = client_account_loan['gender'].value_counts()

# Affichage
sex_counts.plot(kind='pie', autopct='%1.1f%%', title="R√©partition par sexe")
plt.ylabel('')
plt.show()

"""##**3 - repartition par statuts**"""

df_loan_clean.head()

# Compter les sexes
status_counts = client_account_loan['loan_status'].value_counts()

# Affichage
status_counts.plot(kind='pie', autopct='%1.1f%%', title="R√©partition par status")
plt.ylabel('')
plt.show()

"""##**4 - repartition par dur√©√©**"""

duree_counts = client_account_loan['loan_duration'].value_counts()
# Affichage
duree_counts.plot(kind='pie', autopct='%1.1f%%', title="R√©partition par duree")
plt.ylabel('')
plt.show()

# amount_counts = client_account_loan['loan_amount'].value_counts().head(10)
# # Affichage
# amount_counts.plot(kind='pie', autopct='%1.1f%%', title="R√©partition par amount")
# plt.ylabel('')
# plt.show()



"""##**5 - Analyse temporelle**"""

client_account_loan['year'] = client_account_loan['loan_date'].dt.year
client_account_loan['month'] = client_account_loan['loan_date'].dt.month
client_account_loan['month'] = client_account_loan['loan_date'].dt.month
client_account_loan['day'] = client_account_loan['loan_date'].dt.day
client_account_loan['periode'] = client_account_loan['loan_date'].dt.to_period('M')

client_account_loan

# Nombre de pr√©t accord√© par mois
nb_loan = client_account_loan.groupby("periode")["loan_id"].count()
volume_loan = client_account_loan.groupby("periode")["loan_amount"].sum()



# Regroupement dans un DataFrame
monthly_stats_loan = pd.DataFrame({
    "nb_loan": nb_loan,
    "montant_total": volume_loan

}).reset_index()

monthly_stats_loan["periode"] = monthly_stats_loan["periode"].astype(str)
monthly_stats_loan

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="nb_loan", data=monthly_stats_loan, marker="o", label="nb loan")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("√âvolution mensuelle des pr√©t accord√©")
plt.xlabel("Mois")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="montant_total", data=monthly_stats_loan, marker="o", label="montant total")


plt.title("√âvolution mensuelle des montant total")
plt.xlabel("Mois")
plt.ylabel("montant")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

"""##**6 - Analyse des loan a risque**"""

# Compter les sexes
status_counts = client_account_loan['loan_status'].value_counts()

# Affichage
status_counts.plot(kind='pie', autopct='%1.1f%%', title="R√©partition par status")
plt.ylabel('')
plt.show()

df_defaut_litige = client_account_loan[client_account_loan['loan_status'].isin(['d√©faut', 'litige'])]
df_defaut_litige

print(df_defaut_litige['periode'].dtype)
print(df_defaut_litige['periode'].head())

loan_defaut_litige_groupe = df_defaut_litige.groupby("periode")["loan_id"].count().reset_index()
loan_defaut_litige_groupe

df_defaut_litige['type_compte_kmeans'].value_counts()

df_defaut_litige['tranche_age'].value_counts()

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS m√™me si on devrait creuser les int√©rets sur la partie Power BI
#pbt compte : table compte, on ne garde pas anciennet√© (droppper)
#pbt loan : RAS

"""#**3 - Card**"""

df_card_clean.head()

"""##**Jointure**"""

# relier CARD ‚Üí DISP  (cl√© primaire : disp_id)
card_disp = df_card_clean.merge(df_disposition_clean[['disp_id','account_id','disp_role']], on='disp_id', how='left')

# garder une seule ligne par carte et par compte ‚Äì pr√©f√©rence OWNER
card_disp = (card_disp
             .sort_values('disp_role')
             .drop_duplicates('card_id'))

# joindre √† ACCOUNT + cluster
card_account_cluster = card_disp.merge(
        df_account_clean[['account_id','type_compte_kmeans']],
        on='account_id',
        how='left')
card_account_cluster = card_account_cluster.drop_duplicates('card_id')

card_account_cluster['type_compte_kmeans'].value_counts()

card_disp = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='left')
card_account = pd.merge(card_disp, df_account_clean, on='account_id', how='left')
card_account_client = pd.merge(card_account, df_client_clean, on='client_id', how='left')

card_account_client.head()

card_account_client.describe()

card_account_client['card_type'].value_counts()

card_account_client['type_compte_kmeans'].value_counts()

card_account_client['gender'].value_counts()

card_account_client['tranche_age'].value_counts()

card_account_client['year'] = card_account_client['card_date'].dt.year
card_account_client['month'] = card_account_client['card_date'].dt.month
card_account_client['month'] = card_account_client['card_date'].dt.month
card_account_client['day'] = card_account_client['card_date'].dt.day
card_account_client['periode'] = card_account_client['card_date'].dt.to_period('M')

card_account_client.head()

# Nombre de pr√©t accord√© par mois
nb_card = card_account_client.groupby("periode")["card_id"].count()
#volume_card = card_account_client.groupby("periode")["loan_amount"].sum()



# Regroupement dans un DataFrame
monthly_stats_card = pd.DataFrame({
    "nb_card": nb_card

}).reset_index()

monthly_stats_card["periode"] = monthly_stats_card["periode"].astype(str)
monthly_stats_card

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="nb_card", data=monthly_stats_card, marker="o", label="nb card")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("√âvolution mensuelle des cartes bancaire")
plt.xlabel("Mois")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

# Nombre de pr√©t accord√© par mois
nb_card = card_account_client.groupby("year")["card_id"].count()
#volume_card = card_account_client.groupby("periode")["loan_amount"].sum()



# Regroupement dans un DataFrame
year_stats_card = pd.DataFrame({
    "nb_card": nb_card

}).reset_index()
year_stats_card["year"] = year_stats_card["year"].astype(str)
year_stats_card

plt.figure(figsize=(14, 6))
sns.lineplot(x="year", y="nb_card", data=year_stats_card, marker="o", label="nb card")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("√âvolution annuelle des cartes bancaire")
plt.xlabel("ann√©e")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

card_account_client['durree_compte_carte'] = card_account_client['card_date'] - card_account_client['account_date']
card_account_client['durree_compte_carte'] = card_account_client['durree_compte_carte'].dt.days
# ploter le resultat
plt.figure(figsize=(10, 6))
sns.histplot(card_account_client['durree_compte_carte'], bins=30, kde=True)
plt.title('Distribution de la dur√©e des cartes bancaire')
plt.xlabel('Dur√©e (jours)')
plt.ylabel('Fr√©quence')
plt.show()

card_account_client.head()

#proportion de client avec ou sans carte
card_account_client['card_id'].value_counts()

import pandas as pd



# Associer chaque carte √† un client
cards_clients = (
    df_card_clean[['card_id', 'disp_id']]
    .merge(df_disposition_clean[['disp_id', 'client_id']],
           on='disp_id', how='left')
    .dropna(subset=['client_id'])
)

# Obtenir la liste unique des clients qui poss√®dent ‚â•1 carte
clients_with_card = cards_clients['client_id'].unique()

# Compter les clients et calculer les proportions
total_clients        = df_client_clean['client_id'].nunique()
nb_clients_with_card = len(clients_with_card)
nb_clients_no_card   = total_clients - nb_clients_with_card

prop_with_card = nb_clients_with_card / total_clients
prop_no_card   = nb_clients_no_card   / total_clients

print(f"Total clients          : {total_clients:,}")
print(f"Clients avec carte     : {nb_clients_with_card:,}  ({prop_with_card:.2%})")
print(f"Clients sans carte     : {nb_clients_no_card:,}   ({prop_no_card:.2%})")



"""##**Card**"""

df_card_clean['year'] = df_card_clean['card_date'].dt.year
df_card_clean['month'] = df_card_clean['card_date'].dt.month
df_card_clean['day'] = df_card_clean['card_date'].dt.day
df_card_clean['periode'] = df_card_clean['card_date'].dt.to_period('M')

df_card_clean

# Nombre de carte √©mise par mois
nb_card_emise = df_card_clean.groupby("periode")["card_id"].count().reset_index()

nb_card_emise = nb_card_emise.rename(columns={"card_id": "nb_card_emission"})

nb_card_emise.describe()

sns.barplot(data = nb_card_emise, x="periode", y = "nb_card_emission")#, kde = True)

client_disp = pd.merge(df_client_clean, df_disposition, how = 'left', on ='client_id')
client_card = pd.merge(client_disp, df_card_clean, how = 'left', on ='disp_id')

client_card.isna().sum()

import pandas as pd
import matplotlib.pyplot as plt

# --- √âTAPE 0 : CHARGEMENT DES DONN√âES N√âCESSAIRES ---
# Adaptez les chemins si vos fichiers ne sont pas dans le m√™me dossier
df_account =  df_account_clean.copy()
df_card = df_card_clean.copy()
df_disp = df_disposition_clean.copy()


# --- √âTAPE 1 : CALCULER LE NOMBRE DE COMPTES AVEC CARTE ---

# On fusionne les tables 'card' et 'disp' pour lier les cartes aux comptes
df_card_disp = pd.merge(df_card, df_disp, on='disp_id')

# On r√©cup√®re la liste des 'account_id' uniques qui ont une carte
accounts_with_card_ids = df_card_disp['account_id'].unique()
nombre_comptes_avec_carte = len(accounts_with_card_ids)


# --- √âTAPE 2 : CALCULER LE NOMBRE TOTAL DE COMPTES ET CEUX SANS CARTE ---

# On compte le nombre total de comptes uniques dans la table 'account'
total_comptes = df_account['account_id'].nunique()

# On calcule le nombre de comptes sans carte par soustraction
nombre_comptes_sans_carte = total_comptes - nombre_comptes_avec_carte


# --- √âTAPE 3 : CR√âER LE GRAPHIQUE EN SECTEURS (PIE CHART) ---

# Pr√©parer les donn√©es pour le graphique
labels = 'Comptes avec Carte', 'Comptes sans Carte'
sizes = [nombre_comptes_avec_carte, nombre_comptes_sans_carte]
explode = (0.1, 0)  # pour faire ressortir la tranche "Avec Carte"
colors = ['#99ff99', '#ff9999'] # Vert et Rouge

# Cr√©er la figure et l'axe
fig, ax = plt.subplots(figsize=(10, 8))

# Cr√©er le diagramme
ax.pie(sizes,
       explode=explode,
       labels=labels,
       colors=colors,
       autopct='%1.1f%%',  # Affiche les pourcentages avec une d√©cimale
       shadow=True,
       startangle=140,      # Pivoter un peu le graphique pour une meilleure lisibilit√©
       textprops={'fontsize': 12})

# Assurer que le graphique est un cercle
ax.axis('equal')

# Ajouter un titre
plt.title("Proportion des Comptes Ayant une Carte Associ√©e", fontsize=16)

# Sauvegarder et afficher le graphique
#plt.savefig('proportion_comptes_avec_carte.png')
#plt.show()

# Afficher les chiffres exacts pour r√©f√©rence
print(f"Nombre de comptes avec carte : {nombre_comptes_avec_carte}")
print(f"Nombre de comptes sans carte : {nombre_comptes_sans_carte}")
print(f"Nombre total de comptes : {total_comptes}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# On suppose que les DataFrames df_account_clean, df_card_clean, et df_disposition_clean sont charg√©s.
# La fusion et le calcul du d√©lai restent les m√™mes.
df_account_clean['date_creation_compte'] = pd.to_datetime(df_account_clean['account_date'], format='%y%m%d', errors='coerce')
df_card_clean['date_emission_carte'] = pd.to_datetime(df_card_clean['card_date'], format='%y%m%d', errors='coerce')
df_merged = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='inner')
df_final = pd.merge(df_merged, df_account_clean, on='account_id', how='inner')
df_final['delai_emission_jours'] = (df_final['date_emission_carte'] - df_final['date_creation_compte']).dt.days


# --- √âTAPE 3: DIAGNOSTIC DES PROBL√àMES DE DONN√âES ---
print("--- Analyse des Probl√®mes de Donn√©es ---")

# Compter les d√©lais NaN (probl√®me de conversion de date)
delais_nan = df_final['delai_emission_jours'].isna().sum()
print(f"Nombre de lignes avec un d√©lai non calculable (NaN) : {delais_nan}")

# Isoler et compter les d√©lais n√©gatifs illogiques
delais_negatifs = df_final[df_final['delai_emission_jours'] < 0]
print(f"Nombre de cartes √©mises AVANT la cr√©ation du compte : {len(delais_negatifs)}")
if not delais_negatifs.empty:
    print("Exemples de ces d√©lais n√©gatifs :")
    display(delais_negatifs[['account_id', 'card_id', 'date_creation_compte', 'date_emission_carte', 'delai_emission_jours']].head())


# --- √âTAPE 4: VISUALISATION SUR LES DONN√âES NETTOY√âES ---
print("\n--- Cr√©ation du graphique sur les donn√©es logiques ---")

# On cr√©e une s√©rie de donn√©es "propres" pour le graphique
# 1. On enl√®ve les NaN avec .dropna()
# 2. On ne garde que les d√©lais positifs ou nuls (>= 0)
delais_propres = df_final['delai_emission_jours'].dropna()
delais_propres = delais_propres[delais_propres >= 0]


# Cr√©er l'histogramme avec les donn√©es nettoy√©es
if not delais_propres.empty:
    plt.figure(figsize=(12, 6))
    sns.histplot(delais_propres, bins=50, kde=True)
    plt.title('Distribution du d√©lai (en jours) entre cr√©ation de compte et √©mission de carte (Donn√©es Nettoy√©es)', fontsize=16)
    plt.xlabel('D√©lai en jours (uniquement les d√©lais positifs ou nuls)', fontsize=12)
    plt.ylabel('Nombre de cartes √©mises', fontsize=12)
    plt.grid(True, linestyle='--')
    #plt.savefig('delai_emission_carte_nettoye.png')
    plt.show()
else:
    print("Aucune donn√©e valide √† afficher apr√®s le nettoyage.")

# On suppose que vos DataFrames df_account_clean et df_card_clean sont charg√©s

print("--- Inspection du format de date dans df_account_clean ---")
print(df_account_clean[['account_id', 'account_date']].head())
print("\nType de la colonne 'account_date':", df_account_clean['account_date'].dtype)

print("\n" + "="*50 + "\n")

print("--- Inspection du format de date dans df_card_clean ---")
print(df_card_clean[['card_id', 'card_date']].head())
print("\nType de la colonne 'card_date':", df_card_clean['card_date'].dtype)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# On suppose que les DataFrames df_account_clean, df_card_clean, et df_disposition_clean sont charg√©s

# --- √âTAPE 1 : CONVERSION DES DATES (LA CORRECTION EST ICI) ---
print("1. Conversion des colonnes de date (d√©tection automatique)...")

# On laisse pandas deviner le format, car 'AAAA-MM-JJ' est un standard qu'il conna√Æt.
df_account_clean['date_creation_compte'] = pd.to_datetime(df_account_clean['account_date'], errors='coerce')
df_card_clean['date_emission_carte'] = pd.to_datetime(df_card_clean['card_date'], errors='coerce')
print("   -> Dates converties avec succ√®s.")


# --- √âTAPE 2 : FUSIONNER LES TABLES (inchang√©) ---
print("2. Fusion des tables...")
df_merged = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='inner')
df_final = pd.merge(df_merged, df_account_clean, on='account_id', how='inner')
print("   -> Fusion termin√©e.")


# --- √âTAPE 3 : CALCULER L'√âCART DE TEMPS (inchang√©) ---
print("3. Calcul du d√©lai d'√©mission...")
df_final['delai_emission_jours'] = (df_final['date_emission_carte'] - df_final['date_creation_compte']).dt.days
print("   -> Calcul termin√©.")


# --- √âTAPE 4 : AFFICHER LES R√âSULTATS ---
print("\nQuelques statistiques sur ce d√©lai (en jours) :")
display(df_final['delai_emission_jours'].describe())


# --- √âTAPE 5 : VISUALISATION ---
print("\n4. Cr√©ation du graphique de distribution...")
# On s'assure de ne tracer que les donn√©es valides en enlevant les potentiels NaNs restants
delais_a_tracer = df_final['delai_emission_jours'].dropna()

if not delais_a_tracer.empty:
    plt.figure(figsize=(12, 6))
    sns.histplot(delais_a_tracer, bins=50, kde=True)
    plt.title('Distribution du d√©lai (en jours) entre la cr√©ation du compte et l\'√©mission de la carte', fontsize=16)
    plt.xlabel('D√©lai en jours', fontsize=12)
    plt.ylabel('Nombre de cartes √©mises', fontsize=12)
    plt.grid(True, linestyle='--')
    #plt.savefig('delai_emission_carte_final.png')
    plt.show()
else:
    print("Aucune donn√©e de d√©lai valide √† afficher.")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --- √âTAPE 1 : CHARGEMENT ET PR√âPARATION DES DONN√âES (inchang√©) ---
# On suppose que les fichiers clean sont charg√©s
#df_account_clean = pd.read_csv('account_clean.csv')
#df_card_clean = pd.read_csv('card_clean.csv')
#df_disposition_clean = pd.read_csv('disposition_clean.csv')

# Conversion des colonnes de date
df_account_clean['account_date_dt'] = pd.to_datetime(df_account_clean['account_date'])
df_card_clean['card_date_dt'] = pd.to_datetime(df_card_clean['card_date'])

# Fusion des tables
df_merged = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='inner')
df_final = pd.merge(df_merged, df_account_clean, on='account_id', how='inner')

# Calcul du d√©lai
df_final['delai_emission_jours'] = (df_final['card_date_dt'] - df_final['account_date_dt']).dt.days

# S√©lection des colonnes pour l'analyse
result_table = df_final[['account_id', 'card_type', 'account_date_dt', 'delai_emission_jours']]


# --- √âTAPE 2 : VISUALISATION MODIFI√âE ---
print("\n--- Visualisation : D√©lai d'√©mission vs Date de Cr√©ation du compte ---")
plt.figure(figsize=(12, 8))

# LA MODIFICATION EST ICI : on utilise x='account_date_dt'
sns.scatterplot(
    data=result_table,
    x='account_date_dt',
    y='delai_emission_jours',
    hue='card_type',
    alpha=0.7,
    s=100
)

plt.title("D√©lai d'√©mission de la carte vs. Date de Cr√©ation du compte", fontsize=16)
plt.xlabel("Date de Cr√©ation du Compte", fontsize=12) # On met √† jour le label de l'axe
plt.ylabel("D√©lai d'attente pour la carte (jours)", fontsize=12)
plt.grid(True)
plt.legend(title='Type de carte')
#plt.savefig('delai_vs_date_creation_carte.png')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import kruskal

# --- √âTAPE 1: CHARGEMENT DES DONN√âES ---
# try:
#     # Utilisons les noms de vos fichiers "clean" qui ont les bonnes colonnes
#     #df_trans_clean = pd.read_csv('df_trans_clean.csv')
#     #df_card_clean = pd.read_csv('card_clean.csv')
#     #df_disposition_clean = pd.read_csv('disposition_clean.csv')
#     print("Fichiers 'clean' charg√©s avec succ√®s.")
# except FileNotFoundError as e:
#     print(f"Erreur de chargement : {e}. Assurez-vous que les fichiers clean sont disponibles.")
#     # On arr√™te si les fichiers ne sont pas trouv√©s.


# --- √âTAPE 2: PR√âPARATION DES DONN√âES (AVEC CORRECTION ROBUSTE) ---

# 1. Calculer le nombre de transactions par compte
print("1. Calcul du nombre de transactions par compte...")
trans_counts = df_trans_clean.groupby('account_id').size().reset_index(name='nb_transactions')

# 2. Identifier le type de carte pour chaque compte
print("2. Identification du type de carte par compte...")
card_disp = pd.merge(df_card_clean, df_disposition_clean, on='disp_id')

# LA CORRECTION EST ICI : On utilise directement 'card_type' car c'est le bon nom dans vos fichiers clean
card_info = card_disp[['account_id', 'card_type']]
# S'il y a plusieurs cartes pour un m√™me compte, on garde la premi√®re trouv√©e
card_info = card_info.drop_duplicates(subset='account_id', keep='first')


# 3. Harmonisation des types et fusion
print("3. Fusion des donn√©es...")
trans_counts['account_id'] = trans_counts['account_id'].astype(int)
card_info['account_id'] = card_info['account_id'].astype(int)
df_analysis = pd.merge(trans_counts, card_info, on='account_id', how='inner')
print("   -> Donn√©es pr√™tes pour l'analyse.")


# --- √âTAPE 3: VISUALISATION ---
# (Le reste du code est inchang√© et devrait maintenant fonctionner)
print("\n4. Cr√©ation du graphique de comparaison...")
plt.figure(figsize=(10, 8))
sns.boxplot(data=df_analysis, x='card_type', y='nb_transactions', order=['junior', 'classic', 'gold'])
plt.title('Distribution du Nombre de Transactions par Type de Carte', fontsize=16)
plt.xlabel('Type de Carte', fontsize=12)
plt.ylabel('Nombre de Transactions', fontsize=12)
plt.grid(axis='y', linestyle='--')
#plt.savefig('transactions_par_type_carte.png')
plt.show()


# --- √âTAPE 5: TEST STATISTIQUE (KRUSKAL-WALLIS) ---
print("\n5. Ex√©cution du test statistique pour confirmer...")
try:
    # Pr√©parer les donn√©es pour le test
    gold_trans = df_analysis[df_analysis['card_type'] == 'gold']['nb_transactions']
    classic_trans = df_analysis[df_analysis['card_type'] == 'classic']['nb_transactions']
    junior_trans = df_analysis[df_analysis['card_type'] == 'junior']['nb_transactions']

    # Ex√©cuter le test
    stat, p_value = kruskal(gold_trans, classic_trans, junior_trans)

    print("\n--- Test de Kruskal-Wallis ---")
    print(f"Statistique H = {stat:.2f}")
    print(f"P-value = {p_value}")

    if p_value < 0.05:
        print("Conclusion : Il existe une diff√©rence statistiquement significative dans le nombre de transactions entre les diff√©rents types de cartes.")
    else:
        print("Conclusion : Il n'y a pas de diff√©rence statistiquement significative dans le nombre de transactions entre les diff√©rents types de cartes.")
except ValueError:
    print("Un ou plusieurs types de cartes n'ont pas de donn√©es de transaction, le test statistique ne peut √™tre effectu√©.")



"""#check des tables"""

df_account_clean = df_account_clean.drop(columns=['account_date_dt'])
df_card_clean = df_card_clean.drop(columns=['card_date_dt'])

#date_creation_compte =  df_trans_clean.drop(columns=['year',	'month'	,'day',	'periode'])

df_account_clean = df_account_clean.drop(columns=['date_creation_compte'])
df_card_clean = df_card_clean.drop(columns=['date_emission_carte'])

df_card_clean['has_card'] = 1

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy(), #pbt2:  ajout de type_compte_kmeans
account = df_account_clean.copy(), #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_card_clean.head()),
card = df_card_clean.copy(),  #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS m√™me si on devrait creuser les int√©rets sur la partie Power BI
#pbt compte : table compte, on ne garde pas anciennet√© (droppper)
#pbt loan : RAS
#pbt card : drop de colonnes ajouter par Gemini et des dates sur transaction

"""#**4 - Transaction**"""



"""##**interpolation**"""

from sklearn.preprocessing import LabelEncoder

# Copie du dataframe
df_interpolation = df_trans_clean.copy()


# df_interpolation['date'] = pd.to_datetime(df_['date'])
df_interpolation = df_interpolation.sort_values(by=['account_id', 'trans_date'])


df_interpolation['operation_clean'] = df_interpolation['operation'].replace("inconnu", pd.NA)


le = LabelEncoder()
known_ops = df_interpolation['operation_clean'].dropna()
le.fit(known_ops)


def encode_or_nan(val):
    if pd.isna(val):
        return np.nan
    return le.transform([val])[0]

df_interpolation['operation_encoded'] = df_interpolation['operation_clean'].apply(encode_or_nan)

# Interpolation
df_interpolation['operation_encoded_interp'] = (df_interpolation.groupby('account_id', group_keys=False)['operation_encoded']
                                                .apply(lambda x: x.interpolate(method='linear', limit_direction='both'))
)


df_interpolation['operation_interpolated'] = df_interpolation['operation_encoded_interp'].round().apply(lambda x: le.inverse_transform([int(x)])[0] if pd.notna(x) else "inconnu")

# V√©rification
df_interpolation[['account_id', 'trans_date', 'operation', 'operation_interpolated']].head(10)

df_interpolation.value_counts('operation_interpolated')

# Affichage des r√©sultats
operation_counts.head(6)

# Cr√©ation d'un graphique √† barres
plt.figure(figsize=(10, 6))
plt.bar(df_interpolation['operation_interpolated'].value_counts().index, df_interpolation['operation_interpolated'].value_counts().values)
plt.title("Types d'op√©rations bancaires les plus fr√©quents")
plt.xlabel("Type d'op√©ration")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=45)
plt.tight_layout()
plt.grid(axis='y')
plt.show()

df_interpolation.head()

df_trans_clean.shape

#Transformer df_interpolation en df_trans_clean propre
df_inter = df_interpolation[['trans_id', 'account_id', 'trans_date', 'trans_type',
       'trans_amount', 'trans_balance', 'order_type', 'bank_to',
       'order_account', 'type_compte_kmeans', 'year', 'month', 'day',
       'periode', 'operation_interpolated']]

df_inter = df_inter[['trans_id', 'account_id', 'trans_date', 'trans_type','operation_interpolated',
       'trans_amount', 'trans_balance', 'order_type', 'bank_to',
       'order_account', 'type_compte_kmeans', 'year', 'month', 'day',
       'periode']]

df_inter['operation'] = df_inter['operation_interpolated']

df_inter = df_inter[['trans_id', 'account_id', 'trans_date', 'trans_type','operation',
       'trans_amount', 'trans_balance', 'order_type', 'bank_to',
       'order_account', 'type_compte_kmeans', 'year', 'month', 'day',
       'periode']]
df_trans_clean = df_inter.copy()

df_trans_clean.head()

"""##**Jointure**"""

client_account_district_trans_KP = pd.merge(df_trans_clean, client_account_district, on='account_id', how='left')

"""##**1 - R√©partition par type de transaction**"""

import matplotlib.pyplot as plt

# V√©rifie que la colonne 'type' existe
if 'trans_type' in client_account_district_trans_KP.columns:
    plt.figure(figsize=(7,5))
    client_account_district_trans_KP['trans_type'].value_counts().plot(kind='bar', color='skyblue')
    plt.title("R√©partition par type de transaction")
    plt.xlabel("trans_type")
    plt.ylabel("Nombre de transactions")
    plt.xticks(rotation=45)
    plt.grid(axis='y')
    plt.tight_layout()
    plt.show()
else:
    print("Colonne 'type' non trouv√©e.")

"""##**2 - R√©partition par type d'op√©ration**"""

# V√©rifie que la colonne 'operation' existe
if 'operation' in client_account_district_trans_KP.columns:
    plt.figure(figsize=(9,5))
    client_account_district_trans_KP['operation'].value_counts(dropna=False).plot(kind='bar', color='lightcoral')
    plt.title("R√©partition par type d'op√©ration")
    plt.xlabel("Op√©ration")
    plt.ylabel("Nombre de transactions")
    plt.xticks(rotation=90)
    plt.grid(axis='y')
    plt.tight_layout()
    plt.show()
else:
    print("Colonne 'operation' non trouv√©e.")

"""##**3 - Volume total des montants par compte et type d'op√©ration / Moyenne des montants par compte et type d'op√©ration**
      
"""

# On s'assure que les colonnes n√©cessaires existent
required_cols = ['account_id', 'operation', 'trans_amount']
if all(col in client_account_district_trans_KP.columns for col in required_cols):

    # 1. Volume total des montants par compte et type d'op√©ration
    volume_total = client_account_district_trans_KP.groupby(['account_id', 'operation'])['trans_amount'].sum().reset_index()
    volume_total.rename(columns={'trans_amount': 'total_amount'}, inplace=True)

    # 2. Moyenne des montants par compte et type d'op√©ration
    moyenne_montant = client_account_district_trans_KP.groupby(['account_id', 'operation'])['trans_amount'].mean().reset_index()
    moyenne_montant.rename(columns={'trans_amount': 'mean_amount'}, inplace=True)

    # Fusion des deux tableaux
    resume_trans = pd.merge(volume_total, moyenne_montant, on=['account_id', 'operation'])

    # Affichage classique
    resume_trans.head()  # ou .to_csv("resume_trans.csv") pour sauvegarder

else:
    print("Colonnes n√©cessaires manquantes :", [col for col in required_cols if col not in client_account_district_trans_KP.columns])

resume_trans  # ou .to_csv("resume_trans.csv") pour sauvegarder

import matplotlib.pyplot as plt

# On agr√®ge les donn√©es globalement par type d'op√©ration (tous comptes confondus)
agg_by_operation = resume_trans.groupby('operation').agg({
    'total_amount': 'sum',
    'mean_amount': 'mean'
}).sort_values(by='total_amount', ascending=False)

# S√©lection des 10 op√©rations les plus significatives
top_ops = agg_by_operation#.head(10)

# Trac√© du volume total cumul√©
plt.figure(figsize=(10, 5))
top_ops['total_amount'].plot(kind='bar', color='cornflowerblue')
plt.title("Op√©rations par montant total cumul√©")
plt.xlabel("Type d'op√©ration")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Trac√© du montant moyen
plt.figure(figsize=(10, 5))
top_ops['mean_amount'].plot(kind='bar', color='orange')
plt.title("Op√©rations par montant moyen")
plt.xlabel("Type d'op√©ration")
plt.ylabel("Montant moyen (CZK)")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""##**4 - Volume total par compte et type d'op√©ration**"""

# üìä 1. Volume total par compte et type d'op√©ration

import matplotlib.pyplot as plt

# On prend les 10 comptes les plus actifs par volume total (somme) toutes op√©rations confondues
top_comptes_volume = resume_trans.groupby('account_id')['total_amount'].sum().nlargest(5).index

# On filtre les lignes concern√©es
volume_top_accounts = resume_trans[resume_trans['account_id'].isin(top_comptes_volume)]

# Graphe
plt.figure(figsize=(12,6))
for compte in top_comptes_volume:
    subset = volume_top_accounts[volume_top_accounts['account_id'] == compte]
    plt.plot(subset['operation'], subset['total_amount'], marker='o', label=f'Compte {compte}')

plt.title("üìä Volume total par compte et type d'op√©ration (Top 5 comptes)")
plt.xlabel("Type d'op√©ration")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.grid(True)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# ordre des colonnes pour qu‚Äôelles soient toujours dans le m√™me sens
ordre_ops = ['depot en especes',
             'retrait en especes',
             'retrait par carte',
             'virement entrant',
             'virement sortant']

plt.figure(figsize=(12,6))
sns.barplot(data=volume_top_accounts,
            x='operation',
            y='total_amount',
            hue='account_id',
            order=ordre_ops)

plt.title("Volume total (CZK) par type d'op√©ration ‚Äì Top 5 comptes")
plt.xlabel("")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.04,1), loc='upper left')
plt.tight_layout()
plt.show()



# üìà 2. Montant moyen par compte et type d'op√©ration

# On prend les 10 comptes ayant les plus gros montants moyens cumul√©s (sur toutes op√©rations)
top_comptes_moyenne = resume_trans.groupby('account_id')['mean_amount'].mean().nlargest(5).index

# On filtre
mean_top_accounts = resume_trans[resume_trans['account_id'].isin(top_comptes_moyenne)]

# Graphe
plt.figure(figsize=(12,6))
for compte in top_comptes_moyenne:
    subset = mean_top_accounts[mean_top_accounts['account_id'] == compte]
    plt.plot(subset['operation'], subset['mean_amount'], marker='o', label=f'Compte {compte}')

plt.title("üìà Montant moyen par compte et type d'op√©ration (Top 5 comptes)")
plt.xlabel("Type d'op√©ration")
plt.ylabel("Montant moyen (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.grid(True)
plt.show()

plt.figure(figsize=(12,6))
sns.barplot(data=mean_top_accounts,
            x='operation',
            y='mean_amount',
            hue='account_id')

plt.title("Montant moyen (CZK) ‚Äì Top 5 comptes, par type d'op√©ration")
plt.xlabel("")
plt.ylabel("Montant moyen (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.04,1), loc='upper left')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# V√©rifie et convertit la colonne date si besoin
if 'trans_date' not in client_account_district_trans_KP.columns and 'date' in client_account_district_trans_KP.columns:
    client_account_district_trans_KP.rename(columns={'date': 'trans_date'}, inplace=True)

client_account_district_trans_KP['trans_date'] = pd.to_datetime(client_account_district_trans_KP['trans_date'], errors='coerce')

# Regroupement mensuel
client_account_district_trans_KP['month_x'] = client_account_district_trans_KP['trans_date'].dt.to_period('M').astype(str)

monthly_stats = client_account_district_trans_KP.groupby('month_x').agg({
    'trans_amount': ['count', 'sum']
}).reset_index()

monthly_stats.columns = ['month_x', 'transaction_count', 'transaction_sum']

# Visualisation
plt.figure(figsize=(12,5))
plt.plot(monthly_stats['month_x'], monthly_stats['transaction_count'], marker='o', label='Nombre de transactions')
plt.title("üìà √âvolution du nombre de transactions par mois")
plt.xlabel("Mois")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=90)
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,5))
plt.plot(monthly_stats['month_x'], monthly_stats['transaction_sum'], marker='o', color='green', label='Montant total')
plt.title("üí∞ √âvolution du montant total des transactions par mois")
plt.xlabel("Mois")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=90)
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# V√©rifie et convertit la colonne date si besoin
if 'trans_date' not in client_account_district_trans_KP.columns and 'date' in client_account_district_trans_KP.columns:
    client_account_district_trans_KP.rename(columns={'date': 'trans_date'}, inplace=True)

client_account_district_trans_KP['trans_date'] = pd.to_datetime(client_account_district_trans_KP['trans_date'], errors='coerce')

# Regroupement mensuel
client_account_district_trans_KP['year_x'] = client_account_district_trans_KP['trans_date'].dt.to_period('Y').astype(str)

monthly_stats = client_account_district_trans_KP.groupby('year_x').agg({
    'trans_amount': ['count', 'sum']
}).reset_index()

monthly_stats.columns = ['year_x', 'transaction_count', 'transaction_sum']

# Visualisation
plt.figure(figsize=(12,5))
plt.plot(monthly_stats['year_x'], monthly_stats['transaction_count'], marker='o', label='Nombre de transactions')
plt.title("üìà √âvolution du nombre de transactions par an")
plt.xlabel("Ann√©e")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,5))
plt.plot(monthly_stats['year_x'], monthly_stats['transaction_sum'], marker='o', color='green', label='Montant total')
plt.title("üí∞ √âvolution du montant total des transactions par an")
plt.xlabel("Ann√©e")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

"""##**5 - √âvolution des types d'op√©rations bancaires (jusqu'√† 1999)**"""

import pandas as pd
import matplotlib.pyplot as plt


# V√©rifie si la colonne 'type' existe
if 'trans_type' not in df_trans_clean.columns:
    print("‚ùå Erreur : colonne 'type' absente du fichier.")
else:
    # Groupe par mois et type
    grouped = df_trans_clean.groupby(['periode', 'operation']).size().reset_index(name='count')

    # Tableau pivot pour les courbes
    pivoted = grouped.pivot(index='periode', columns='operation', values='count').fillna(0)

    # Trac√©
    pivoted.plot(
    figsize=(14, 8),  #<-- LA CORRECTION EST ICI (ex: 18 de large, 8 de haut)
    marker='o',
    linestyle='--'
    )
    #plt.figure(figsize=(14, 6))
    #pivoted.plot(marker='o')
    plt.title("üìà √âvolution des types d'op√©rations bancaires (jusqu'√† 1999)")
    plt.xlabel("Mois")
    plt.ylabel("Nombre d'op√©rations")
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.tight_layout()
    plt.legend(title="Type d'op√©ration")
    plt.show()

"""#check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy(), #pbt2:  ajout de type_compte_kmeans
#account = df_account_clean.copy(), #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_card_clean.head()),
#card = df_card_clean.copy(),  #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans
#transaction = df_trans_clean.copy() #pbt transaction: remplacer les inconnus par des valeurs sur la colonne Operation

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS m√™me si on devrait creuser les int√©rets sur la partie Power BI
#pbt compte : table compte, on ne garde pas anciennet√© (droppper)
#pbt loan : RAS
#pbt card : drop de colonnes ajouter par Gemini et des dates sur transaction

#v√©rification
#df_trans_clean['operation'].value_counts(dropna = False)

"""#**5 - Client Solvabilit√©**

###**Jointure**
"""

df_client_disp = pd.merge(df_client_clean, df_disposition_clean, on='client_id', how='left')
df_client_account = pd.merge(df_client_disp, df_account_clean, on='account_id', how='left')
df_client_loan = pd.merge(df_client_account, df_loan_clean, on='account_id', how='left')
df_full = pd.merge(df_client_loan, df_district_clean, left_on='district_id_x', right_on='district_id', how='left')



import pandas as pd
from datetime import date
# MAPPING : client  ‚Üí  account
df_client_disp = (df_disposition_clean
                  .merge(df_client_clean, on='client_id', how='left'))

df_client_account = (df_client_disp
                     .merge(df_account_clean, on='account_id', how='left'))

# PR√äTS  (1 max par compte)

df_loan_flag = df_loan_clean.rename(columns={'amount': 'loan_amount',
                                             'duration': 'loan_duration',
                                             'payments': 'loan_pmt'})
df_client_loan = df_client_account.merge(df_loan_flag,
                                         on='account_id', how='left')

# AGR√âGATS TRANSACTIONS

# solde moyen
trans = df_trans_clean.copy()
trans['trans_balance'] = trans['trans_balance'].astype(float)
avg_bal = (trans.groupby('account_id')['trans_balance']
                 .mean().reset_index(name='avg_balance'))

# ¬´ incidents ¬ª de tr√©sorerie : retraits, paiements, d√©couverts
mask_inc = trans['operation'].str.contains(
              'withdraw|collect|remit|credit card',
              case=False, na=False)

incidents = (trans[mask_inc]
             .groupby('account_id')
             .size()
             .reset_index(name='nb_incidents'))
for df in [df_client_loan, avg_bal, incidents]:
    df['account_id'] = df['account_id'].astype(str)


# fusion agr√©gats
df_client_tx = (df_client_loan
                .merge(avg_bal, on='account_id', how='left')
                .merge(incidents, on='account_id', how='left'))

df_client_tx['avg_balance'].fillna(0, inplace=True)
df_client_tx['nb_incidents'].fillna(0, inplace=True)


# 4.  VARIABLES DE SOLVABILIT√â

# flags pr√™ts / cartes
df_client_tx['has_loan'] = df_client_tx['loan_amount'].notna().astype(int)

# ratio mensualit√© / solde moyen (√©vite division par 0)
df_client_tx['loan_monthly_ratio'] = (
    df_client_tx['loan_payments'] /
    df_client_tx['avg_balance'].replace(0, pd.NA)
).fillna(0)

# seuils data-driven (percentiles)
ratio_p75     = df_client_tx['loan_monthly_ratio'].quantile(0.75)
incident_p75  = df_client_tx['nb_incidents'].quantile(0.75)

df_client_tx['solvable'] = (
      (df_client_tx['loan_monthly_ratio'] < ratio_p75)
    & (df_client_tx['nb_incidents']       < incident_p75)
).astype(int)

#  AGR√âGATION PAR CLIENT
df_solv = (df_client_tx
           .groupby('client_id')
           .agg(has_loan          = ('has_loan', 'max'),
                loan_amount_sum  = ('loan_amount', 'sum'),
                loan_monthly_ratio= ('loan_monthly_ratio', 'mean'),
                avg_balance       = ('avg_balance', 'mean'),
                nb_incidents      = ('nb_incidents', 'sum'),
                solvable          = ('solvable', 'max'))
           .reset_index())



# Calculer le 75e percentile SANS les z√©ros
ratio_p75 = (df_solv['loan_monthly_ratio']
             .loc[lambda s: s > 0]
             .quantile(0.75))

# Si tout est √† 0 ‚Üí on force un epsilon, ex. 0.01
if pd.isna(ratio_p75) or ratio_p75 == 0:
    ratio_p75 = 0.01

# Construire les bornes, puis supprimer les doublons √©ventuels
bins = pd.unique([-float('inf'), ratio_p75/2, ratio_p75, float('inf')])

# Adapter la liste de labels au nombre de classes (len(bins)-1)
labels = ['Solvable (A)', 'Vigilance (B)', 'Risque (C)'][:len(bins)-1]

# D√©couper
df_solv['segment_solvabilit√©'] = pd.cut(
    df_solv['loan_monthly_ratio'],
    bins=bins,
    labels=labels,
    duplicates='drop'
)

# R√âSULTAT
df_solv['segment_solvabilit√©'].value_counts(dropna=False)
df_solv

df_solv['segment_solvabilit√©'].value_counts()

"""##**interpretation de la solvabilit√©**"""

# # | Segment           | R√®gle (rappel)                                          |  Effectif | Part du portefeuille | Lecture terrain                                                                                                      |
# # | ----------------- | ------------------------------------------------------- | --------: | -------------------: | -------------------------------------------------------------------------------------------------------------------- |
# # | **Solvable (A)**  | mensualit√© / solde moyen < ¬Ω P75 **ET** incidents < P75 | **4 777** |           **‚âà 89 %** | Client√®le globalement saine : capacit√© de remboursement confortable ; incidents de tr√©sorerie inf√©rieurs √† la norme. |
# # | **Vigilance (B)** | ¬Ω P75 ‚â§ ratio < P75 **OU/ET** incidents proches P75     |   **386** |                ‚âà 7 % | Situation correcte mais marge de man≈ìuvre plus faible ; suivi prudent, proposer conseils budg√©taires.                |
# # | **Risque (C)**    | ratio ‚â• P75 **OU** incidents ‚â• P75                      |   **206** |                ‚âà 4 % | Tension de tr√©sorerie √©lev√©e ; potentiel d√©faut en cas de choc. Priorit√© : restructuration ou garanties.             |

# # ********Total clients analys√©s : 5 369.

# 1. Ce que cela dit de votre portefeuille
# Structure tr√®s favorable : pr√®s de 9 clients sur 10 sont dans la zone verte (A).

# Risque concentr√© : 4 % (¬´ C ¬ª) suffisent toutefois √† entra√Æner des pertes si les encours sont √©lev√©s ; ces clients m√©ritent un suivi individualis√©.

# Les clients ¬´ B ¬ª forment une zone tampon : ils ne posent pas encore probl√®me mais peuvent basculer vers ¬´ C ¬ª en cas d‚Äôaugmentation des taux ou perte de revenus.

"""##**visualistaion**"""

import matplotlib.pyplot as plt

# Data for the solvency segments
labels = ['Solvable (A)', 'Vigilance (B)', 'Risque (C)']
sizes = [4777, 386, 206]

# Create the pie chart
fig, ax = plt.subplots(figsize=(5, 5))
ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=45)
ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('R√©partition des segments de solvabilit√©')

plt.show()

client_solv = pd.merge(df_client_clean, df_solv, how = 'left', on = 'client_id')
client_solv

client_solv = client_solv[['client_id', 'district_id', 'birth_date', 'gender', 'age','tranche_age',
  'has_loan', 'loan_amount_sum', 'loan_monthly_ratio',
  'segment_solvabilit√©']]
client_solv

#v√©rification
#df_trans_clean['operation'].value_counts(dropna = False)

df_card_clean.head()

# jointure client avec loan et card
client_disp = pd.merge(df_client_clean, df_disposition_clean, on='client_id', how='left')
client_loan= pd.merge(client_disp, df_loan_clean, on='account_id', how='left')
client_card = pd.merge(client_loan, df_card_clean, on='disp_id', how='left')
client_card['has_card'] = client_card['card_id'].notna().astype(int)
client_card['has_loan'] = client_card['has_loan'].notna().astype(int)
client_card['has_account'] = client_card['disp_role'].replace({'OWNER': 1, 'DISPONENT': 0})
client_card.columns

client_card = client_card[['client_id', 'district_id', 'birth_date', 'gender', 'age',
       'tranche_age', 'has_account','has_loan', 'has_card']]

client_card

"""#**Analyse Sup**"""

# Fusion client ‚Üî disposition ‚Üî compte
df_disp_client = df_disposition_clean.merge(client_card, on='client_id', how='left')
df_account_client = df_disp_client.merge(df_account_clean, on='account_id', how='left')
df_account_client

#df_owner = df_account_client[df_account_client['disp_role'] == 'OWNER']
#df_account_client.head()

df_owner = df_account_client.merge(df_solv, on='client_id', how='left')
df_owner

colonnes_a_supprimer = [
    'has_loan_y',
    'loan_amount_sum',
    'loan_monthly_ratio',
    'avg_balance',
    'nb_incidents',
    'solvable',
    'district_id_y'
]

df_owner.drop(columns=colonnes_a_supprimer, inplace=True)

df_owner

df_client_final = df_owner.copy()
df_client_clean = df_client_final.copy()

"""#check des tables"""

df_client_clean = client_card.copy()

df_account_clean

display(df_loan_clean.head())
loan = df_loan_clean.copy() #pbt2: ajout de has_loan

display(df_client_clean.head())
client = df_client_clean.copy() # pbt1 ajout des tranches d'age
#client = df_client_clean.copy() # pbt solvabilite : ajout has_account, loan et card


display(df_account_clean.head())
account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans
#account = df_account_clean.copy(), #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_card_clean.head())
card = df_card_clean.copy()  #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_disposition_clean.head())
disposition = df_disposition_clean.copy()


display(df_district_clean.head())
district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head())
order = df_order_clean.copy()


display(df_trans_clean.head())
transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans
#transaction = df_trans_clean.copy() #pbt transaction: remplacer les inconnus par des valeurs sur la colonne Operation

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais √†re checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS m√™me si on devrait creuser les int√©rets sur la partie Power BI
#pbt compte : table compte, on ne garde pas anciennet√© (droppper)
#pbt loan : RAS
#pbt card : drop de colonnes ajouter par Gemini et des dates sur transaction

#type(df_account_clean)
df_client_clean

"""#**Exportation des donn√©es**"""

# client.to_csv("client_final.csv", index=False)

# client.to_csv("client_final.csv", index=False)
# account.to_csv("account_final.csv", index=False)
# transaction.to_csv("transaction_final.csv", index=False)
# loan.to_csv("loan_final.csv", index=False)
# card.to_csv("card_final.csv", index=False)
# order.to_csv("order_final.csv", index=False)
# district.to_csv("district_final.csv", index=False)
# disposition.to_csv("disposition_final.csv", index=False)

df_client_final



"""#Order Permanent"""

order_account = pd.merge(df_account_clean, df_order_clean, on='account_id', how='left')
order_account

df_order_clean.shape

df_account_clean.shape

account_order = pd.merge(df_account_clean, df_order_clean, on='account_id', how='inner')
account_order

account_order['order_type'].value_counts(dropna = False)

#group√© par account_id
account_ = account_order.groupby(['account_id', 'order_type']).size().reset_index(name='count')
account_

group = account_order.groupby('account_id')['order_amount'].sum()
group

