# -*- coding: utf-8 -*-
"""the_berka_bank_DB_2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JaHOcIn9mlPc-qEPkgQ2cnJ-ua6kwg0P
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import chi2_contingency

df_loan = pd.read_csv("/content/loan.csv", sep=';')
df_client = pd.read_csv("/content/client.csv", sep=';')
df_account = pd.read_csv("/content/account.csv", sep=';')
df_card = pd.read_csv("/content/card.csv", sep=';')
df_disposition = pd.read_csv("/content/disp.csv", sep=';')
df_district = pd.read_csv("/content/district.csv", sep=';')
df_order = pd.read_csv("/content/order.csv", sep=';')
df_trans = pd.read_csv("/content/trans.csv", sep=';')

# cellule de test
df_trans = pd.read_csv("/content/trans.csv", sep=';')

pd.set_option('display.max_columns', 500)

"""#**Data Cleaning**

##**1- description de la table loan**
"""

df_loan.head()

df_loan["status"].value_counts()#(normalize=True)
# A : Prêt en cours de remboursement (actif).
# B : Prêt en défaut de paiement (défaut).
# C : Prêt remboursé intégralement (clos).
# D : Prêt restructuré ou en cours en recouvrement

# | `loan_id`             | Integer       | Identifiant unique du prêt. Clé primaire de la table.                                                                                                                                                      |
# | `account_id`          | Integer       | Identifiant du compte lié au prêt. Clé étrangère vers la table `account`. Permet de relier le prêt au client concerné.                                                                                     |
# | `date`                | Date          | Date d'octroi du prêt (format AAAA-MM-JJ).                                                                                                                                                                 |
# | `amount`              | Float/Integer | Montant total du prêt accordé (en couronnes tchèques).                                                                                                                                                     |
# | `duration`            | Integer       | Durée du prêt, exprimée en **mois**.                                                                                                                                                                       |
# | `payments`            | Float         | Montant **mensuel** à rembourser (valeur fixe).                                                                                                                                                            |
# | `status`              | Categorical   | Statut actuel du prêt. Généralement codé par une lettre :
# | `A` = actif (en cours de remboursement) `B` = en défaut (impayé) `C` = remboursé `D` = litige ou restructuré (moins courant) |

# aperçu
print(df_loan.shape)
print("_______________")
print(df_loan.columns)
print("_______________")
print(df_loan.info())

df_loan.describe()

status_mapping = {
    'A': 'actif',       # en cours de remboursement
    'B': 'défaut',      # en défaut de paiement
    'C': 'remboursé',   # prêt terminé
    'D': 'litige'       # autre situation (rare)
}
df_loan['status'] = df_loan['status'].map(status_mapping)
df_loan.head()

df_loan['date'] = pd.to_datetime(df_loan['date'], format='%y%m%d', errors='coerce')
df_loan

df_loan['loan_id'] = df_loan['loan_id'].astype(str)
df_loan['account_id'] = df_loan['account_id'].astype(str)
df_loan.info()

print(df_loan.isnull().sum())

print(df_loan.duplicated().sum())

df_loan['status'].value_counts(normalize=True)

# renommé les colonnes
df_loan.rename(columns={
    'amount': 'loan_amount',
    'duration': 'loan_duration',
    'payments': 'loan_payments',
    'status': 'loan_status',
    'date': 'loan_date'
}, inplace=True)

df_loan_clean = df_loan.copy()
df_loan_clean

"""##**2 - description de la table client**



"""

df_client.head()

# aperçu
print(df_client.shape)
print("_______________")
print(df_client.columns)
print("_______________")
print(df_client.info())

df_client.describe()

# | `client_id`     Identifiant unique du client. Clé primaire. Sert à relier le client aux autres tables (`disposition`, `card`, etc.).                                                                      |
# | `birth_number`  Encodage de la **date de naissance** et du **sexe** :<br>→ Format `YYMMDD`<br>→ Si le mois est > 50, il s'agit d'une femme (ex. 536123 = 16 mars 1953, femme)<br>→ Sinon, c’est un homme. |
# | `district_id`   Identifiant du **district** de résidence du client. Clé étrangère vers la table `district`, qui contient les données socio-économiques de la zone.                                        |

def decode_birth_number(birth_number):
    # S'assure que c'est bien une chaîne de 6 chiffres
    birth_str = str(birth_number).zfill(6)
    year = int(birth_str[:2])
    month = int(birth_str[2:4])
    day = int(birth_str[4:6])

    gender = 'F' if month > 50 else 'M'
    if month > 50:
        month -= 50

    # Gestion du siècle (à adapter si besoin)
    year += 1900

    return pd.to_datetime(f"{year}-{month:02d}-{day:02d}"), gender

# Exemple d’utilisation sur un DataFrame
df_client['birth_date'], df_client['gender'] = zip(*df_client['birth_number'].apply(decode_birth_number))
df_client.head()

df_client['age'] = 1998 - df_client['birth_date'].dt.year

df_client.drop(columns='birth_number', inplace=True)

df_client['client_id'] = df_client['client_id'].astype(str)
df_client['district_id'] = df_client['district_id'].astype(str)
df_client.head()

df_client.isnull().sum()

df_client.duplicated().sum()

df_client['district_id'].nunique()

df_client_clean = df_client.copy()

df_client_clean

df_client_clean.describe()

"""##**3 - description de la table account**

"""

df_account.head()

# | `account_id`           Identifiant unique du compte bancaire.                                                                             |
# | `district_id`          Identifiant du district où le compte est domicilié.                                                                                                   |
# | `frequency`            Fréquence d’envoi des relevés bancaires au titulaire du compte.
# | `date`                 Date d’ouverture du compte bancaire.                                                                                                                                   |

# aperçu
print(df_account.shape)
print("_______________")
print(df_account.columns)
print("_______________")
print(df_account.info())

df_account.describe()

df_account['date'] = pd.to_datetime(df_account['date'], format='%y%m%d', errors='coerce')

df_account['frequency'].unique()
#`'POPLATEK MESICNE'` → mensuel
#'POPLATEK TYDNE'` → hebdomadaire
#'POPLATEK PO OBRATU'` → après transaction

freq_map = {
    'POPLATEK MESICNE': 'mensuel',
    'POPLATEK TYDNE': 'hebdomadaire',
    'POPLATEK PO OBRATU': 'après transaction'
}

df_account['frequency'] = df_account['frequency'].map(freq_map)

df_account.isna().sum()

df_account.drop_duplicates(inplace=True)
df_account.duplicated().sum()

df_account['account_id'] = df_account['account_id'].astype(str)
df_account['district_id'] = df_account['district_id'].astype(str)
df_account.head()

df_account['frequency'].value_counts()

# renommé les colonnes
df_account.rename(columns={
    'date': 'account_date',
    'frequency': 'sending_frequency'
}, inplace=True)

df_account

df_account_clean = df_account.copy()

df_account_clean.describe()

"""##**4 - description de la table card**"""

df_card.head()

# | `card_id`              Identifiant unique de la carte.                                                                                                               |
# | `disp_id`              Identifiant de la **relation client-compte** Permet de relier la carte à un client précis et à son compte.                  |
# | `type`                 Type de carte bancaire.
# | `issued`               Date d’émission de la carte

# aperçu
print(df_card.shape)
print("_______________")
print(df_card.columns)
print("_______________")
print(df_card.info())

df_card.describe()

def fix_date(d):
    if pd.isna(d):
        return pd.NaT
    d = pd.to_datetime(str(d)[:6], format="%y%m%d", errors='coerce')
    # Corrige les années supérieures à 2025 en les ramenant au XXe siècle
    if d and d.year > 2000:
        d = d.replace(year=d.year - 100)
    return d

df_card['issued'] = df_card['issued'].apply(fix_date)

df_card['card_id'] = df_card['card_id'].astype(str)
df_card['disp_id'] = df_card['disp_id'].astype(str)
df_card.head()

df_card['type'].unique()

df_card.rename(columns={
    'type': 'card_type',
    'issued': 'card_date'
}, inplace=True)

df_card_clean = df_card.copy()

df_card_clean

df_card_clean.describe()

"""##**5 - description de la table disp**

"""

df_disposition.head()

df_disposition.info()

df_disposition['type'].unique()
#  'OWNER' → le client est le titulaire du compte
#  'DISPONENT' → le client est un utilisateur (ex. mandataire, conjoint)

df_disposition['type'].value_counts()

df_disposition['disp_id'] = df_disposition['disp_id'].astype(str)
df_disposition['client_id'] = df_disposition['client_id'].astype(str)
df_disposition['account_id'] = df_disposition['account_id'].astype(str)
df_disposition

# renommé les colonnes
df_disposition.rename(columns={
    'type': 'disp_role'
}, inplace=True)

df_disposition_clean = df_disposition.copy()
df_disposition_clean

"""
##**6 - description de la table district (région)**"""

df_district.head()

# Renommage des colonnes avec des noms plus parlants
df_district.rename(columns={
    'A1': 'district_id',
    'A2': 'district_name',
    'A3': 'region',
    'A4': 'nb_inhabitants',
    'A5': 'municipalities_lt_499',
    'A6': 'municipalities_500_1999',
    'A7': 'municipalities_2000_9999',
    'A8': 'municipalities_gt_10000',
    'A9': 'nb_cities',
    'A10': 'urban_ratio',
    'A11': 'average_salary',
    'A12': 'unemployment_1995',
    'A13': 'unemployment_1996',
    'A14': 'entrepreneurs_par_1000',
    'A15': 'crimes_1995',
    'A16': 'crimes_1996'
}, inplace=True)

# district_id : Identifiant unique du district.
# district_name : Nom du district.
# region : Région administrative.
# nb_inhabitants : Nombre d'habitants.
# municipalities_lt_499 : Nombre de municipalités avec moins de 499 habitants.
# municipalities_500_1999 : Nombre de municipalités avec 500 à 1999 habitants.
# municipalities_2000_9999 : Nombre de municipalités avec 2000 à 9999 habitants.
# municipalities_gt_10000 : Nombre de municipalités avec plus de 10000 habitants.
# nb_cities : Nombre de villes.
# urban_ratio : Proportion d'habitants urbains.
# average_salary : Salaire moyen dans le district.
# unemployment_1995 : Taux de chômage en 1995.
# unemployment_1995 : Taux de chômage en 1996.
# entrepreneurs_par_1000 : nb d'entrepreneurs par 1000 habitants
# crimes_1995 : Nombre de crimes commis en 1995.
# crimes_1995 : Nombre de crimes commis en 1996.

df_district.info()

df_district['unemployment_1995'].unique()

df_district['crimes_1995'].unique()

df_district['unemployment_1995'] = df_district['unemployment_1995'].replace('?', np.nan)
df_district['crimes_1995'] = df_district['crimes_1995'].replace('?', np.nan)

df_district['district_id'] = df_district['district_id'].astype(str)
df_district['unemployment_1995'] = df_district['unemployment_1995'].astype(float)
df_district['crimes_1996'] = df_district['crimes_1996'].astype(float)
df_district['crimes_1995'] = df_district['crimes_1995'].astype(float)

df_district.head()

df_district.isnull().sum()

mean_value = df_district['unemployment_1995'].mean()
mean_valuee = df_district['crimes_1995'].mean()
df_district['unemployment_1995'].fillna(mean_value, inplace=True)
df_district['crimes_1995'].fillna(mean_valuee, inplace=True)

df_district.describe()

df_district.isnull().sum()

df_district.duplicated().sum()

df_district.info()

df_district['district_name'].unique()

df_district_clean = df_district.copy()

df_district_clean

"""


##**7 - description de la table order**"""

df_order.head()



#  `order_id`             Identifiant unique de l’ordre permanent.
#  `account_id`           Identifiant du compte émetteur de l’ordre.
#  `bank_to`              Code de la banque du bénéficiaire du virement
#  `account_to`           Numéro du compte du bénéficiaire.
#  `amount`               Montant envoyé à chaque exécution de l’ordre permanent
#  `k_symbol`             Code de signification du virement.

df_order.info()

df_order.describe()

df_order.shape



k_symbol_map = {
    'SIPO': 'paiement groupé (SIPO)',
    'UVER': 'remboursement de prêt',
    'POJISTNE': 'assurance',
    'LEASING': 'leasing',
    'SLUZBY': 'services',
    'DUCHOD': 'retraite',
    'SANKC. UROK': 'intérêts de pénalité',
    'UROK': 'intérêts créditeurs'

}

df_order['k_symbol'] = df_order['k_symbol'].map(k_symbol_map).fillna('inconnu')
df_order.head()

df_order['account_id'] = df_order['account_id'].astype(str)
df_order['order_id'] = df_order['order_id'].astype(str)
df_order['account_to'] = df_order['account_to'].astype(str)
df_order.head()

df_order['k_symbol'].unique()
#'POJISTNE' → assurance
#'LEASING' → location / leasing
#'UVER' → remboursement de prêt
# 'SIPO' → Paiement groupé de factures courantes
# ' ' → NAN

#df_order['k_symbol'] = df_order['k_symbol'].fillna('inconnu')

df_order.isnull().sum()

df_order.duplicated().sum()

df_order['bank_to'].unique()
#Ces codes sont fictifs et anonymisés dans le dataset à des fins de protection des données.

df_order['bank_to'].value_counts()

df_order.rename(columns={
    'amount': 'order_amount',
    'k_symbol' : 'order_type'
}, inplace=True)

df_order_clean = df_order.copy()
df_order_clean

df_order_clean.groupby('bank_to').count

df_order_clean['order_type'].value_counts()

"""##**8 - description de la table transaction**"""

df_trans.head()

# | **`trans_id`**    Identifiant unique de la transaction.                                  |
# | **`account_id`**  Référence au **compte bancaire** concerné par la transaction     |
# | **`date`**        Date de la transaction
# | **`type`**        Type général de la transaction
# | **operation**     Détail du type d’opération
# | **amount**        Montant de la transaction (en couronnes tchèques). |
# | **balance**       Solde du compte après la transaction. |
# | **k_symbol**      Catégorie du paiement. Valeurs possibles
# | **bank**          Code de la banque de l’autre partie (comme dans bank_to dans order).
# | **account**       Numéro de compte du bénéficiaire ou de l’expéditeur.

# important
# | Elles sont simplement vides (NaN) dans certaines lignes, notamment pour les retraits ou dépôts manuels sans contrepartie externe.

df_trans.info()

df_trans.shape

df_trans.describe()

df_trans['type'].unique()
# 'PRIJEM' → crédit (entrée d’argent)
# 'VYDAJ' → débit (sortie d’argent)
# 'VYBER' → retrait (par le client)

type_map = {
    'PRIJEM': 'credit',
    'VYDAJ': 'debit',
    'VYBER': 'retrait'
}
df_trans['type'] = df_trans['type'].map(type_map)

df_trans['operation'].unique()
#'VKLAD' → dépôt en espèces
#'PREVOD Z UCTU' → virement entrant
#'VYBER' → retrait standard
#'PREVOD NA UCET' → virement sortant
#'VYBER KARTOU' → retrait par carte

df_trans['k_symbol'].unique()
#'SIPO' → Paiement groupé de factures courantes
#'UVER' → remboursement de prêt
#' ' → Vide
#'POJISTNE' → assurance
#'LEASING' → location / leasing
#'SLUZBY' →  Paiements pour des services divers
#'SANKC. UROK'  →  	Intérêts de pénalité
#'UROK' → Paiement d’intérêts versés au client par la banque
#'DUCHOD' → une pension ou une retraite mensuelle.

df_trans['k_symbol'] = df_trans['k_symbol'].str.strip().replace('', None)

k_symbol_map = {
    'SIPO': 'paiement groupe',
    'UVER': 'remboursement pret',
    'POJISTNE': 'assurance',
    'LEASING': 'leasing',
    'SLUZBY': 'services',
    'DUCHOD': 'retraite',
    'SANKC. UROK': 'intérets penalite',
    'UROK': 'interets crediteurs',
    None: 'inconnu'
}

df_trans['k_symbol'] = df_trans['k_symbol'].map(k_symbol_map).fillna('inconnu')

df_trans['k_symbol'].unique()

operation_map = {
    'VYBER KARTOU': 'retrait par carte',
    'VKLAD': 'depot en especes',
    'PREVOD Z UCTU': 'virement entrant',
    'PREVOD NA UCET': 'virement sortant',
    'SANKC. UROK': 'interets de penalite',
    'UROK': 'interets crediteurs',
    'VYBER': 'retrait en especes',
    ' ': 'inconnu',
    None: 'inconnu'
}
# nous décidons de traiter les ' ' en NAN


# Nettoyage des espaces superflus
df_trans['operation'] = df_trans['operation'].str.strip()

# Remplacement
df_trans['operation'] = df_trans['operation'].replace(operation_map)

df_trans['date'] = pd.to_datetime(df_trans['date'], format='%y%m%d', errors='coerce')

df_trans.info()

df_trans['account_id'] = df_trans['account_id'].astype(str)
df_trans['trans_id'] = df_trans['trans_id'].astype(str)
df_trans['account'] = df_trans['account'].astype(str)
df_trans.head()

df_trans.isnull().sum()

df_trans['bank'] = df_trans['bank'].fillna('inconnu')
df_trans['account'] = df_trans['account'].fillna('inconnu')
df_trans['account'] = df_trans['account'].replace({"nan": "inconnu"})

df_trans.isnull().sum()

df_trans.duplicated().sum()

df_trans.head()

df_trans.info()

#Colonnes
df_trans.rename(columns={
    'date': 'trans_date',
    'type' : 'trans_type',
    'amount' : 'trans_amount',
    'balance' : 'trans_balance',
    'k_symbol' : 'order_type',
    'bank' : 'bank_to',
    'account' : 'order_account'
}, inplace=True)

df_trans_clean = df_trans.copy()
df_trans_clean

"""#**Outliers**"""

import pandas as pd
import matplotlib.pyplot as plt


dfs = {
    'loan'     : df_loan_clean,
    'account'  : df_account_clean,
    'card'     : df_card_clean,
    'trans'    : df_trans_clean,
    'client'   : df_client_clean,
    'district' : df_district_clean,
    'order'    : df_order_clean,
}


outlier_stats = []

for tbl_name, df in dfs.items():
    numeric_cols = df.select_dtypes(include='number').columns

    for col in numeric_cols:
        plt.figure()
        df.boxplot(column=col)
        plt.title(f'{tbl_name} — {col}')
        plt.ylabel(col)
        plt.show()


        q1, q3 = df[col].quantile([0.25, 0.75])
        iqr = q3 - q1
        lower = q1 - 1.5 * iqr
        upper = q3 + 1.5 * iqr
        n_out = ((df[col] < lower) | (df[col] > upper)).sum()

        outlier_stats.append({
            'table'       : tbl_name,
            'column'      : col,
            'lower_bound' : lower,
            'upper_bound' : upper,
            'n_outliers'  : n_out
        })

report_df = pd.DataFrame(outlier_stats)
report_df.sort_values(['table', 'n_outliers'], ascending=[True, False], inplace=True)
report_df.reset_index(drop=True, inplace=True)


report_df

"""#**Exportation des données**"""

# df_client.to_csv("client_clean.csv", index=False)
# df_account.to_csv("account_clean.csv", index=False)
# df_trans.to_csv("transaction_clean.csv", index=False)
# df_loan.to_csv("loan_clean.csv", index=False)
# df_card.to_csv("card_clean.csv", index=False)
# df_order.to_csv("order_clean.csv", index=False)
# df_district.to_csv("district_clean.csv", index=False)
# df_disposition.to_csv("disposition_clean.csv", index=False)

"""#TABLES

"""

df_disposition_clean.head(1)

df_client_clean.head(1)

df_account_clean.head(1)

df_district_clean.head(1)

df_card_clean.head(1)

df_loan_clean.head(1)

df_trans_clean.head(1)

df_order_clean.head(1)

"""#**1 - PROBLÉMATIQUE 1 : Répartition des clients selon l’âge, sexe, localisation ou statut**

#**Jointures**
"""

# === Jointure client + disposition ===
client_dispo = pd.merge(df_client_clean, df_disposition_clean, on="client_id", how="inner")

# === Jointure avec district ===
df_final_p_1 = pd.merge(client_dispo, df_district_clean, left_on="district_id", right_on="district_id", how="left")

# === Jointure avec loan
df_final_p_1_loan = pd.merge(df_final_p_1, df_loan_clean, on="account_id", how="left")

"""## **1 - Répartition par sexe**"""

df_client_clean.head()

# Compter les sexes
sex_counts = df_client_clean['gender'].value_counts()

# Affichage
sex_counts.plot(kind='pie', autopct='%1.1f%%', title="Répartition par sexe")
plt.ylabel('')
plt.show()

"""## **2 - Répartition par tranche d’âge**"""

# Créer des tranches
df_client_clean['tranche_age'] = pd.cut(df_client_clean['age'], bins=[0, 18, 30, 45, 60, 100],
                                labels=['<18', '18-30', '31-45', '46-60', '60+'])
df_client_clean.head()

# Compter et afficher
df_client_clean['tranche_age'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black', width=0.8
, title="Répartition par tranche d’âge")
plt.xlabel("Tranche d’âge")
plt.ylabel("Nombre de clients")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**3 - Répartition géographique**"""

# Top 10 des région
df_final_p_1["district_name"].value_counts().head(10)

plt.figure(figsize=(10, 6))
df_final_p_1["district_name"].value_counts().head(10).plot(kind='bar')
plt.title("Top 10 des districts les plus représentés")
plt.xlabel("Nom du district")
plt.ylabel("Nombre de clients")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**4 -  Répartition par statut**"""

df_final_p_1_loan.head()

df_final_p_1_loan["loan_status"].value_counts()
#[-3:]
#(normalize=True) * 100

plt.figure(figsize=(6, 4))
df_final_p_1_loan["loan_status"].value_counts().plot(kind='bar', color='skyblue')
plt.title("Répartition des clients selon leur statut")
plt.xlabel("Statut")
plt.ylabel("Nombre de clients")
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

"""## check des tables"""

display(df_account_clean.head()), #ok

display(df_client_clean.head()), #copy
client = df_client_clean.copy() #ajout des tranches d'age

display(df_account_clean.head()),

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),
display(df_trans_clean.head())

"""#**2 - PROBLÉMATIQUE 2 : les types de comptes les plus utilisés, et avec quelle fréquence les opérations sont effectuées**





"""

# La colonne 'frequency' (fréquence de frais ou de relevé)
df_account_clean['sending_frequency'].value_counts()

plt.figure(figsize=(8,5))
df_account_clean['sending_frequency'].value_counts().plot(kind='bar', color='orange')
plt.title("Répartition des types de comptes")
plt.xlabel("Type de compte (fréquence)")
plt.ylabel("Nombre de comptes")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Nombre d'opérations par compte
transactions_per_account = df_trans_clean.groupby('account_id').size().reset_index(name='transaction_count')
transactions_per_account

# Jointure avec account_clean pour récupérer le type de compte
account_usage = pd.merge(df_account_clean, transactions_per_account, on='account_id', how='left')
account_usage

account_usage['transaction_count'].sum()

account_usage['transaction_count'] = account_usage['transaction_count'].fillna(0)

account_usage['sending_frequency'].value_counts()

# === 5. Analyse : Moyenne d’opérations par type de compte ===
avg_transactions_by_type = account_usage.groupby('sending_frequency')['transaction_count'].mean().sort_values(ascending=False)

print("Nombre moyen d'opérations par type de compte :")
avg_transactions_by_type

plt.figure(figsize=(8,5))
avg_transactions_by_type.plot(kind='bar', color='green')
plt.title("Moyenne d'opérations par type de compte")
plt.xlabel("Type de compte (fréquence)")
plt.ylabel("Nombre moyen d'opérations")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""# segmenter les compte et deduire un type par leur comportement"""

df_account_clean.head()

df_trans_clean.head()

# Regrouper les transactions par compte
agg_trans = df_trans_clean.groupby('account_id').agg(
    nb_operations_trans=('trans_amount', 'count'),
    montant_moyen_trans=('trans_amount', 'mean'),
    montant_total_trans=('trans_amount', 'sum'),
    balance_moyen_trans	 = ('trans_balance', 'mean'),
    balance_total_trans = ('trans_balance', 'sum'),
).reset_index().round(2)
agg_trans

# Regrouper les transactions par compte
agg_trans_2 = df_trans_clean.groupby('account_id').agg(
    nb_operations_trans=('trans_amount', 'count'),
    montant_moyen_trans=('trans_amount', 'mean'),
    montant_total_trans=('trans_amount', 'sum'),
    balance_moyen_trans_mean	 = ('trans_balance', 'mean'),
    balance_total_trans_median = ('trans_balance', 'median'),
    balance_total_trans_std = ('trans_balance', 'std')
).reset_index().round(2)
agg_trans_2

df_card_disp = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='left')
df_card_disp

# Créer une colonne binaire : 1 si le compte a un prêt
df_loan_clean['has_loan'] = 1
loan_flag = df_loan_clean[['account_id', 'has_loan']].drop_duplicates()

df_card_disp['has_card'] = 1
card_flag = df_card_disp[['account_id', 'has_card']].drop_duplicates()

# Fusion avec les données des comptes

df = (df_account_clean
      .merge(agg_trans_2, on='account_id', how='left')   # agrégats de transactions
      .merge(loan_flag, on='account_id', how='left')   # flag prêt
      .merge(card_flag, on='account_id', how='left') )




# df = pd.merge(df_account_clean, agg_trans, on='account_id', how='left')
# df = pd.merge(df, loan_flag, on='account_id', how='left')


df['has_loan'] = df['has_loan'].fillna(0)
df['has_card'] = df['has_card'].fillna(0)
df['nb_operations_trans'] = df['nb_operations_trans'].fillna(0)
df['montant_moyen_trans'] = df['montant_moyen_trans'].fillna(0)
df['montant_total_trans'] = df['montant_total_trans'].fillna(0)
df['balance_moyen_trans_mean'] = df['balance_moyen_trans_mean'].fillna(0)
df['balance_total_trans_median'] = df['balance_total_trans_median'].fillna(0)
df['balance_total_trans_std'] = df['balance_total_trans_std'].fillna(0)




  # balance_moyen_trans_mean	 = ('trans_balance', 'mean'),
  #   balance_total_trans_median = ('trans_balance', 'median'),
  #   balance_total_trans_std = ('trans_balance', 'std')

df.head()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

#Clustering avec KMeans


X = df[['nb_operations_trans', 'montant_moyen_trans', 'montant_total_trans', 'balance_moyen_trans_mean', 'balance_total_trans_median', 'balance_total_trans_std','has_loan', 'has_card']]

# Standardisation
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# KMeans clustering
kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
df['cluster'] = kmeans.fit_predict(X_scaled)

# Visualisation du résultat
plt.figure(figsize=(8, 5))
df['cluster'].value_counts().sort_index().plot(kind='bar', color='purple')
plt.title("Segmentation des comptes bancaires par KMeans")
plt.xlabel("Cluster")
plt.ylabel("Nombre de comptes")
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
kmeans

# Moyenne des variables explicatives par cluster
resume_clusters = df.groupby('cluster')[['nb_operations_trans', 'montant_moyen_trans', 'montant_total_trans', 'balance_moyen_trans_mean', 'balance_total_trans_median', 'balance_total_trans_std','has_loan', 'has_card']].mean().round(2)
resume_clusters

# | Cluster | Segmentation comportementale                 | Type bancaire probable                                 |
# | ------- | -------------------------------------------- | ------------------------------------------------------ |
# | **0**   | Activité moyenne, pas de prêt                | 🧾 **Compte courant personnel standard**               |
# | **1**   | Compte très actif, flux élevés               | 💼 **Compte courant professionnel (TPE/PME) ou client très fortuné |
# | **2**   | Grosse activité, très gros flux, pas de prêt | 💰 **Livret épargne haut de gamme / Compte titre**     |
# | **3**   | Gros volumes + prêt                          | 💳 **Compte avec crédit (conso ou immo)**              |

def nom_cluster(row):
    if row['cluster'] == 0:
        return 'Compte courant'
    elif row['cluster'] == 1:
        return 'Compte courant pro'
    elif row['cluster'] == 2:
        return 'Compte épargne'
    elif row['cluster'] == 3:
        return 'Compte crédit'

df['type_compte_kmeans'] = df.apply(nom_cluster, axis=1)
df

df_account_clean.head()

df_trans_clean = df_trans_clean.merge(df[['account_id', 'type_compte_kmeans']], on='account_id', how='left')
df_account_clean = df_account_clean.merge(df[['account_id', 'type_compte_kmeans']], on='account_id', how='left')

df_account_clean.head()

df_trans_clean.head()

df_account_clean['type_compte_kmeans'].value_counts().sort_index()

df_trans_clean['type_compte_kmeans'].value_counts().sort_index()

df_loan_clean.shape

# agg_df = df.groupby(['type_compte_kmeans', 'sending_frequency']).agg(
#     {'nb_operations_trans': 'count','montant_total_trans': 'sum'}
#     ).reset_index().round(2)
trans = df_trans_clean.groupby(['type_compte_kmeans','trans_type', 'operation']).size().reset_index(name='nb_transactions')
trans

import pandas as pd

# Regrouper les données par type de compte et trans_type
#bar_data = trans.groupby(['type_compte_kmeans', 'trans_type'])['nb_transactions'].sum().unstack()

trans.plot(kind='bar', stacked=True, figsize=(10, 6))
plt.title("Répartition des types de transactions par cluster")
plt.xlabel("Type de compte (cluster KMeans)")
plt.ylabel("Nombre de transactions")
plt.legend(title='Type de transaction')
plt.tight_layout()
plt.show()

import plotly.express as px

fig = px.bar(
    trans,
    x='type_compte_kmeans',
    y='nb_transactions',
    color='trans_type',
    hover_data=['operation'],
    title='Nombre de transactions par type de compte et type de transaction',
    barmode='stack'
)
fig.show()

# Visualisation du résultat nb de comptes
plt.figure(figsize=(8, 5))
df_account_clean['type_compte_kmeans'].value_counts().sort_index().plot(kind='bar', color='purple')
plt.title("Segmentation des comptes bancaires par KMeans")
plt.xlabel("Cluster")
plt.ylabel("Nombre de comptes")
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

# Visualisation du résultat nb de transaction ===
plt.figure(figsize=(8, 5))
df_trans_clean['type_compte_kmeans'].value_counts().sort_index().plot(kind='bar', color='purple')
plt.title("Segmentation des transactions bancaires par KMeans")
plt.xlabel("Cluster")
plt.ylabel("Nombre de transaction")
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

# Regrouper par ty compte
agg = df.groupby(['type_compte_kmeans','sending_frequency']).size().reset_index(name='nb_compte')
agg

agg_df = df.groupby(['type_compte_kmeans', 'sending_frequency']).agg(
    {'nb_operations_trans': 'count','montant_total_trans': 'sum'}
    ).reset_index().round(2)

agg_df

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
components = pca.fit_transform(X_scaled)
df['PC1'] = components[:, 0]
df['PC2'] = components[:, 1]

# Graphique
plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")
sns.scatterplot(data=df, x='PC1', y='PC2', hue='type_compte_kmeans', palette='Set2', s=70, alpha=0.9)
plt.title("Segmentation KMeans des comptes (PCA 2D)")
plt.xlabel("Composante principale 1")
plt.ylabel("Composante principale 2")
plt.legend(title='type_compte')
plt.tight_layout()
plt.show()

# Composante principale 1 (axe horizontal) :
# Probablement corrélée aux flux monétaires (montants d’opérations, soldes, etc.)
# Va de comptes à flux faibles (gauche) à très élevés (droite)

# Composante principale 2 (axe vertical) :
# Peut refléter la variabilité ou fréquence des opérations (ou une distinction actif/passif)
# Haut : comptes avec activité régulière
# Bas : comptes plus passifs ou déséquilibrés (comme crédit ou livret peu utilisé)

components = pca.fit_transform(X_scaled)
components

"""## Check des tables"""

display(df_loan_clean.head()),
loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),
display(df_trans_clean.head()),
transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

"""#**3 - PROBLÉMATIQUE 3 : le volume mensuel ou annuel des transactions ? Y a-t-il une saisonnalité dans les dépenses ?**"""

df_trans_clean.head()

df_trans_clean['year'] = df_trans['trans_date'].dt.year
df_trans_clean['month'] = df_trans['trans_date'].dt.month
df_trans_clean['month'] = df_trans['trans_date'].dt.month
df_trans_clean['day'] = df_trans['trans_date'].dt.day
df_trans_clean['periode'] = df_trans['trans_date'].dt.to_period('M')

df_trans_clean.head()

# Nombre de transactions par mois
tx_count = df_trans_clean.groupby("periode")["trans_id"].count()

# Montant total des transactions par mois
tx_sum = df_trans_clean.groupby("periode")["trans_amount"].sum()

# Regroupement dans un DataFrame
monthly_stats = pd.DataFrame({
    "transactions_count": tx_count,
    "transactions_sum": tx_sum
}).reset_index()

monthly_stats["periode"] = monthly_stats["periode"].astype(str)
monthly_stats

#Visualisation des tendances

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="transactions_sum", data=monthly_stats, marker="o", label="Montant total")
#sns.lineplot(x="periode", y="transactions_count", data=monthly_stats, marker="o", label="Nb opérations")

plt.title("Évolution mensuelle des transactions")
plt.xlabel("Mois")
plt.ylabel("Montants / Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

#Détection de la saisonnalité
# Moyenne mensuelle toutes années confondues
seasonal_avg = df_trans_clean.groupby("month")["trans_amount"].sum().reset_index()
seasonal_nb = df_trans_clean.groupby("month")["trans_id"].count().reset_index()

#seasonal_avg

plt.figure(figsize=(10, 5))
#sns.barplot(x="month", y="trans_amount", data=seasonal_avg)
sns.lineplot(x="month", y="trans_amount", data=seasonal_avg, marker="o")
sns.lineplot(x="month", y='trans_id', data=seasonal_nb, marker="o")

plt.title("Saison moyenne des dépenses mensuelles")
plt.xlabel("Mois")
plt.ylabel("Montant/nb total")
plt.show()

seasonal_nb

#Détection de la saisonnalité
# Moyenne mensuelle toutes années confondues
seasonal_avg = df_trans_clean.groupby("year")["trans_amount"].sum().reset_index()
seasonal_nb = df_trans_clean.groupby("year")["trans_id"].count().reset_index()

#seasonal_avg

plt.figure(figsize=(10, 5))
#sns.barplot(x="year", y="trans_amount", data=seasonal_avg)
sns.lineplot(x="year", y="trans_amount", data=seasonal_avg, marker="o")
#sns.lineplot(x="year", y='trans_id', data=seasonal_nb, marker="o")

plt.title("Saison moyenne des dépenses mensuelles")
plt.xlabel("année")
plt.ylabel("Montant/nb total")
plt.show()

"""#**time series**"""

df_time = df_trans_clean.copy()
df_time.head()

df_time.set_index("trans_date", inplace=True)

# Option 1 : montant total mensuel
ts_montant = df_time["trans_amount"].resample("M").sum()

# Option 2 : nombre de transactions mensuel
#ts_count = df["amount"].resample("M").count()
print(ts_montant.head())

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))
ts_montant.plot(title="Montant total des transactions (mensuel)")
plt.ylabel("Montant")
plt.xlabel("Date")
plt.grid(True)
plt.show()

from statsmodels.tsa.seasonal import seasonal_decompose

decomposition = seasonal_decompose(ts_montant, model='multiplicative')  # multiplicative parce quevariance croissante

decomposition.plot()
plt.suptitle("Décomposition de la série temporelle")
plt.tight_layout()
plt.show()

# Tendance : Évolution globale sur le long terme
# Saison : Motifs récurrents chaque année (périodicité)
# Résidu : Événements irréguliers

decomposition.seasonal.plot(title="Composante saisonnière")
plt.show()

decomposition.resid.plot(title="Composante résiduelle")
plt.show()

# Amplitude modérée des variations
# Les résidus oscillent autour de la valeur 1.00, ce qui signifie que les écarts à la tendance + saison sont faibles (max ~1.06, min ~0.96).
# → Le modèle capte bien la structure globale de la série.

# Aucune tendance forte apparente
# Pas de dérive claire à la hausse ou à la baisse : les résidus sont stationnaires autour de 1.
# → Cela indique que la tendance et la saisonnalité ont été correctement extraites.

# Quelques pics irréguliers
# Des pics en 1993-1994, en 1995, et un peu en 1998.
# → Cela pourrait indiquer des anomalies ponctuelles, ou des événements exceptionnels (ex : opération massive, erreur, effet externe).

import matplotlib.cm as cm

df_season = ts_montant.to_frame(name='valeur')
df_season['année'] = df_season.index.year
df_season['mois'] = df_season.index.month

# Pivot pour lignes = mois, colonnes = années
df_pivot = df_season.pivot(index='mois', columns='année', values='valeur')

# Tracé
plt.figure(figsize=(12, 6))
colors = cm.rainbow(np.linspace(0, 1, df_pivot.shape[1]))

for i, col in enumerate(df_pivot.columns):
    plt.plot(df_pivot.index, df_pivot[col], label=str(col), color=colors[i], marker="o")

plt.title("Seasonplot : Rendement")
plt.xlabel("Mois")
plt.ylabel("Valeur")
plt.xticks(ticks=range(1,13), labels=[
    "Jan", "Fév", "Mar", "Avr", "Mai", "Juin",
    "Juil", "Août", "Sep", "Oct", "Nov", "Déc"
])
plt.legend(title="Année", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Préparation des données (index datetime et colonnes 'ds' et 'y')
df_ts = ts_montant.reset_index()
df_ts.columns = ['ds', 'y']
df_ts['ds'] = pd.to_datetime(df_ts['ds'])  # S'assurer que ds est en datetime
df_ts.set_index('ds', inplace=True)

# Entraînement du modèle SARIMA
#model = auto_arima(df_ts['y'], seasonal=True, m=12, trace=True, error_action='ignore')
model = SARIMAX(df_ts['y'],  # <- endog ici !
                order=(1, 1, 1),
                seasonal_order=(1, 1, 1, 12),
                enforce_stationarity=False,
                enforce_invertibility=False)

results = model.fit()

# Prévision sur 36 mois à venir
# On étend l'index avec 36 dates supplémentaires
future_dates = pd.date_range(start=df_ts.index[-1] + pd.DateOffset(months=1), periods=12, freq='M')
df_forecast_index = df_ts.index.union(future_dates)

# Prédictions complètes
forecast = results.predict(start=0, end=len(df_forecast_index)-1)

# 4. Visualisation
plt.figure(figsize=(12, 6))
plt.plot(df_ts.index, df_ts['y'], label='Historique')
plt.plot(df_forecast_index, forecast, label='Prévision', linestyle='--')
plt.title("Prévision des transactions")
plt.xlabel("Date")
plt.ylabel("Montant")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""## Check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),

display(df_trans_clean.head()),
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

"""#**4 - PROBLÉMATIQUE 4 : Quel est le solde moyen par région ou par groupe d’âge ? Y a-t-il des différences significatives selon le sexe ou la zone géographique ?**

#**Jointure**
"""

pd.set_option('display.max_columns', 500)

df_district_clean['region'].value_counts()

# Fusion avec les comptes (account) pour récupérer les dates et district_id
client_dispo_account = pd.merge(client_dispo, df_account, on="account_id")

# Renommage pour éviter le conflit de colonnes
client_dispo_account = client_dispo_account.rename(columns={"district_id_y": "district_id"})
client_dispo_account = client_dispo_account.drop(columns=["district_id_x"])

# Fusion avec la table des districts (avec colonnes renommées)
client_account = pd.merge(client_dispo_account, df_district, on="district_id", how="left")
client_account.head()

# Création de tranches d'âge
bins = [0, 25, 35, 45, 55, 65, 100]
labels = ["<25", "25-34", "35-44", "45-54", "55-64", "65+"]
client_account["age_group"] = pd.cut(client_account["age"], bins=bins, labels=labels, right=False)

# Calcul du solde moyen par compte à partir des transactions
balance_mean = df_trans_clean.groupby("account_id")["trans_balance"].mean().reset_index(name="avg_balance")

# Fusion avec les données client-account
client_account = pd.merge(client_account, balance_mean, on="account_id", how="left")

# Agrégation du solde moyen par région, groupe d'âge et sexe
agg_result = client_account.groupby(["region", "age_group", "gender"])["avg_balance"].mean().reset_index()
agg_result.head(15)

import scipy.stats as stats


# Test t de Student : solde moyen homme vs femme
male_balances = client_account[client_account["gender"] == "M"]["avg_balance"].dropna()
female_balances = client_account[client_account["gender"] == "F"]["avg_balance"].dropna()
t_stat_sex, p_value_sex = stats.ttest_ind(male_balances, female_balances, equal_var=False)

# Test ANOVA : solde moyen par région
region_groups = client_account.dropna(subset=["avg_balance"]).groupby("region")["avg_balance"].apply(list)
f_stat_region, p_value_region = stats.f_oneway(*region_groups)

{
    "test_t_sex": {"t_stat": t_stat_sex, "p_value": p_value_sex},
    "anova_region": {"f_stat": f_stat_region, "p_value": p_value_region}
}

# Test entre hommes et femmes (t de Student)
# t-statistique = 1.51
# p-value = 0.13
# 👉 : pas de différence significative entre les sexes (car p > 0.05)

# Test entre régions (ANOVA)
# F-statistique = 0.63
# p-value = 0.73
# 👉 : pas de différence significative entre les régions non plus

# ✅ : Selon ces tests, le solde moyen ne varie pas significativement selon le sexe ou la zone géographique.

df_dispo_ownerr = df_disposition_clean[df_disposition_clean['disp_role'] == 'OWNER'].value_counts()
df_dispo_ownerr

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
display(df_order_clean.head()),

display(df_trans_clean.head()),
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker

"""#**5 - PROBLÉMATIQUE 5 : Quels districts présentent les meilleures conditions économiques (faible chômage, salaire élevé, peu de criminalité) ?**"""

df_district_clean.head()

# Création d'un score économique combiné
df_district_clean['score'] = (
    df_district_clean['average_salary'] -
    df_district_clean[['unemployment_1995', 'unemployment_1996']].mean(axis=1)*1000 -
    df_district_clean[['crimes_1995', 'crimes_1996']].mean(axis=1)*100
)

# Top 10 des meilleurs districts selon ce score
top_districts = df_district_clean.sort_values(by='score', ascending=False)[[
    'region', 'district_name', 'average_salary', 'unemployment_1996', 'crimes_1996', 'score'
]].head(10)

top_districts

# des revenus élevés (donc on ajoute le salaire moyen),
# un faible taux de chômage (donc on soustrait le chômage),
# une faible criminalité (donc on soustrait le taux de crimes).

# #  Interprétation :
# # Plus le score est élevé (moins négatif), plus le district est favorable économiquement.
# # # Un district avec un salaire élevé, peu de chômage, et peu de crimes aura un score élevé.

 #Bien que Prague ou Brno soient les centres économiques évidents, mon analyse fait ressortir des districts moins urbanisés mais très stables comme Rokycany ou Domazlice, où la combinaison entre bas taux de chômage, salaires corrects et faible criminalité constitue un excellent indicateur de bien-être économique.

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Sélectionner les colonnes pour l'analyse
features = ['unemployment_1996', 'average_salary', 'crimes_1996']
df_features = df_district_clean[features]
df_features
# Standardiser les données
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df_features)
scaled_features

# Appliquer la PCA pour créer 1 seul "super-score"
pca = PCA(n_components=1)
df_district_clean['score_pca'] = pca.fit_transform(scaled_features)
df_district_clean['score_pca']


# Interpréter les poids (les "loadings")
# pca.components_ nous donne la "recette"
poids = pca.components_[0]

print("Poids calculés par la PCA pour chaque variable :")
for feature, weight in zip(features, poids):
    print(f"- {feature}: {weight:.2f}")

# Pour obtenir un classement, on doit s'assurer que le score va dans le bon sens.
# Ex: si 'average_salary' a un poids positif, un score élevé est bon.
# Si 'unemployment' a un poids négatif, un score élevé est bon.
# Ici, il faut peut-être inverser le signe du score pour que "petit = meilleur".
# On regarde les poids : si le poids du salaire est négatif, on inverse.
if poids[1] < 0:
    df_district_clean['score_pca'] = -df_district_clean['score_pca']


# Afficher le classement final basé sur la PCA
classement_pca = df_district_clean.sort_values('score_pca', ascending=False)
display(classement_pca[['district_name', 'score_pca']].head(10))

df_district_clean
df_district_clean = df_district_clean.drop(columns=["score"])

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker

"""#**6 - PROBLÉMATIQUE 6 : Quelle proportion de clients a contracté un prêt ? Quels sont les montants et durées les plus fréquents ?**

#**Jointure**
"""

# Fusion pour relier les prêts aux clients via disposition
df_loan_full = df_loan_clean.merge(df_disposition_clean, on="account_id", how="left")
df_loan_full = df_loan_full.merge(df_client_clean, on="client_id", how="left")

df_loan_clean.head()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np



# Calcul de la proportion de clients ayant un prêt
total_clients = df_client_clean['client_id'].nunique()
clients_with_loan = df_loan_full['client_id'].nunique()
loan_proportion = clients_with_loan / total_clients
loan_proportion
# 15,4 % des clients ont au moins un prêt actif.

# Affichage graphique des montants et durées les plus fréquents
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Histogramme des montants
sns.histplot(df_loan_clean['loan_amount'], bins=30, kde=True, ax=axes[0])
axes[0].set_title('Distribution des montants de prêts')
axes[0].set_xlabel('Montant')
axes[0].set_ylabel('Nombre de prêts')

# Histogramme des durées
sns.histplot(df_loan_clean['loan_duration'], bins=30, kde=True, ax=axes[1])
axes[1].set_title('Distribution des durées de prêts')
axes[1].set_xlabel('Durée (mois)')
axes[1].set_ylabel('Nombre de prêts')

plt.tight_layout()
plt.show()

# Montants et durées les plus fréquents
top_loan_amounts = df_loan['loan_amount'].value_counts().head(5)
top_loan_durations = df_loan['loan_duration'].value_counts().head(5)
# Résultats chiffrés
top_loan_amounts, top_loan_durations

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS

"""#**7 - Problematique 7 : Quels types d’opérations bancaires sont les plus fréquents (virements, retraits, paiements par carte...) ?**"""

df_trans_clean.head()

# Comptage des types d'opérations les plus fréquents
operation_counts = df_trans_clean['operation'].value_counts().reset_index()
operation_counts.columns = ['operation', 'count']

# Affichage des résultats
operation_counts.head(10)

# Création d'un graphique à barres
plt.figure(figsize=(10, 6))
plt.bar(operation_counts['operation'], operation_counts['count'])
plt.title("Types d'opérations bancaires les plus fréquents")
plt.xlabel("Type d'opération")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=45)
plt.tight_layout()
plt.grid(axis='y')
plt.show()

"""# check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS
#pbt 7 : RAS

"""#**8 - PROBLEMATIQUE 8 : À travers les prêts et les frais bancaires visibles dans les transactions, peut-on estimer la rentabilité par client ou par région**

#**Jointure**
"""

df_trans_clean.head()

# Lier clients aux comptes via la table des dispositions
df_dispo_owner = df_disposition_clean[df_disposition_clean['disp_role'] == 'OWNER']
df_clients_accounts = df_dispo_owner.merge(df_client_clean, on='client_id').merge(df_account_clean, on='account_id')
df_clients_accounts = df_clients_accounts.rename(columns={"district_id_y": "district_id"})
df_clients_accounts = df_clients_accounts.drop(columns=["district_id_x"])
# Ajout des infos sur les districts
df_clients_accounts = df_clients_accounts.merge(df_district_clean, on='district_id')
# Ajout des infos client sur les prêts
df_loan_clients = df_loan_clean.merge(df_account_clean[['account_id']], on='account_id')
df_loan_clients = df_loan_clients.merge(df_clients_accounts[['account_id', 'client_id', 'district_id', 'district_name']], on='account_id')
df_loan_clients.head()

# Revenu = intérêts = (amount * interest_rate / 100) * (duration / 12)
df_loan_clients['revenu_pret'] = df_loan_clients['loan_payments'] * df_loan_clients['loan_duration'] - df_loan_clients['loan_amount']
df_loan_clients['revenu_pret'].sum()

# Revenus issus des frais bancaires (transactions)

# Sélection des frais dans les transactions (frais = "POPLATEK", intérêts crédit = "PRIJEM_UROKU")
df_frais = df_trans_clean[df_trans_clean['operation'].isin(['intérets penalite','interets crediteurs'])].reset_index()

# Join avec comptes et clients
df_frais = df_frais.merge(df_clients_accounts[['account_id', 'client_id', 'district_id', 'district_name']], on='account_id')

# Ajout d'une colonne 'revenu_frais' (positif si revenu pour la banque)
#df_frais['revenu_frais'] = df_frais['tans_amount'].abs()
df_frais.head()

"""## Check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS même si on devrait creuser les intérets sur la partie Power BI

"""#**1 - Comptes**

##**jointure**
"""

# === Jointure client + disposition ===
client_dispo = pd.merge(df_client_clean, df_disposition_clean, on="client_id", how="inner")
client_account = pd.merge(client_dispo, df_account_clean, on="account_id", how="inner")

# Renommage pour éviter le conflit de colonnes
client_account = client_account.rename(columns={"district_id_y": "district_id"})
client_account = client_account.drop(columns=["district_id_x"])

client_account_district = pd.merge(df_district_clean, client_account, on='district_id', how='left')

client_account_district_trans = pd.merge(df_trans_clean, client_account_district, on='account_id', how='left')

"""##**1 - account fidèle**"""

client_account_district_trans.head()

# Recalcul de la date maximale pour mesurer l'ancienneté
max_trans = df_trans_clean['trans_date'].max()

max_trans

# # Calcul de l'ancienneté en années
df_account_clean['anciennete_annees'] = (max_trans - df_account_clean['account_date']).dt.days / 365.25
anciennete_stats = df_account_clean['anciennete_annees'].describe()
anciennete_stats



"""##**2 - repartion par sexe**"""

# Compter les sexes
sex_counts = client_account['gender'].value_counts()

# Affichage
sex_counts.plot(kind='pie', autopct='%1.1f%%', title="Répartition par sexe")
plt.ylabel('')
plt.show()

"""##**3 - repartion des comptes par tranche d'age**"""

# Compter et afficher
client_account['tranche_age'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black', width=0.8
, title="Répartition par tranche d’âge")
plt.xlabel("Tranche d’âge")
plt.ylabel("Nombre de compte")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**4 - repartion des comptes par type**"""

# repartition des comptes par type de compte
client_account_district['type_compte_kmeans'].value_counts().plot(kind='pie', autopct='%1.1f%%', title="Répartition des comptes par type de compte")
plt.ylabel('')
plt.show()

"""##**5 - Analyse temporelle**

###**Par nombre de compte crée par mois**
"""

client_account_district['year'] = client_account_district['account_date'].dt.year
client_account_district['month'] = client_account_district['account_date'].dt.month
client_account_district['month'] = client_account_district['account_date'].dt.month
client_account_district['day'] = client_account_district['account_date'].dt.day
client_account_district['periode'] = client_account_district['account_date'].dt.to_period('M')

client_account_district.head()

# Nombre de compte crée par mois
tx_count = client_account_district.groupby("periode")["account_id"].count()



# Regroupement dans un DataFrame
monthly_stats = pd.DataFrame({
    "compte_cree": tx_count,
    "balance_total": tx_sum

}).reset_index()

monthly_stats["periode"] = monthly_stats["periode"].astype(str)
monthly_stats

#Visualisation des tendances

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="compte_cree", data=monthly_stats, marker="o", label="nb compte cree ")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("Évolution mensuelle des compte cree")
plt.xlabel("Mois")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

#Détection de la saisonnalité
# Moyenne mensuelle toutes années confondues
#seasonal_avg = df_trans_clean.groupby("month")["trans_amount"].sum().reset_index()
seasonal_nb = client_account_district.groupby("month")["account_id"].count().reset_index()

#seasonal_avg

plt.figure(figsize=(10, 5))
#sns.barplot(x="month", y="trans_amount", data=seasonal_avg)
#sns.lineplot(x="month", y="trans_amount", data=seasonal_avg, marker="o")
sns.lineplot(x="month", y='account_id', data=seasonal_nb, marker="o")

plt.title("Saison moyenne des creation de compte mensuelles")
plt.xlabel("Mois")
plt.ylabel("nb total")
plt.show()



# attention a l'échelle

"""###**Par solde des compte**"""

client_account_district_trans.sort_values(by=['account_id', 'trans_date']).head(100)

"""####**Par année**"""

# Trier les données
client_account_district_trans_year = client_account_district_trans.sort_values(by=['account_id', 'year', 'trans_date'])

# Garder la dernière transaction de chaque mois pour chaque compte
df_last_trans_per_year = client_account_district_trans_year.groupby(['account_id', 'year']).tail(1)

# Garder uniquement les colonnes utiles
result_year = df_last_trans_per_year[['account_id', 'year', 'trans_date', 'trans_balance']].reset_index(drop=True)

result_year.head(10)

result_year.groupby('year')['trans_balance'].sum().reset_index()

sns.lineplot(x="year", y='trans_balance', data=result_year, marker="o")

plt.title("solde total par année")
plt.xlabel("année")
plt.ylabel("solde total")
plt.show()

"""####**Par mois**"""

# 3. Trier les données
client_account_district_trans_month = client_account_district_trans.sort_values(by=['account_id', 'periode', 'trans_date'])

# 4. Garder la dernière transaction de chaque mois pour chaque compte
df_last_trans_per_month = client_account_district_trans_month.groupby(['account_id', 'periode']).tail(1)

# 5. (Optionnel) Garder uniquement les colonnes utiles
result_month = df_last_trans_per_month[['account_id', 'month','year','periode', 'trans_date', 'trans_balance']].reset_index(drop=True)

result_month

result_month.groupby('month')['trans_balance'].sum()

sns.lineplot(x="month", y='trans_balance', data=result_month, marker="o")

plt.title("solde total par mois")
plt.xlabel("année")
plt.ylabel("solde total")
plt.show()



"""##**6 - Stat des soldes des comptes**"""

result_year.describe()

result_month.describe()

"""##**7 - volume des comptes par région**"""

result_month

df_month = pd.merge(result_month, client_account_district, on='account_id', how='left')
df_month_bis = df_month.groupby('region')['trans_balance'].sum().reset_index()
df_month_bis.head()

"""## check des tables"""

df_account_clean = df_account_clean.drop(columns='anciennete_annees')

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS même si on devrait creuser les intérets sur la partie Power BI
#pbt compte : table compte, on ne garde pas ancienneté (droppper)

"""#**2- loan**

##**Jointures**
"""

client_account_loan = pd.merge(df_loan_clean, client_account, on='account_id', how='left')

client_account_loan.head()

"""##**1- repartition par tranche d'age**

"""

# Compter et afficher
client_account_loan['tranche_age'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black', width=0.8
, title="Répartition par tranche d’âge")
plt.xlabel("Tranche d’âge")
plt.ylabel("Nombre de prét")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""##**2 - repartion par sexe**"""

# Compter les sexes
sex_counts = client_account_loan['gender'].value_counts()

# Affichage
sex_counts.plot(kind='pie', autopct='%1.1f%%', title="Répartition par sexe")
plt.ylabel('')
plt.show()

"""##**3 - repartition par statuts**"""

df_loan_clean.head()

# Compter les sexes
status_counts = client_account_loan['loan_status'].value_counts()

# Affichage
status_counts.plot(kind='pie', autopct='%1.1f%%', title="Répartition par status")
plt.ylabel('')
plt.show()

"""##**4 - repartition par duréé**"""

duree_counts = client_account_loan['loan_duration'].value_counts()
# Affichage
duree_counts.plot(kind='pie', autopct='%1.1f%%', title="Répartition par duree")
plt.ylabel('')
plt.show()

# amount_counts = client_account_loan['loan_amount'].value_counts().head(10)
# # Affichage
# amount_counts.plot(kind='pie', autopct='%1.1f%%', title="Répartition par amount")
# plt.ylabel('')
# plt.show()



"""##**5 - Analyse temporelle**"""

client_account_loan['year'] = client_account_loan['loan_date'].dt.year
client_account_loan['month'] = client_account_loan['loan_date'].dt.month
client_account_loan['month'] = client_account_loan['loan_date'].dt.month
client_account_loan['day'] = client_account_loan['loan_date'].dt.day
client_account_loan['periode'] = client_account_loan['loan_date'].dt.to_period('M')

client_account_loan

# Nombre de prét accordé par mois
nb_loan = client_account_loan.groupby("periode")["loan_id"].count()
volume_loan = client_account_loan.groupby("periode")["loan_amount"].sum()



# Regroupement dans un DataFrame
monthly_stats_loan = pd.DataFrame({
    "nb_loan": nb_loan,
    "montant_total": volume_loan

}).reset_index()

monthly_stats_loan["periode"] = monthly_stats_loan["periode"].astype(str)
monthly_stats_loan

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="nb_loan", data=monthly_stats_loan, marker="o", label="nb loan")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("Évolution mensuelle des prét accordé")
plt.xlabel("Mois")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="montant_total", data=monthly_stats_loan, marker="o", label="montant total")


plt.title("Évolution mensuelle des montant total")
plt.xlabel("Mois")
plt.ylabel("montant")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

"""##**6 - Analyse des loan a risque**"""

# Compter les sexes
status_counts = client_account_loan['loan_status'].value_counts()

# Affichage
status_counts.plot(kind='pie', autopct='%1.1f%%', title="Répartition par status")
plt.ylabel('')
plt.show()

df_defaut_litige = client_account_loan[client_account_loan['loan_status'].isin(['défaut', 'litige'])]
df_defaut_litige

print(df_defaut_litige['periode'].dtype)
print(df_defaut_litige['periode'].head())

loan_defaut_litige_groupe = df_defaut_litige.groupby("periode")["loan_id"].count().reset_index()
loan_defaut_litige_groupe

df_defaut_litige['type_compte_kmeans'].value_counts()

df_defaut_litige['tranche_age'].value_counts()

"""## check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans

display(df_card_clean.head()),
display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS même si on devrait creuser les intérets sur la partie Power BI
#pbt compte : table compte, on ne garde pas ancienneté (droppper)
#pbt loan : RAS

"""#**3 - Card**"""

df_card_clean.head()

"""##**Jointure**"""

# relier CARD → DISP  (clé primaire : disp_id)
card_disp = df_card_clean.merge(df_disposition_clean[['disp_id','account_id','disp_role']], on='disp_id', how='left')

# garder une seule ligne par carte et par compte – préférence OWNER
card_disp = (card_disp
             .sort_values('disp_role')
             .drop_duplicates('card_id'))

# joindre à ACCOUNT + cluster
card_account_cluster = card_disp.merge(
        df_account_clean[['account_id','type_compte_kmeans']],
        on='account_id',
        how='left')
card_account_cluster = card_account_cluster.drop_duplicates('card_id')

card_account_cluster['type_compte_kmeans'].value_counts()

card_disp = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='left')
card_account = pd.merge(card_disp, df_account_clean, on='account_id', how='left')
card_account_client = pd.merge(card_account, df_client_clean, on='client_id', how='left')

card_account_client.head()

card_account_client.describe()

card_account_client['card_type'].value_counts()

card_account_client['type_compte_kmeans'].value_counts()

card_account_client['gender'].value_counts()

card_account_client['tranche_age'].value_counts()

card_account_client['year'] = card_account_client['card_date'].dt.year
card_account_client['month'] = card_account_client['card_date'].dt.month
card_account_client['month'] = card_account_client['card_date'].dt.month
card_account_client['day'] = card_account_client['card_date'].dt.day
card_account_client['periode'] = card_account_client['card_date'].dt.to_period('M')

card_account_client.head()

# Nombre de prét accordé par mois
nb_card = card_account_client.groupby("periode")["card_id"].count()
#volume_card = card_account_client.groupby("periode")["loan_amount"].sum()



# Regroupement dans un DataFrame
monthly_stats_card = pd.DataFrame({
    "nb_card": nb_card

}).reset_index()

monthly_stats_card["periode"] = monthly_stats_card["periode"].astype(str)
monthly_stats_card

plt.figure(figsize=(14, 6))
sns.lineplot(x="periode", y="nb_card", data=monthly_stats_card, marker="o", label="nb card")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("Évolution mensuelle des cartes bancaire")
plt.xlabel("Mois")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

# Nombre de prét accordé par mois
nb_card = card_account_client.groupby("year")["card_id"].count()
#volume_card = card_account_client.groupby("periode")["loan_amount"].sum()



# Regroupement dans un DataFrame
year_stats_card = pd.DataFrame({
    "nb_card": nb_card

}).reset_index()
year_stats_card["year"] = year_stats_card["year"].astype(str)
year_stats_card

plt.figure(figsize=(14, 6))
sns.lineplot(x="year", y="nb_card", data=year_stats_card, marker="o", label="nb card")
#sns.lineplot(x="periode", y="balance_total", data=monthly_stats, marker="o", label="balance total")

plt.title("Évolution annuelle des cartes bancaire")
plt.xlabel("année")
plt.ylabel("Nombre")
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

card_account_client['durree_compte_carte'] = card_account_client['card_date'] - card_account_client['account_date']
card_account_client['durree_compte_carte'] = card_account_client['durree_compte_carte'].dt.days
# ploter le resultat
plt.figure(figsize=(10, 6))
sns.histplot(card_account_client['durree_compte_carte'], bins=30, kde=True)
plt.title('Distribution de la durée des cartes bancaire')
plt.xlabel('Durée (jours)')
plt.ylabel('Fréquence')
plt.show()

card_account_client.head()

#proportion de client avec ou sans carte
card_account_client['card_id'].value_counts()

import pandas as pd



# Associer chaque carte à un client
cards_clients = (
    df_card_clean[['card_id', 'disp_id']]
    .merge(df_disposition_clean[['disp_id', 'client_id']],
           on='disp_id', how='left')
    .dropna(subset=['client_id'])
)

# Obtenir la liste unique des clients qui possèdent ≥1 carte
clients_with_card = cards_clients['client_id'].unique()

# Compter les clients et calculer les proportions
total_clients        = df_client_clean['client_id'].nunique()
nb_clients_with_card = len(clients_with_card)
nb_clients_no_card   = total_clients - nb_clients_with_card

prop_with_card = nb_clients_with_card / total_clients
prop_no_card   = nb_clients_no_card   / total_clients

print(f"Total clients          : {total_clients:,}")
print(f"Clients avec carte     : {nb_clients_with_card:,}  ({prop_with_card:.2%})")
print(f"Clients sans carte     : {nb_clients_no_card:,}   ({prop_no_card:.2%})")



"""##**Card**"""

df_card_clean['year'] = df_card_clean['card_date'].dt.year
df_card_clean['month'] = df_card_clean['card_date'].dt.month
df_card_clean['day'] = df_card_clean['card_date'].dt.day
df_card_clean['periode'] = df_card_clean['card_date'].dt.to_period('M')

df_card_clean

# Nombre de carte émise par mois
nb_card_emise = df_card_clean.groupby("periode")["card_id"].count().reset_index()

nb_card_emise = nb_card_emise.rename(columns={"card_id": "nb_card_emission"})

nb_card_emise.describe()

sns.barplot(data = nb_card_emise, x="periode", y = "nb_card_emission")#, kde = True)

client_disp = pd.merge(df_client_clean, df_disposition, how = 'left', on ='client_id')
client_card = pd.merge(client_disp, df_card_clean, how = 'left', on ='disp_id')

client_card.isna().sum()

import pandas as pd
import matplotlib.pyplot as plt

# --- ÉTAPE 0 : CHARGEMENT DES DONNÉES NÉCESSAIRES ---
# Adaptez les chemins si vos fichiers ne sont pas dans le même dossier
df_account =  df_account_clean.copy()
df_card = df_card_clean.copy()
df_disp = df_disposition_clean.copy()


# --- ÉTAPE 1 : CALCULER LE NOMBRE DE COMPTES AVEC CARTE ---

# On fusionne les tables 'card' et 'disp' pour lier les cartes aux comptes
df_card_disp = pd.merge(df_card, df_disp, on='disp_id')

# On récupère la liste des 'account_id' uniques qui ont une carte
accounts_with_card_ids = df_card_disp['account_id'].unique()
nombre_comptes_avec_carte = len(accounts_with_card_ids)


# --- ÉTAPE 2 : CALCULER LE NOMBRE TOTAL DE COMPTES ET CEUX SANS CARTE ---

# On compte le nombre total de comptes uniques dans la table 'account'
total_comptes = df_account['account_id'].nunique()

# On calcule le nombre de comptes sans carte par soustraction
nombre_comptes_sans_carte = total_comptes - nombre_comptes_avec_carte


# --- ÉTAPE 3 : CRÉER LE GRAPHIQUE EN SECTEURS (PIE CHART) ---

# Préparer les données pour le graphique
labels = 'Comptes avec Carte', 'Comptes sans Carte'
sizes = [nombre_comptes_avec_carte, nombre_comptes_sans_carte]
explode = (0.1, 0)  # pour faire ressortir la tranche "Avec Carte"
colors = ['#99ff99', '#ff9999'] # Vert et Rouge

# Créer la figure et l'axe
fig, ax = plt.subplots(figsize=(10, 8))

# Créer le diagramme
ax.pie(sizes,
       explode=explode,
       labels=labels,
       colors=colors,
       autopct='%1.1f%%',  # Affiche les pourcentages avec une décimale
       shadow=True,
       startangle=140,      # Pivoter un peu le graphique pour une meilleure lisibilité
       textprops={'fontsize': 12})

# Assurer que le graphique est un cercle
ax.axis('equal')

# Ajouter un titre
plt.title("Proportion des Comptes Ayant une Carte Associée", fontsize=16)

# Sauvegarder et afficher le graphique
#plt.savefig('proportion_comptes_avec_carte.png')
#plt.show()

# Afficher les chiffres exacts pour référence
print(f"Nombre de comptes avec carte : {nombre_comptes_avec_carte}")
print(f"Nombre de comptes sans carte : {nombre_comptes_sans_carte}")
print(f"Nombre total de comptes : {total_comptes}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# On suppose que les DataFrames df_account_clean, df_card_clean, et df_disposition_clean sont chargés.
# La fusion et le calcul du délai restent les mêmes.
df_account_clean['date_creation_compte'] = pd.to_datetime(df_account_clean['account_date'], format='%y%m%d', errors='coerce')
df_card_clean['date_emission_carte'] = pd.to_datetime(df_card_clean['card_date'], format='%y%m%d', errors='coerce')
df_merged = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='inner')
df_final = pd.merge(df_merged, df_account_clean, on='account_id', how='inner')
df_final['delai_emission_jours'] = (df_final['date_emission_carte'] - df_final['date_creation_compte']).dt.days


# --- ÉTAPE 3: DIAGNOSTIC DES PROBLÈMES DE DONNÉES ---
print("--- Analyse des Problèmes de Données ---")

# Compter les délais NaN (problème de conversion de date)
delais_nan = df_final['delai_emission_jours'].isna().sum()
print(f"Nombre de lignes avec un délai non calculable (NaN) : {delais_nan}")

# Isoler et compter les délais négatifs illogiques
delais_negatifs = df_final[df_final['delai_emission_jours'] < 0]
print(f"Nombre de cartes émises AVANT la création du compte : {len(delais_negatifs)}")
if not delais_negatifs.empty:
    print("Exemples de ces délais négatifs :")
    display(delais_negatifs[['account_id', 'card_id', 'date_creation_compte', 'date_emission_carte', 'delai_emission_jours']].head())


# --- ÉTAPE 4: VISUALISATION SUR LES DONNÉES NETTOYÉES ---
print("\n--- Création du graphique sur les données logiques ---")

# On crée une série de données "propres" pour le graphique
# 1. On enlève les NaN avec .dropna()
# 2. On ne garde que les délais positifs ou nuls (>= 0)
delais_propres = df_final['delai_emission_jours'].dropna()
delais_propres = delais_propres[delais_propres >= 0]


# Créer l'histogramme avec les données nettoyées
if not delais_propres.empty:
    plt.figure(figsize=(12, 6))
    sns.histplot(delais_propres, bins=50, kde=True)
    plt.title('Distribution du délai (en jours) entre création de compte et émission de carte (Données Nettoyées)', fontsize=16)
    plt.xlabel('Délai en jours (uniquement les délais positifs ou nuls)', fontsize=12)
    plt.ylabel('Nombre de cartes émises', fontsize=12)
    plt.grid(True, linestyle='--')
    #plt.savefig('delai_emission_carte_nettoye.png')
    plt.show()
else:
    print("Aucune donnée valide à afficher après le nettoyage.")

# On suppose que vos DataFrames df_account_clean et df_card_clean sont chargés

print("--- Inspection du format de date dans df_account_clean ---")
print(df_account_clean[['account_id', 'account_date']].head())
print("\nType de la colonne 'account_date':", df_account_clean['account_date'].dtype)

print("\n" + "="*50 + "\n")

print("--- Inspection du format de date dans df_card_clean ---")
print(df_card_clean[['card_id', 'card_date']].head())
print("\nType de la colonne 'card_date':", df_card_clean['card_date'].dtype)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# On suppose que les DataFrames df_account_clean, df_card_clean, et df_disposition_clean sont chargés

# --- ÉTAPE 1 : CONVERSION DES DATES (LA CORRECTION EST ICI) ---
print("1. Conversion des colonnes de date (détection automatique)...")

# On laisse pandas deviner le format, car 'AAAA-MM-JJ' est un standard qu'il connaît.
df_account_clean['date_creation_compte'] = pd.to_datetime(df_account_clean['account_date'], errors='coerce')
df_card_clean['date_emission_carte'] = pd.to_datetime(df_card_clean['card_date'], errors='coerce')
print("   -> Dates converties avec succès.")


# --- ÉTAPE 2 : FUSIONNER LES TABLES (inchangé) ---
print("2. Fusion des tables...")
df_merged = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='inner')
df_final = pd.merge(df_merged, df_account_clean, on='account_id', how='inner')
print("   -> Fusion terminée.")


# --- ÉTAPE 3 : CALCULER L'ÉCART DE TEMPS (inchangé) ---
print("3. Calcul du délai d'émission...")
df_final['delai_emission_jours'] = (df_final['date_emission_carte'] - df_final['date_creation_compte']).dt.days
print("   -> Calcul terminé.")


# --- ÉTAPE 4 : AFFICHER LES RÉSULTATS ---
print("\nQuelques statistiques sur ce délai (en jours) :")
display(df_final['delai_emission_jours'].describe())


# --- ÉTAPE 5 : VISUALISATION ---
print("\n4. Création du graphique de distribution...")
# On s'assure de ne tracer que les données valides en enlevant les potentiels NaNs restants
delais_a_tracer = df_final['delai_emission_jours'].dropna()

if not delais_a_tracer.empty:
    plt.figure(figsize=(12, 6))
    sns.histplot(delais_a_tracer, bins=50, kde=True)
    plt.title('Distribution du délai (en jours) entre la création du compte et l\'émission de la carte', fontsize=16)
    plt.xlabel('Délai en jours', fontsize=12)
    plt.ylabel('Nombre de cartes émises', fontsize=12)
    plt.grid(True, linestyle='--')
    #plt.savefig('delai_emission_carte_final.png')
    plt.show()
else:
    print("Aucune donnée de délai valide à afficher.")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --- ÉTAPE 1 : CHARGEMENT ET PRÉPARATION DES DONNÉES (inchangé) ---
# On suppose que les fichiers clean sont chargés
#df_account_clean = pd.read_csv('account_clean.csv')
#df_card_clean = pd.read_csv('card_clean.csv')
#df_disposition_clean = pd.read_csv('disposition_clean.csv')

# Conversion des colonnes de date
df_account_clean['account_date_dt'] = pd.to_datetime(df_account_clean['account_date'])
df_card_clean['card_date_dt'] = pd.to_datetime(df_card_clean['card_date'])

# Fusion des tables
df_merged = pd.merge(df_card_clean, df_disposition_clean, on='disp_id', how='inner')
df_final = pd.merge(df_merged, df_account_clean, on='account_id', how='inner')

# Calcul du délai
df_final['delai_emission_jours'] = (df_final['card_date_dt'] - df_final['account_date_dt']).dt.days

# Sélection des colonnes pour l'analyse
result_table = df_final[['account_id', 'card_type', 'account_date_dt', 'delai_emission_jours']]


# --- ÉTAPE 2 : VISUALISATION MODIFIÉE ---
print("\n--- Visualisation : Délai d'émission vs Date de Création du compte ---")
plt.figure(figsize=(12, 8))

# LA MODIFICATION EST ICI : on utilise x='account_date_dt'
sns.scatterplot(
    data=result_table,
    x='account_date_dt',
    y='delai_emission_jours',
    hue='card_type',
    alpha=0.7,
    s=100
)

plt.title("Délai d'émission de la carte vs. Date de Création du compte", fontsize=16)
plt.xlabel("Date de Création du Compte", fontsize=12) # On met à jour le label de l'axe
plt.ylabel("Délai d'attente pour la carte (jours)", fontsize=12)
plt.grid(True)
plt.legend(title='Type de carte')
#plt.savefig('delai_vs_date_creation_carte.png')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import kruskal

# --- ÉTAPE 1: CHARGEMENT DES DONNÉES ---
# try:
#     # Utilisons les noms de vos fichiers "clean" qui ont les bonnes colonnes
#     #df_trans_clean = pd.read_csv('df_trans_clean.csv')
#     #df_card_clean = pd.read_csv('card_clean.csv')
#     #df_disposition_clean = pd.read_csv('disposition_clean.csv')
#     print("Fichiers 'clean' chargés avec succès.")
# except FileNotFoundError as e:
#     print(f"Erreur de chargement : {e}. Assurez-vous que les fichiers clean sont disponibles.")
#     # On arrête si les fichiers ne sont pas trouvés.


# --- ÉTAPE 2: PRÉPARATION DES DONNÉES (AVEC CORRECTION ROBUSTE) ---

# 1. Calculer le nombre de transactions par compte
print("1. Calcul du nombre de transactions par compte...")
trans_counts = df_trans_clean.groupby('account_id').size().reset_index(name='nb_transactions')

# 2. Identifier le type de carte pour chaque compte
print("2. Identification du type de carte par compte...")
card_disp = pd.merge(df_card_clean, df_disposition_clean, on='disp_id')

# LA CORRECTION EST ICI : On utilise directement 'card_type' car c'est le bon nom dans vos fichiers clean
card_info = card_disp[['account_id', 'card_type']]
# S'il y a plusieurs cartes pour un même compte, on garde la première trouvée
card_info = card_info.drop_duplicates(subset='account_id', keep='first')


# 3. Harmonisation des types et fusion
print("3. Fusion des données...")
trans_counts['account_id'] = trans_counts['account_id'].astype(int)
card_info['account_id'] = card_info['account_id'].astype(int)
df_analysis = pd.merge(trans_counts, card_info, on='account_id', how='inner')
print("   -> Données prêtes pour l'analyse.")


# --- ÉTAPE 3: VISUALISATION ---
# (Le reste du code est inchangé et devrait maintenant fonctionner)
print("\n4. Création du graphique de comparaison...")
plt.figure(figsize=(10, 8))
sns.boxplot(data=df_analysis, x='card_type', y='nb_transactions', order=['junior', 'classic', 'gold'])
plt.title('Distribution du Nombre de Transactions par Type de Carte', fontsize=16)
plt.xlabel('Type de Carte', fontsize=12)
plt.ylabel('Nombre de Transactions', fontsize=12)
plt.grid(axis='y', linestyle='--')
#plt.savefig('transactions_par_type_carte.png')
plt.show()


# --- ÉTAPE 5: TEST STATISTIQUE (KRUSKAL-WALLIS) ---
print("\n5. Exécution du test statistique pour confirmer...")
try:
    # Préparer les données pour le test
    gold_trans = df_analysis[df_analysis['card_type'] == 'gold']['nb_transactions']
    classic_trans = df_analysis[df_analysis['card_type'] == 'classic']['nb_transactions']
    junior_trans = df_analysis[df_analysis['card_type'] == 'junior']['nb_transactions']

    # Exécuter le test
    stat, p_value = kruskal(gold_trans, classic_trans, junior_trans)

    print("\n--- Test de Kruskal-Wallis ---")
    print(f"Statistique H = {stat:.2f}")
    print(f"P-value = {p_value}")

    if p_value < 0.05:
        print("Conclusion : Il existe une différence statistiquement significative dans le nombre de transactions entre les différents types de cartes.")
    else:
        print("Conclusion : Il n'y a pas de différence statistiquement significative dans le nombre de transactions entre les différents types de cartes.")
except ValueError:
    print("Un ou plusieurs types de cartes n'ont pas de données de transaction, le test statistique ne peut être effectué.")



"""#check des tables"""

df_account_clean = df_account_clean.drop(columns=['account_date_dt'])
df_card_clean = df_card_clean.drop(columns=['card_date_dt'])

#date_creation_compte =  df_trans_clean.drop(columns=['year',	'month'	,'day',	'periode'])

df_account_clean = df_account_clean.drop(columns=['date_creation_compte'])
df_card_clean = df_card_clean.drop(columns=['date_emission_carte'])

df_card_clean['has_card'] = 1

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy(), #pbt2:  ajout de type_compte_kmeans
account = df_account_clean.copy(), #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_card_clean.head()),
card = df_card_clean.copy(),  #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS même si on devrait creuser les intérets sur la partie Power BI
#pbt compte : table compte, on ne garde pas ancienneté (droppper)
#pbt loan : RAS
#pbt card : drop de colonnes ajouter par Gemini et des dates sur transaction

"""#**4 - Transaction**"""



"""##**interpolation**"""

from sklearn.preprocessing import LabelEncoder

# Copie du dataframe
df_interpolation = df_trans_clean.copy()


# df_interpolation['date'] = pd.to_datetime(df_['date'])
df_interpolation = df_interpolation.sort_values(by=['account_id', 'trans_date'])


df_interpolation['operation_clean'] = df_interpolation['operation'].replace("inconnu", pd.NA)


le = LabelEncoder()
known_ops = df_interpolation['operation_clean'].dropna()
le.fit(known_ops)


def encode_or_nan(val):
    if pd.isna(val):
        return np.nan
    return le.transform([val])[0]

df_interpolation['operation_encoded'] = df_interpolation['operation_clean'].apply(encode_or_nan)

# Interpolation
df_interpolation['operation_encoded_interp'] = (df_interpolation.groupby('account_id', group_keys=False)['operation_encoded']
                                                .apply(lambda x: x.interpolate(method='linear', limit_direction='both'))
)


df_interpolation['operation_interpolated'] = df_interpolation['operation_encoded_interp'].round().apply(lambda x: le.inverse_transform([int(x)])[0] if pd.notna(x) else "inconnu")

# Vérification
df_interpolation[['account_id', 'trans_date', 'operation', 'operation_interpolated']].head(10)

df_interpolation.value_counts('operation_interpolated')

# Affichage des résultats
operation_counts.head(6)

# Création d'un graphique à barres
plt.figure(figsize=(10, 6))
plt.bar(df_interpolation['operation_interpolated'].value_counts().index, df_interpolation['operation_interpolated'].value_counts().values)
plt.title("Types d'opérations bancaires les plus fréquents")
plt.xlabel("Type d'opération")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=45)
plt.tight_layout()
plt.grid(axis='y')
plt.show()

df_interpolation.head()

df_trans_clean.shape

#Transformer df_interpolation en df_trans_clean propre
df_inter = df_interpolation[['trans_id', 'account_id', 'trans_date', 'trans_type',
       'trans_amount', 'trans_balance', 'order_type', 'bank_to',
       'order_account', 'type_compte_kmeans', 'year', 'month', 'day',
       'periode', 'operation_interpolated']]

df_inter = df_inter[['trans_id', 'account_id', 'trans_date', 'trans_type','operation_interpolated',
       'trans_amount', 'trans_balance', 'order_type', 'bank_to',
       'order_account', 'type_compte_kmeans', 'year', 'month', 'day',
       'periode']]

df_inter['operation'] = df_inter['operation_interpolated']

df_inter = df_inter[['trans_id', 'account_id', 'trans_date', 'trans_type','operation',
       'trans_amount', 'trans_balance', 'order_type', 'bank_to',
       'order_account', 'type_compte_kmeans', 'year', 'month', 'day',
       'periode']]
df_trans_clean = df_inter.copy()

df_trans_clean.head()

"""##**Jointure**"""

client_account_district_trans_KP = pd.merge(df_trans_clean, client_account_district, on='account_id', how='left')

"""##**1 - Répartition par type de transaction**"""

import matplotlib.pyplot as plt

# Vérifie que la colonne 'type' existe
if 'trans_type' in client_account_district_trans_KP.columns:
    plt.figure(figsize=(7,5))
    client_account_district_trans_KP['trans_type'].value_counts().plot(kind='bar', color='skyblue')
    plt.title("Répartition par type de transaction")
    plt.xlabel("trans_type")
    plt.ylabel("Nombre de transactions")
    plt.xticks(rotation=45)
    plt.grid(axis='y')
    plt.tight_layout()
    plt.show()
else:
    print("Colonne 'type' non trouvée.")

"""##**2 - Répartition par type d'opération**"""

# Vérifie que la colonne 'operation' existe
if 'operation' in client_account_district_trans_KP.columns:
    plt.figure(figsize=(9,5))
    client_account_district_trans_KP['operation'].value_counts(dropna=False).plot(kind='bar', color='lightcoral')
    plt.title("Répartition par type d'opération")
    plt.xlabel("Opération")
    plt.ylabel("Nombre de transactions")
    plt.xticks(rotation=90)
    plt.grid(axis='y')
    plt.tight_layout()
    plt.show()
else:
    print("Colonne 'operation' non trouvée.")

"""##**3 - Volume total des montants par compte et type d'opération / Moyenne des montants par compte et type d'opération**
      
"""

# On s'assure que les colonnes nécessaires existent
required_cols = ['account_id', 'operation', 'trans_amount']
if all(col in client_account_district_trans_KP.columns for col in required_cols):

    # 1. Volume total des montants par compte et type d'opération
    volume_total = client_account_district_trans_KP.groupby(['account_id', 'operation'])['trans_amount'].sum().reset_index()
    volume_total.rename(columns={'trans_amount': 'total_amount'}, inplace=True)

    # 2. Moyenne des montants par compte et type d'opération
    moyenne_montant = client_account_district_trans_KP.groupby(['account_id', 'operation'])['trans_amount'].mean().reset_index()
    moyenne_montant.rename(columns={'trans_amount': 'mean_amount'}, inplace=True)

    # Fusion des deux tableaux
    resume_trans = pd.merge(volume_total, moyenne_montant, on=['account_id', 'operation'])

    # Affichage classique
    resume_trans.head()  # ou .to_csv("resume_trans.csv") pour sauvegarder

else:
    print("Colonnes nécessaires manquantes :", [col for col in required_cols if col not in client_account_district_trans_KP.columns])

resume_trans  # ou .to_csv("resume_trans.csv") pour sauvegarder

import matplotlib.pyplot as plt

# On agrège les données globalement par type d'opération (tous comptes confondus)
agg_by_operation = resume_trans.groupby('operation').agg({
    'total_amount': 'sum',
    'mean_amount': 'mean'
}).sort_values(by='total_amount', ascending=False)

# Sélection des 10 opérations les plus significatives
top_ops = agg_by_operation#.head(10)

# Tracé du volume total cumulé
plt.figure(figsize=(10, 5))
top_ops['total_amount'].plot(kind='bar', color='cornflowerblue')
plt.title("Opérations par montant total cumulé")
plt.xlabel("Type d'opération")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Tracé du montant moyen
plt.figure(figsize=(10, 5))
top_ops['mean_amount'].plot(kind='bar', color='orange')
plt.title("Opérations par montant moyen")
plt.xlabel("Type d'opération")
plt.ylabel("Montant moyen (CZK)")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""##**4 - Volume total par compte et type d'opération**"""

# 📊 1. Volume total par compte et type d'opération

import matplotlib.pyplot as plt

# On prend les 10 comptes les plus actifs par volume total (somme) toutes opérations confondues
top_comptes_volume = resume_trans.groupby('account_id')['total_amount'].sum().nlargest(5).index

# On filtre les lignes concernées
volume_top_accounts = resume_trans[resume_trans['account_id'].isin(top_comptes_volume)]

# Graphe
plt.figure(figsize=(12,6))
for compte in top_comptes_volume:
    subset = volume_top_accounts[volume_top_accounts['account_id'] == compte]
    plt.plot(subset['operation'], subset['total_amount'], marker='o', label=f'Compte {compte}')

plt.title("📊 Volume total par compte et type d'opération (Top 5 comptes)")
plt.xlabel("Type d'opération")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.grid(True)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# ordre des colonnes pour qu’elles soient toujours dans le même sens
ordre_ops = ['depot en especes',
             'retrait en especes',
             'retrait par carte',
             'virement entrant',
             'virement sortant']

plt.figure(figsize=(12,6))
sns.barplot(data=volume_top_accounts,
            x='operation',
            y='total_amount',
            hue='account_id',
            order=ordre_ops)

plt.title("Volume total (CZK) par type d'opération – Top 5 comptes")
plt.xlabel("")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.04,1), loc='upper left')
plt.tight_layout()
plt.show()



# 📈 2. Montant moyen par compte et type d'opération

# On prend les 10 comptes ayant les plus gros montants moyens cumulés (sur toutes opérations)
top_comptes_moyenne = resume_trans.groupby('account_id')['mean_amount'].mean().nlargest(5).index

# On filtre
mean_top_accounts = resume_trans[resume_trans['account_id'].isin(top_comptes_moyenne)]

# Graphe
plt.figure(figsize=(12,6))
for compte in top_comptes_moyenne:
    subset = mean_top_accounts[mean_top_accounts['account_id'] == compte]
    plt.plot(subset['operation'], subset['mean_amount'], marker='o', label=f'Compte {compte}')

plt.title("📈 Montant moyen par compte et type d'opération (Top 5 comptes)")
plt.xlabel("Type d'opération")
plt.ylabel("Montant moyen (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.grid(True)
plt.show()

plt.figure(figsize=(12,6))
sns.barplot(data=mean_top_accounts,
            x='operation',
            y='mean_amount',
            hue='account_id')

plt.title("Montant moyen (CZK) – Top 5 comptes, par type d'opération")
plt.xlabel("")
plt.ylabel("Montant moyen (CZK)")
plt.xticks(rotation=45)
plt.legend(title="Account ID", bbox_to_anchor=(1.04,1), loc='upper left')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Vérifie et convertit la colonne date si besoin
if 'trans_date' not in client_account_district_trans_KP.columns and 'date' in client_account_district_trans_KP.columns:
    client_account_district_trans_KP.rename(columns={'date': 'trans_date'}, inplace=True)

client_account_district_trans_KP['trans_date'] = pd.to_datetime(client_account_district_trans_KP['trans_date'], errors='coerce')

# Regroupement mensuel
client_account_district_trans_KP['month_x'] = client_account_district_trans_KP['trans_date'].dt.to_period('M').astype(str)

monthly_stats = client_account_district_trans_KP.groupby('month_x').agg({
    'trans_amount': ['count', 'sum']
}).reset_index()

monthly_stats.columns = ['month_x', 'transaction_count', 'transaction_sum']

# Visualisation
plt.figure(figsize=(12,5))
plt.plot(monthly_stats['month_x'], monthly_stats['transaction_count'], marker='o', label='Nombre de transactions')
plt.title("📈 Évolution du nombre de transactions par mois")
plt.xlabel("Mois")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=90)
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,5))
plt.plot(monthly_stats['month_x'], monthly_stats['transaction_sum'], marker='o', color='green', label='Montant total')
plt.title("💰 Évolution du montant total des transactions par mois")
plt.xlabel("Mois")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=90)
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Vérifie et convertit la colonne date si besoin
if 'trans_date' not in client_account_district_trans_KP.columns and 'date' in client_account_district_trans_KP.columns:
    client_account_district_trans_KP.rename(columns={'date': 'trans_date'}, inplace=True)

client_account_district_trans_KP['trans_date'] = pd.to_datetime(client_account_district_trans_KP['trans_date'], errors='coerce')

# Regroupement mensuel
client_account_district_trans_KP['year_x'] = client_account_district_trans_KP['trans_date'].dt.to_period('Y').astype(str)

monthly_stats = client_account_district_trans_KP.groupby('year_x').agg({
    'trans_amount': ['count', 'sum']
}).reset_index()

monthly_stats.columns = ['year_x', 'transaction_count', 'transaction_sum']

# Visualisation
plt.figure(figsize=(12,5))
plt.plot(monthly_stats['year_x'], monthly_stats['transaction_count'], marker='o', label='Nombre de transactions')
plt.title("📈 Évolution du nombre de transactions par an")
plt.xlabel("Année")
plt.ylabel("Nombre de transactions")
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,5))
plt.plot(monthly_stats['year_x'], monthly_stats['transaction_sum'], marker='o', color='green', label='Montant total')
plt.title("💰 Évolution du montant total des transactions par an")
plt.xlabel("Année")
plt.ylabel("Montant total (CZK)")
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

"""##**5 - Évolution des types d'opérations bancaires (jusqu'à 1999)**"""

import pandas as pd
import matplotlib.pyplot as plt


# Vérifie si la colonne 'type' existe
if 'trans_type' not in df_trans_clean.columns:
    print("❌ Erreur : colonne 'type' absente du fichier.")
else:
    # Groupe par mois et type
    grouped = df_trans_clean.groupby(['periode', 'operation']).size().reset_index(name='count')

    # Tableau pivot pour les courbes
    pivoted = grouped.pivot(index='periode', columns='operation', values='count').fillna(0)

    # Tracé
    pivoted.plot(
    figsize=(14, 8),  #<-- LA CORRECTION EST ICI (ex: 18 de large, 8 de haut)
    marker='o',
    linestyle='--'
    )
    #plt.figure(figsize=(14, 6))
    #pivoted.plot(marker='o')
    plt.title("📈 Évolution des types d'opérations bancaires (jusqu'à 1999)")
    plt.xlabel("Mois")
    plt.ylabel("Nombre d'opérations")
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.tight_layout()
    plt.legend(title="Type d'opération")
    plt.show()

"""#check des tables"""

display(df_loan_clean.head()),
#loan = df_loan_clean.copy(), #pbt2: ajout de has_loan

display(df_client_clean.head()),
#client = df_client_clean.copy() # pbt1 ajout des tranches d'age

display(df_account_clean.head()),
#account = df_account_clean.copy(), #pbt2:  ajout de type_compte_kmeans
#account = df_account_clean.copy(), #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_card_clean.head()),
#card = df_card_clean.copy(),  #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_disposition_clean.head()),
display(df_district_clean.head()),
#district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head()),

display(df_trans_clean.head())
#transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans
#transaction = df_trans_clean.copy() #pbt transaction: remplacer les inconnus par des valeurs sur la colonne Operation

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS même si on devrait creuser les intérets sur la partie Power BI
#pbt compte : table compte, on ne garde pas ancienneté (droppper)
#pbt loan : RAS
#pbt card : drop de colonnes ajouter par Gemini et des dates sur transaction

#vérification
#df_trans_clean['operation'].value_counts(dropna = False)

"""#**5 - Client Solvabilité**

###**Jointure**
"""

df_client_disp = pd.merge(df_client_clean, df_disposition_clean, on='client_id', how='left')
df_client_account = pd.merge(df_client_disp, df_account_clean, on='account_id', how='left')
df_client_loan = pd.merge(df_client_account, df_loan_clean, on='account_id', how='left')
df_full = pd.merge(df_client_loan, df_district_clean, left_on='district_id_x', right_on='district_id', how='left')



import pandas as pd
from datetime import date
# MAPPING : client  →  account
df_client_disp = (df_disposition_clean
                  .merge(df_client_clean, on='client_id', how='left'))

df_client_account = (df_client_disp
                     .merge(df_account_clean, on='account_id', how='left'))

# PRÊTS  (1 max par compte)

df_loan_flag = df_loan_clean.rename(columns={'amount': 'loan_amount',
                                             'duration': 'loan_duration',
                                             'payments': 'loan_pmt'})
df_client_loan = df_client_account.merge(df_loan_flag,
                                         on='account_id', how='left')

# AGRÉGATS TRANSACTIONS

# solde moyen
trans = df_trans_clean.copy()
trans['trans_balance'] = trans['trans_balance'].astype(float)
avg_bal = (trans.groupby('account_id')['trans_balance']
                 .mean().reset_index(name='avg_balance'))

# « incidents » de trésorerie : retraits, paiements, découverts
mask_inc = trans['operation'].str.contains(
              'withdraw|collect|remit|credit card',
              case=False, na=False)

incidents = (trans[mask_inc]
             .groupby('account_id')
             .size()
             .reset_index(name='nb_incidents'))
for df in [df_client_loan, avg_bal, incidents]:
    df['account_id'] = df['account_id'].astype(str)


# fusion agrégats
df_client_tx = (df_client_loan
                .merge(avg_bal, on='account_id', how='left')
                .merge(incidents, on='account_id', how='left'))

df_client_tx['avg_balance'].fillna(0, inplace=True)
df_client_tx['nb_incidents'].fillna(0, inplace=True)


# 4.  VARIABLES DE SOLVABILITÉ

# flags prêts / cartes
df_client_tx['has_loan'] = df_client_tx['loan_amount'].notna().astype(int)

# ratio mensualité / solde moyen (évite division par 0)
df_client_tx['loan_monthly_ratio'] = (
    df_client_tx['loan_payments'] /
    df_client_tx['avg_balance'].replace(0, pd.NA)
).fillna(0)

# seuils data-driven (percentiles)
ratio_p75     = df_client_tx['loan_monthly_ratio'].quantile(0.75)
incident_p75  = df_client_tx['nb_incidents'].quantile(0.75)

df_client_tx['solvable'] = (
      (df_client_tx['loan_monthly_ratio'] < ratio_p75)
    & (df_client_tx['nb_incidents']       < incident_p75)
).astype(int)

#  AGRÉGATION PAR CLIENT
df_solv = (df_client_tx
           .groupby('client_id')
           .agg(has_loan          = ('has_loan', 'max'),
                loan_amount_sum  = ('loan_amount', 'sum'),
                loan_monthly_ratio= ('loan_monthly_ratio', 'mean'),
                avg_balance       = ('avg_balance', 'mean'),
                nb_incidents      = ('nb_incidents', 'sum'),
                solvable          = ('solvable', 'max'))
           .reset_index())



# Calculer le 75e percentile SANS les zéros
ratio_p75 = (df_solv['loan_monthly_ratio']
             .loc[lambda s: s > 0]
             .quantile(0.75))

# Si tout est à 0 → on force un epsilon, ex. 0.01
if pd.isna(ratio_p75) or ratio_p75 == 0:
    ratio_p75 = 0.01

# Construire les bornes, puis supprimer les doublons éventuels
bins = pd.unique([-float('inf'), ratio_p75/2, ratio_p75, float('inf')])

# Adapter la liste de labels au nombre de classes (len(bins)-1)
labels = ['Solvable (A)', 'Vigilance (B)', 'Risque (C)'][:len(bins)-1]

# Découper
df_solv['segment_solvabilité'] = pd.cut(
    df_solv['loan_monthly_ratio'],
    bins=bins,
    labels=labels,
    duplicates='drop'
)

# RÉSULTAT
df_solv['segment_solvabilité'].value_counts(dropna=False)
df_solv

df_solv['segment_solvabilité'].value_counts()

"""##**interpretation de la solvabilité**"""

# # | Segment           | Règle (rappel)                                          |  Effectif | Part du portefeuille | Lecture terrain                                                                                                      |
# # | ----------------- | ------------------------------------------------------- | --------: | -------------------: | -------------------------------------------------------------------------------------------------------------------- |
# # | **Solvable (A)**  | mensualité / solde moyen < ½ P75 **ET** incidents < P75 | **4 777** |           **≈ 89 %** | Clientèle globalement saine : capacité de remboursement confortable ; incidents de trésorerie inférieurs à la norme. |
# # | **Vigilance (B)** | ½ P75 ≤ ratio < P75 **OU/ET** incidents proches P75     |   **386** |                ≈ 7 % | Situation correcte mais marge de manœuvre plus faible ; suivi prudent, proposer conseils budgétaires.                |
# # | **Risque (C)**    | ratio ≥ P75 **OU** incidents ≥ P75                      |   **206** |                ≈ 4 % | Tension de trésorerie élevée ; potentiel défaut en cas de choc. Priorité : restructuration ou garanties.             |

# # ********Total clients analysés : 5 369.

# 1. Ce que cela dit de votre portefeuille
# Structure très favorable : près de 9 clients sur 10 sont dans la zone verte (A).

# Risque concentré : 4 % (« C ») suffisent toutefois à entraîner des pertes si les encours sont élevés ; ces clients méritent un suivi individualisé.

# Les clients « B » forment une zone tampon : ils ne posent pas encore problème mais peuvent basculer vers « C » en cas d’augmentation des taux ou perte de revenus.

"""##**visualistaion**"""

import matplotlib.pyplot as plt

# Data for the solvency segments
labels = ['Solvable (A)', 'Vigilance (B)', 'Risque (C)']
sizes = [4777, 386, 206]

# Create the pie chart
fig, ax = plt.subplots(figsize=(5, 5))
ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=45)
ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Répartition des segments de solvabilité')

plt.show()

client_solv = pd.merge(df_client_clean, df_solv, how = 'left', on = 'client_id')
client_solv

client_solv = client_solv[['client_id', 'district_id', 'birth_date', 'gender', 'age','tranche_age',
  'has_loan', 'loan_amount_sum', 'loan_monthly_ratio',
  'segment_solvabilité']]
client_solv

#vérification
#df_trans_clean['operation'].value_counts(dropna = False)

df_card_clean.head()

# jointure client avec loan et card
client_disp = pd.merge(df_client_clean, df_disposition_clean, on='client_id', how='left')
client_loan= pd.merge(client_disp, df_loan_clean, on='account_id', how='left')
client_card = pd.merge(client_loan, df_card_clean, on='disp_id', how='left')
client_card['has_card'] = client_card['card_id'].notna().astype(int)
client_card['has_loan'] = client_card['has_loan'].notna().astype(int)
client_card['has_account'] = client_card['disp_role'].replace({'OWNER': 1, 'DISPONENT': 0})
client_card.columns

client_card = client_card[['client_id', 'district_id', 'birth_date', 'gender', 'age',
       'tranche_age', 'has_account','has_loan', 'has_card']]

client_card

"""#**Analyse Sup**"""

# Fusion client ↔ disposition ↔ compte
df_disp_client = df_disposition_clean.merge(client_card, on='client_id', how='left')
df_account_client = df_disp_client.merge(df_account_clean, on='account_id', how='left')
df_account_client

#df_owner = df_account_client[df_account_client['disp_role'] == 'OWNER']
#df_account_client.head()

df_owner = df_account_client.merge(df_solv, on='client_id', how='left')
df_owner

colonnes_a_supprimer = [
    'has_loan_y',
    'loan_amount_sum',
    'loan_monthly_ratio',
    'avg_balance',
    'nb_incidents',
    'solvable',
    'district_id_y'
]

df_owner.drop(columns=colonnes_a_supprimer, inplace=True)

df_owner

df_client_final = df_owner.copy()
df_client_clean = df_client_final.copy()

"""#check des tables"""

df_client_clean = client_card.copy()

df_account_clean

display(df_loan_clean.head())
loan = df_loan_clean.copy() #pbt2: ajout de has_loan

display(df_client_clean.head())
client = df_client_clean.copy() # pbt1 ajout des tranches d'age
#client = df_client_clean.copy() # pbt solvabilite : ajout has_account, loan et card


display(df_account_clean.head())
account = df_account_clean.copy() #pbt2:  ajout de type_compte_kmeans
#account = df_account_clean.copy(), #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_card_clean.head())
card = df_card_clean.copy()  #pbt card : suppression de colonnes de dates ajouter avec gemini

display(df_disposition_clean.head())
disposition = df_disposition_clean.copy()


display(df_district_clean.head())
district = df_district_clean.copy() #pbt 5 ajout du score PCA

display(df_order_clean.head())
order = df_order_clean.copy()


display(df_trans_clean.head())
transaction = df_trans_clean.copy() #pbt2: ajout de type_compte_kmeans
#transaction = df_trans_clean.copy() #pbt transaction: remplacer les inconnus par des valeurs sur la colonne Operation

#pbt 3 : rien a signaler (RAS)
#pbt 4 : nous ne reprenons pas le avg_balance, car pas utile, mais àre checker
#pbt 6 : RAS
#pbt 7 : RAS
#pbt 8 : RAS même si on devrait creuser les intérets sur la partie Power BI
#pbt compte : table compte, on ne garde pas ancienneté (droppper)
#pbt loan : RAS
#pbt card : drop de colonnes ajouter par Gemini et des dates sur transaction

#type(df_account_clean)
df_client_clean

"""#**Exportation des données**"""

# client.to_csv("client_final.csv", index=False)

# client.to_csv("client_final.csv", index=False)
# account.to_csv("account_final.csv", index=False)
# transaction.to_csv("transaction_final.csv", index=False)
# loan.to_csv("loan_final.csv", index=False)
# card.to_csv("card_final.csv", index=False)
# order.to_csv("order_final.csv", index=False)
# district.to_csv("district_final.csv", index=False)
# disposition.to_csv("disposition_final.csv", index=False)

df_client_final



"""#Order Permanent"""

order_account = pd.merge(df_account_clean, df_order_clean, on='account_id', how='left')
order_account

df_order_clean.shape

df_account_clean.shape

account_order = pd.merge(df_account_clean, df_order_clean, on='account_id', how='inner')
account_order

account_order['order_type'].value_counts(dropna = False)

#groupé par account_id
account_ = account_order.groupby(['account_id', 'order_type']).size().reset_index(name='count')
account_

group = account_order.groupby('account_id')['order_amount'].sum()
group

